{"./":{"url":"./","title":"简介","keywords":"","body":"简介 本资源是PyTorch模型训练实用教程的第二版，将为广大朋友带来更丰富的PyTorch学习资源。看到PyTorch模型训练实用教程过了三年，仍旧在发光发热，依旧能帮助到初学者，这令我十分欣慰，但又非常愧疚。为什么？因为深感PyTorch模型训练实用教程的内容不够丰富，不能给初学朋友更多的帮助。为此，《PyTorch实用教程》将弥补第一版的空白，新增丰富的内容，想大家之所想，将提供在线阅读的电子书籍，以及入门友好的、可工业落地的配套代码。 本书整体分三部分，上篇：入门，中篇：应用，下篇：落地。 上篇 PyTorch基础。针对刚入门、非科班、本科生，提供PyTorch介绍，讲解开发环境的搭建，介绍PyTorch核心模块，详解核心功能函数，最后利用所讲解的PyTorch知识点构建一套自己的代码结构，为后续的应用打下基础。 中篇 产业应用。经过上篇，磨了一把好刀，接下来就用它在各领域上大显身手。计划讲解的领域包括，计算机视觉（Computer Vision）的图像分类、图像分割、目标检测、生成对抗网络等；自然语言处理（Natural Language Processing）的部分应用；语音识别；多模态等领域。（由于自己对CV比较熟悉，其他领域欢迎有志之士一同补充） 下篇 工业落地。有了工具，有了场景，接下来就要让它产生价值，变成可用的、好用的产品。本篇会涉及模型加速三板斧：模型量化、模型剪枝、模型蒸馏。此外，还会涉及主流的模型部署框架平台：TensorRT、Openvinno、ONNX等（同上，此处欢迎大家一同补充各平台的部署内容） 相信经过上、中、下篇的学习，可以帮助入门的同学少走很多弯路，快速掌握PyTorch，具备独当一面的能力，能依据实际场景选择算法模型，可以将模型部署应用，形成闭环，全流程打通。 如何使用本资源，请看前言 有任何想法和建议，欢迎与我联系：yts3221@126.com Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"preface.html":{"url":"preface.html","title":"前言","keywords":"","body":"前言 本书背后的故事 《PyTorch实用教程》（第二版），动笔时间为2021年12月16日，什么时候能完结，并不知道。为什么会不是写完再发布？因为担心再不迈出第一步，这本书就会难产。其实，想写这本书已经很久了，至少2年多了吧（见下图），总由于各种原因，迟迟没有开始动笔，索性，采用github在线更新的方式，和各位朋友提前见面吧，你们的反馈是我最大的动力。 为什么是书？ 书籍是人类智慧的结晶，不同于普通的博客、公众号甚至课件，书籍的内容会更加完整和充实，这是受到前些天看到的一个视频有感而发，视频说的是北大退休的韩茂莉教授将在B站上延续她的课堂生涯，将她毕生所学的历史地理知识传授给更多的朋友，在第一个视频里她提到：“但凡具有一种人类形成的，知识性的精华，其实都在书中 。” 看到这句话感触颇深，因为写书的事情一直在脑海中反复回荡，但一次次的被生活的琐碎给拍灭。除了韩老师触动之外，自己这几年的经历也十分契合书写一本书，同时也欢迎有志之士与我一同完善这本《PyTorch实用教程》（第二版）。 一小步 为了不让这本书难产，于是先走出这一小步，让自己踏上书写的征程，至于后面的东西交给时间吧。 为什么写这本书 ​ 这本书是对PyTorch模型训练实用教程的改进优化，是对第一版的内容进行丰富，会增加更多的PyTorch基础，增加丰富的应用案例，同时包含模型部署上线这一关键的知识点。萌生第二版的想法大约在2019年11月，当时距离第一版发布大约一年，期间又对PyTorch有了一个深入的学习了解过程，于是想把这本书继续优化下去，帮助更多的朋友快速掌握PyTorch。可奈于当时精力有限，就迟迟没有动笔，2020年与2021年是忙碌的两年，生活的琐碎以及工作占据了大多数时间，现在（2021年12月16日22:13:10）终于有合适的条件动笔了，一刻不敢拖延，害怕这刚刚燃起的火苗又被琐碎的生活浇灭。 ​ 除了是对第一版的改进，更大的原因是一种责任。由于这几年的经历，让我感到需要出一本高质量的PyTorch书，它一定是大家爱不释手的资料，可以为大家的深度学习道路提供一点便捷，能给大家带来些许改变，这就足够了。第一版发布过去已经三年有余，仍旧能看到她在发光发热，这令我十分欣慰，但又非常愧疚。 第一版仍旧在发光发热 ​ 因为第一版的内容略显简单，内容单薄，缺乏应用案例以及工业部署落地。那么第二版就是为了弥补上述缺点，把PyTorch基础内容完善，增加CV和NLP以及多模态的工业级应用案例，最后讲解模型部署，实现工业落地，这样的教程才是完整的，不是么。 ​ 通过本书，也希望给大家带来一个清晰的深度学习模型应用流程。 读者对象 首先，适合新手，本书上篇将介绍PyTorch最基础的概念，为新手构建知识框架，上篇所有知识点配备Notebook进行图、文、代码，三位一体的学习。 其次，适合初学者，本书中篇将采用PyTorch代码进行各领域应用案例讲解，暂定包括计算机视觉、自然语言处理、语音识别和多模态，同时提供完整的代码框架，开箱即用，无需额外编程，可涵盖大多数朋友的项目需求。 再者，适合中高级朋友，本书下篇将涉及模型加速与部署内容，是算法工程师进阶的必备之路，模型加速包括剪枝、量化、蒸馏，部署暂定包括TensorRT、OpenVINO和ONNX。 上中下篇分别对应不同阶段的学习，相信大多数朋友都能从本书中获益。 如何阅读这本书 本书采用电子书在线更新方式，详见PyTorch实用教程（第二版）-电子书 全书配套代码，详见PyTorch-Tutorial-2nd 由于自身水平、精力有限，书中不可避免的会出现错误，恳请大家指正。同时欢迎大家投稿，例如NLP方向，多模态方向，模型部署，模型加速方向均可。 欢迎联系：yts3221@126.com 致谢 首先感谢家人的理解与支持。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-1/":{"url":"chapter-1/","title":"第一章 PyTorch 简介与安装","keywords":"","body":"第一章 PyTorch 简介与安装 第一章 PyTorch 简介与安装 1.1 PyTorch 初认识 1.2 环境配置之Anaconda 1.3 环境配置之Pycharm 1.4 环境配置之CUDA&cuDNN 1.5 环境配置之PyTorch系列包 1.6 环境配置之Jupyter Notebook Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-1/1.1-PyTorch-Introduction.html":{"url":"chapter-1/1.1-PyTorch-Introduction.html","title":"1.1 PyTorch 初认识","keywords":"","body":"1.1 PyTorch 初认识 一句话认识PyTorch “An open source machine learning framework that accelerates the path from research prototyping to production deployment.” ——选自 https://pytorch.org/ PyTorch是一个帮助大家加速算法模型研究到产品部署的开源机器学习框架。 PyTorch历史 FAIR（ Facebook AI Research，Facebook人工智能研究院 ）于2017年初发布PyTorch，PyTorch的命名可以拆为Py（Python）与Torch。Py就是python语言，Torch是一款早期的深度学习框架，所以PyTorch是在Torch基础上用python语言重新打造的一款深度学习框架。 那么什么是Torch呢？Torch是纽约大学在2002年开发的深度学习框架。Torch虽然很好用，但是它采用了一门较为小众的语言——Lua语言作为接口。这明显地增高了Torch的使用门槛，想要使用Torch必须学习一门新的编程语言，这让大家都望而却步。 好在Torch的幕后团队也意识到这一点，于是团队采用python语言作为接口对Torch进行了重构，于是就有了PyTorch。 PyTorch代码最早公开可追溯到2016年8月24日的v0.1.1（https://github.com/pytorch/pytorch/tags?after=v0.1.4） 随后 •2017年1月正式发布PyTorch •2018年4月更新0.4.0版，支持Windows系统 •2018年11月更新1.0稳定版，已GitHub 增长第二快的开源项目 ...... 对PyTorch版本的更新感兴趣的朋友，可以关注 PyTorch-Tags，这里是最权威版本更新信息来源，要比官方文档还要快。 PyTorch必备网站 要熟悉PyTorch，不得不熟悉PyTorch的一些官方网站，以及这些网站的使用。下面列举几个实用的PyTorch网站。 官网 https://pytorch.org/ 官网包含权威的PyTorch介绍、PyTorch官方文档、生态资源等信息。例如Get Started中，可以获取权威的安装信息。例如，特定版本下，windows系统，所支持的CUDA版本是多少，这点非常关键，往往GPU用不起来，就是CUDA版本不匹配。 除了最新稳定版，还可以下载历史版本的whl文件，进行离线安装（网速不好的朋友，建议手动下载whl，然后进行安装）。历史版本whl的在哪那里下载呢？ 是需要挖掘的，网址在上图的windows系统、Pip安装、Python、CUDA条件下才会出现，它是：https://download.pytorch.org/whl，点击torch，就可以发现所有历史版本都在这里可以找到，并且命名都有良好的规范，这里不过多介绍，在安装部分再详细讲解。 除了Get Started栏目，其它栏目也是很好的学习资料。 Ecosystem：PyTorch生态系统资源库，里面收录生态系统内的资源，也欢迎大家加入并贡献资源，里边有CV数据增强开源库——albumentations、FB的目标检测和分割算法库——detectron2、优秀的部署平台——onnxruntime等等 Mobile：移动端PyTorch实现方案及资源。 Blog：PyTorch相关新闻。 Tutorials：案例教程，这里面都是个人提供的、针对某一个应用的demo级的教程。包含如下方向，对于新手来说，可以看一下，了解个大概，但里面的代码多是demo，无法开箱即用于项目应用，这也是本书第二部分将会弥补的地方，敬请期待。 Docs：PyTorch API官方文档, 这也是我一直首推的学习资料，PyTorch的文档非常友好，可以查阅不同版本，各个API都有详细介绍，大多都有代码案例，PyTorch的基础部分主要从这里开始进行讲解。Docs下还会分PyTorch、torchvision、torchaudio、torchtext等，大家需要针对性的检索。 Resource：这里包含各种资源，如社区、新闻报道、论坛、ModelHub资源等等。 PyTorch发展趋势 为什么要学PyTorch？ 因为PyTorch发展迅猛，已经在多方面荣登深度学习框架第一的宝座，学术界绝大多数论文都有PyTorch实现，想要紧跟技术，利用新模型进行科学研究，进行项目开发的，不得不跟随学术界的趋势，所以可以看到PyTorch席卷各界。 PyTorch称王，TensorFlow答应么？一起来看看几个数据。 图1： 各大顶会期刊中，使用PyTorch的论文数量占PyTorch+TensorFlow的百分比。其实就是 p / (p+t)，这里有一个分界点就是50%，当达到50%时，说明PyTorch与TensorFlow平分秋色，当大于50%时说明PyTorch已经超过TF，而当数据超过75%，表明PyTorch已经是TF的两倍。从这个趋势可以发现转折点在2018-2019年之间发生，现在已经2021年末了，哪个框架是学术界的带头大哥？ 图2：这幅图对比的是PyTorch与TF的决定数量，可以看到TF的份额被PyTorch一步步蚕食，实线代表的PyTorch持续上扬，TF的虚线不断下探。 图片出自：https://horace.io/pytorch-vs-tensorflow/ 通过学术界的论文情况就可以说明PyTorch是未来的大势所趋，虽然说早期PyTorch在工业部署上并不如TensorFlow，但是如今PyTorch推出了libtorch，TorchServe，以及各类优秀的，适配性良好的部署框架层出不穷，如TensorRT、OpenVINO、ONNX等，都可以帮助PyTorch进行快速部署 感觉PyTorch是得学术界得天下，先让科研工作者用爽了，新模型都是PyTorch实现的，工业界的朋友总不能不用最新的算法、模型吧，只能纷纷转向PyTorch了。因此，相信大家选择使用PyTorch进行深度学习、机器学习模型开发，一定能加速你的算法模型开发，也印证了PyTorch的主旨——“An open source machine learning framework that accelerates the path from research prototyping to production deployment.” Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-1/1.2-Anaconda.html":{"url":"chapter-1/1.2-Anaconda.html","title":"1.2 环境配置之Anaconda","keywords":"","body":"1.2 环境配置之Anaconda 工欲善其事必先利其器，想要使用PyTorch进行模型开发，必须要搭建好开发环境。听到环境安装，是否大家已经瑟瑟发抖？是否都被某些不知名的报错卡住好几天，百度各种搜不到答案，各种文章的方案都不适用？ 为了解决大家环境安装的苦恼，本章将从Python虚拟环境、Anaconda、Pycharm、CUDA、CuDNN的背景说起，给大家构建系统的认识，理清各软件之间的关系，为大家呈现一个清晰的、完整的开发环境配置。 1.1节中提到过，PyTorch是基于Python为接口提供给用户使用，因此Python语言是我们的核心，PyTorch对于python只是一个工具包（library），通过import torch的方式使用而已。因此想要搭建完整的PyTorch开发环境，其实是搭建完整的Python开发环境，同时安装上PyTorch这个工具库。 虚拟环境 为了使用PyTorch，先搞定Python环境安装。提到Python环境，就不得不讲python虚拟环境（virtual environment）的概念了。python虚拟环境是为了解决众多的工具包之间版本冲突而设计的一个纯净开发环境，简单地，可创建多个虚拟环境，不同的环境中使用不同的工具包，例如虚拟环境1中安装pytorch 1.6， 虚拟环境2中安装的是pytorch0.4，当需要用老版本pytorch时，切换到虚拟环境2，然后调用虚拟环境2中的解释器——python.exe 运行你的.py代码。当需要用pytorch1.6时，就切换到虚拟环境1，调用虚拟环境1中的python.exe运行代码。这样就很好的解决工具包版本冲突问题。 解释器 这里提到一个概念，解释器——python.exe。 解释器就是人类与CPU之间的桥梁，人写的高级语言，如print(\"Hello World\")，CPU是读不懂的，CPU只能读0/1形式的二进制文件，这时就需要一个翻译官——python.exe， python.exe读取.py文件，解释成二进制文件，让CPU读懂，并运行。这就是解释器的作用，更直观的例子，python3的解释器是无法翻译python2语法的语句print \"Hello World\"的，因此不同的python.exe其实就对应了不同的环境。 Anaconda Anaconda是为方便使用python而建立的一个软件包，其包含常用的250多个工具包，多版本python解释器和强大的虚拟环境管理工具，所以Anaconda得名python全家桶。Anaconda可以使安装、运行和升级环境变得更简单，因此使用它作为Python虚拟环境管理工具。 安装非常简单，首先进入 anaconda官网，点击“Get Started\", 点击”download anaconda installers“，看到如下图所示的信息，选择你对应的操作系统下载，安装即可。 安装完毕，可以尝试创建一个你的虚拟环境，这里需要注意创建环境的时候就要决定pyhon的版本，而pytorch的安装对python的版本有要求，所以大家先到pytorch官网看看要装的pytorch版本所支持的python版本，然后再回来创建虚拟环境。这里演示pytorch最新版本1.10的安装。由于1.10是支持python3.6/3.7/3.9的（通过 1.1介绍过的神奇网站找到信息），在这里用python3.6作为python版本进行创建虚拟环境。 >>> conda create -n pytorch-1.10-gpu python=3.6 这里的pytorch-1.10-gpu就是虚拟环境的名称，激活（activate）时的标识，同时也会在anaconda安装目录下创建pytorch-1.10-gpu的文件夹，在该文件夹存放本环境所有工具包、解释器，如下图所示： 虚拟环境创建好之后，可以看看这个文件夹里都有些什么，先来看解释器： D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\python.exe ，大家可以双击它，就可以看到解释器的相关信息，后续用到pytorch_1.10_gpu这个环境的时候，也是用这个.exe进行运行.py文件，后面用pycharm运行代码的时候会给大家callback。 到此，一个纯净的虚拟环境就创建好了，接下来需要激活（activate）这个环境，然后再里面进行各种工具包的安装。这里先暂停一下，先去看另外一个工具——Pycharm的安装及使用。 anaconda常用命令 创建环境：conda create -n your_env_name python=X.X （X.X为python版本） eg: conda create -n pytorch_tutorial python=3.7 激活环境：source activate your_env_name eg: source activate pytorch_tutorial 退出环境：source deactivate 删除环境：conda remove -n your_env_name –all eg: conda remove -n pytorch_tutorial --all 查看已有虚拟环境：conda env list / conda info -e （推荐大家自行了解更多anaconda命令） 有了anaconda帮助我们管理虚拟环境以及python工具包，接下来就可以安装IDE，用来管理项目了。请看Pycharm安装 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-1/1.3-Pycharm.html":{"url":"chapter-1/1.3-Pycharm.html","title":"1.3 环境配置之Pycharm","keywords":"","body":"1.3 环境配置之Pycharm Pycharm——强大的python IDE Pycharm——强大的python IDE，拥有调试、语法高亮、Project管理、代码跳转、智能提示、版本控制等功能。有社区版和专业版区分，社区版为免费的，专业版需要付费，不过在校学生可通过edu邮箱进行注册，获取免费的专版使用。当然大家可以有其他方法完成购买。专业版相对于社区版功能更丰富一些，这里我采用的是pycharm.2019专业版，基础功能没有大的区别，用于演示还是OK的。 Pycharm的安装： 官网下载安装包 https://www.jetbrains.com/pycharm/ 运行pycharm-professional-2019.2.exe 选择路径，勾选Add launchers dir to the PATH，等待安装完成 激活部分：略。 这里主要讲如何创建项目，以及关联前面创建的虚拟环境pytorch_1.10_gpu。 打开pycharm，左上角的File可选择New，或者Open，如果已经有一个文件夹下有相关.py代码，那么就用Open对应的文件夹即可。这里假设已经存在pytorch-tutorial-2nd文件夹，找到它，Open即可。 我们找到pytorch-tutorial-2nd\\code\\chapter-1\\01-hello-pytorch.py，发现import torch下面有个红色波浪线，鼠标放上去会提示“No Module named torch\"，表明当前环境里并没有torch这个工具包。可好像我们并没有为当前.py文件设定好用哪个一解释器不是？所以我们先将当前项目pytorch-tutorial-2nd的虚拟环境设置为刚刚创建好的pytorch_1.10_gpu，然后再在pytorch_1.10_gpu里安装上pytorch即可。 左上角File--> Settings-->Project:pytorch-tutorial-2nd-->Project Interpreter， 然后如下图找到对应的python.exe，之后选中，点击OK,再次点击OK。就完成了虚拟环境与项目的关联，接着就可以安装pytorch了。 到这里，大家可以尝试运行 pytorch-tutorial-2nd\\code\\chapter-1\\01-hello-pytorch.py，会提示 D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\python.exe E:/pytorch-tutorial-2nd/code/chapter-1/01-hello-pytorch.py Traceback (most recent call last): File \"E:/pytorch-tutorial-2nd/code/chapter-1/01-hello-pytorch.py\", line 9, in import torch ModuleNotFoundError: No module named 'torch' Process finished with exit code 1 这里是完整的Pycharm控制台信息，我们可以看到第一行先是解释器（即对应了我们创建的虚拟环境），然后是执行的.py文件，接着是报错信息，提示没有torch这个module，下一小节我们来就来安装这个module。 pycharm拓展 pycharm是很好用的IDE，这里面提供很多快捷键，希望大家可以熟悉使用这些快捷键，例如常用的 批量注释：Ctrl + / 快速查看文档：Ctrl + q 搜索：Ctrl+f 运行：Shift + F10 Tab / Shift + Tab 缩进、不缩进当前行 Ctrl + D 复制选定的区域或行 Ctrl + Y 删除选定的行 更多功能推荐大家自行了解一下pycharm的基础使用，相信它一定是你的高效生产力。pycharm也有一些出名的教程，例如《pycharm 中文指南》pycharm中文指南。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-1/1.4-CUDA&cuDNN.html":{"url":"chapter-1/1.4-CUDA&cuDNN.html","title":"1.4 环境配置之CUDA&cuDNN","keywords":"","body":"1.4 环境配置之CUDA&cuDNN 有了python环境，有了开发环境，下面马上到主角登场。PyTorch登场前，针对GPU版，还需要额外安装一些东西。 从1.1我们知道PyTorch的安装可根据设备类型分为GPU版或CPU版。 CPU 对于CPU版本直接通过pip或者anaconda命令安装即可，如： >>> pip3 install torch torchvision torchaudio 具体的命令可查阅：https://pytorch.org/get-started/locally/ 官网上给出的命令其实安装了3个包，分别是torch, torchvision,torchaudio，这命令会根据当前系统自动选择对应python版本的whl进行安装，不需要用户操心。但，如果网速不好，或者需要离线安装，这时可以考虑下载whl包然后自行安装，下载whl的链接：https://download.pytorch.org/whl/torch/ pytorch与torchvision版本匹配 若是手动下载的whl，需要注意pytorch与torchvision之间版本对应关系，这个可以到torchvision Github查看，这点非常重要，CV中一些报错就是因为torchvision与pytorch版本不匹配导致的。这里就copy过来，大家参考好了。 torch torchvision python main / nightly main / nightly >=3.6, 1.10.0 0.11.1 >=3.6, 1.9.1 0.10.1 >=3.6, 1.9.0 0.10.0 >=3.6, 1.8.2 0.9.2 >=3.6, 1.8.1 0.9.1 >=3.6, 1.8.0 0.9.0 >=3.6, 1.7.1 0.8.2 >=3.6, 1.7.0 0.8.1 >=3.6, 1.7.0 0.8.0 >=3.6, 1.6.0 0.7.0 >=3.6, 1.5.1 0.6.1 >=3.5, 1.5.0 0.6.0 >=3.5, 1.4.0 0.5.0 ==2.7, >=3.5, 1.3.1 0.4.2 ==2.7, >=3.5, 1.3.0 0.4.1 ==2.7, >=3.5, 1.2.0 0.4.0 ==2.7, >=3.5, 1.1.0 0.3.0 ==2.7, >=3.5, 0.2.2 ==2.7, >=3.5, 举一反三，torchaudio、torchtext同理。 GPU版本 深度学习能火，正式因为有了强大的GPU支撑，自然地，绝大多数情况下我们会安装GPU版本的pytorch。目前PyTorch不仅支持NVIDIA的GPU，还支持AMD的ROMc的GPU。不过我们还是以N卡为例，毕竟N卡还是主流，A卡仍需努力。 对于N卡，什么型号是pytorch支持的呢？首先，需要计算能力（compute capability）≥3.0的GPU。很多地方都会看到计算能力≥3.0，理论出自哪呢？ 我在官方文档里找到了出处文档 It has a CUDA counterpart, that enables you to run your tensor computations on an NVIDIA GPU with compute capability >= 3.0 那么问题来了，怎么知道自己的GPU的copute capability呢？请看NVIDA文档,选择你对应的系列，找到对应型号。 举几个例子： GPU 计算能力 GeForce RTX 2080 7.5 GeForce RTX 2070 7.5 GeForce RTX 2060 7.5 GeForce GTX 1080 6.1 GeForce GTX 1070 6.1 GeForce GTX 1060 6.1 其实，只要是近几年购买的N卡都是没有问题的。确定了显卡是支持的，接下来就要决定一个非常重要事情，就是选中对应的CUDA版本进行安装。 CUDA ​ CUDA(ComputeUnified Device Architecture)，是NVIDIA推出的运算平台。 CUDA是一种由NVIDIA推出的通用并行计算架构，该架构使GPU能够解决复杂的计算问题。 与之配套的是cuDNN, NVIDIA cuDNN是用于深度神经网络的GPU加速库。它强调性能、易用性和低内存开销。NVIDIA cuDNN可以集成到更高级别的机器学习框架中。 细心的朋友在PyTorch官网就能发现， Compute Platform中并不给出显卡型号，而是给出CUDA版本，这就要求我们安装特定版本的CUDA，才能使用特定版本的PyTorch。例如PyTorch 1.10 只支持CUDA 10.2, CUDA 11.3，以及CUDA 11.1。为什么这里用了以及呢？ 因为在官网上并没有显示CUDA 11.1，但是在https://download.pytorch.org/whl/torch，搜索，可以看到11.1的whl。 在这里选择的是10.2版本进行安装，CUDA下载通过官网，官网通常只显示最新版本cuda，这里需要大家进入具体的版本下载界面，拖到底部，找到： Archive of Previous CUDA Releases 接着可以找到对应的CUDA版本，进入下载即可，这Installer Type 有 exe (network) 和 exe (local)两种选择，我们选local的方式，下载2.6G的cuda_10.2.89_441.22_win10.exe即可。 安装方式十分简单，一直下一步即可，只需要记住安装到了哪里，这里默认路径为 C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2 下面来测试一下CUDA安装是否成功，可以打开命令窗，进入C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2\\bin，然后输入 nvcc -V cuDNN 有了CUDA平台，还需要安装cuDNN，cuDNN全称为NVIDIA CUDA Deep Neural Network (cuDNN) 。它是一个深度神经网络的加速库，里边实现了神经网络常用的操作，并且是高度优化的，可以极大地榨干NVIDA显卡的性能，因此用N卡都会用cuDNN库。 cuDNN库的安装非常简单，与其说是安装，不如说是下载库文件，放到CUDA所在的目录下。具体步骤如下： 打开网址：https://developer.nvidia.com/cudnn，点击右上角，需要注册，再登录。 登录后，点击Download cuDNN，跳转到下载页面，选择好cudnn版本，操作系统版本，即可开始下载 将下载好的压缩包cudnn-10.2-windows10-x64-v8.2.4.15.zip 解压 分别将bin、include、lib\\x64下的文件分别对应拷贝到C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2文件夹下的bin、include、lib\\x64下 打开命令窗口，在C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2\\extras\\demo_suite文件夹中分别执行bandwidthTest.exe和deviceQuery.exe。观察到Result=PASS即可 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-1/1.5-PyTorch-install.html":{"url":"chapter-1/1.5-PyTorch-install.html","title":"1.5 环境配置之PyTorch系列包","keywords":"","body":"1.5 环境配置之PyTorch系列包 虚拟环境，Pycharm，CUDA，cuDNN均已准备好，现在终于可以安装PyTorch了，加油，就快成功啦。 现在，通过命令窗口，进入（激活）虚拟环境 E:\\pytorch-tutorial-2nd>conda activate pytorch_1.10_gpu (pytorch_1.10_gpu) E:\\pytorch-tutorial-2nd> 可通过以下命令安装 pip3 install torch==1.10.1+cu102 torchvision==0.11.2+cu102 torchaudio===0.10.1+cu102 -f https://download.pytorch.org/whl/cu102/torch_stable.html 可以看到通过pip安装，也是下载我们提到的神奇网站里的whl文件，这时大家可以根据自己的网速决定是采用pip还是自行下载的方法。 如果网速不好的话，推荐通过神奇的网站——https://download.pytorch.org/whl/torch 搜索对应的whl进行下载。然后pip install *.whl就行。 对于pip，建议大家添加镜像源。例如，清华镜像源或者中科大镜像源，这样安装python工具包的下载速度会快很多，请自行百度如何添加清华镜像源。 安装完毕，再回到pycharm，运行 pytorch-tutorial-2nd\\code\\chapter-1\\01-hello-pytorch.py，可以看到 D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\python.exe E:/pytorch-tutorial-2nd/code/chapter-1/01-hello-pytorch.py Hello World, Hello PyTorch 1.10.1+cu102 CUDA is available:True, version is 10.2 device_name: NVIDIA GeForce GTX 1660 Ti with Max-Q Design Process finished with exit code 0 表示pytorch环境安装完毕，此时我们也可以再次打开pycharm的解释器配置，可以看到当前的解释器（虚拟环境）下，拥有的相关工具包，这个界面也是后续大家检查当前环境工具包版本常用的工具，请收藏。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-1/1.6-JupyterNotebook-install.html":{"url":"chapter-1/1.6-JupyterNotebook-install.html","title":"1.6 环境配置之Jupyter Notebook","keywords":"","body":"1.6 环境配置之Jupyter Notebook 什么是 jupyter notebook 经过前几个小节，大家已经具备了PyTorch开发环境，但本教程需要照顾初学者使用代码，让刚入门的同学有更好的代码学习体验。因此，在上篇，主要采用Jupyter Notebook进行代码演示。 注意：\"Notebook只建议用于学习目的，不建议用于项目开发\" * 3， 重要事说三遍！ 为什么？这是由于notebook自身定位决定的，先来看看jupyter notebook 的定义“The Jupyter Notebook is a web application for creating and sharing documents that contain code, visualizations, and text. It can be used for data science, statistical modeling, machine learning, and much more.”——官网 Jupyter notebook 是一个网页应用，在这个网页上可以编写代码、做可视化、写文本，这就是非常好的教学展示平台。可以在上面进行概念描述、配上代码、运行结果，并且可以按小段进行代码运行，给用户更多的交互体验，便于用户理解代码细节。 基于此，上篇主要采用notebook进行代码讲解，到了中篇，基于完整的项目代码框架进行应用开发。 关于jupyter与jupyter notebook的关系，请大家查看官网（以下开始，notebook 指代 jupyter notebook） notebook 运行逻辑 notebook不是一个简单的web应用程序，它还需要关联指定的kernel，用于执行我们的代码。相信刚接触notebook的朋友大多都被notebook, kernel的概念搞的一头雾水。如果上述概念理不清楚，就更不清楚如何配置kernel，选择指定的虚拟环境了。 下面，我们先来看看notebook的结构 图片来自官网 图中左边是用户写的代码，传输到中间的Jupyter server, server本身不能执行代码（python.exe干的活，server是不会的），server把代码传给Kernel，Kernel才是真正干活，执行代码的地方。Kernel执行完代码，把结果返回给server，再返回到用户的网页。 从图中可以看出Kernel不仅可以是python.exe，也可以是其他语言的解释器，如Julia, R等，更多kernel可以看支持的kernel列表. 通过上述示意图我们就知道了，在pytorch开发中，kernel其实就是某一个python解释器——python.exe，我们需要让当前的notebook启用对应的kernel，来进入相应的虚拟环境，这样才能运行代码。 notebook 安装 理清概念，下面进行notebook安装，我们续期是正确调用pytorch_1.10_gpu这个虚拟环境来执行notebook上的代码。 安装过程分3步： 进入虚拟环境：conda activate pytorch_1.10_gpu 安装ipykernel工具包（安装jupyter）: pip install jupyter 添加kernel到notebook： python -m ipykernel install --user --name pytorch_1.10_gpu (意思是，将python这个kernel添加到jupyter的kernel中，由于当前已经在虚拟环境中，所以第一个python表示的含义是：D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\python.exe；而pytorch_1.10_gpu是kernel的别名，用于区分不同的kernel，这里建议与虚拟环境名称保持一致就好) 启动 在命令窗中执行jupyter notebook就可以打开web应用了，网址为:http://localhost:8888; 这里默认端口为8888，如果你再次启动一个jupyter notebook，可以看到端口号变为了8889，即它是另外一个web服务。 进入之后，我们可以看到有一个/目录，我们需要找到我们的notebook文件进行打开，这里有一个小技巧，就是进入到指定文件夹后，再运行notebook，这样notebook的路径就进入了想要的文件夹。 配置kernel 我们进入 chapter-1/02-notebook-demo.ipynb，点击run，可发现如下报错 --------------------------------------------------------------------------- ModuleNotFoundError Traceback (most recent call last) in 7 \"\"\" 8 ----> 9 import torch 10 11 print(\"Hello World, Hello PyTorch {}\".format(torch.__version__)) ModuleNotFoundError: No module named 'torch' 告诉我们找不到torch这个包，这很明显，使用的kernel不是我们的D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\python.exe。 下面我们来设置一下，方法很简单： 再次运行，可看到以下信息，表明notebook的环境就配置好了。 Hello World, Hello PyTorch 1.10.1+cu102 CUDA is available:True, version is 10.2 device_name: NVIDIA GeForce GTX 1660 Ti with Max-Q Design 实用插件——jupyter_contrib_nbextensions 原生的notebook还是缺点意思，这里推荐大家安装jupyter_contrib_nbextensions插件，jupyter_contrib_nbextensions提供了非常丰富的功能，例如代码折叠、分段折叠、代码自动补全、字体大小、行号显示、目录索引等等，详见下图 插件安装十分简单，打开命令窗，进入虚拟环境，分别依次执行 : pip install jupyter_contrib_nbextensions jupyter contrib nbextension install --user 然后重启notebook，就可以看到导航栏里有Nbextensions，大家可以根据自己的喜好进行调整，更多内容请查看Github Notebook 快速上手 notebook所使用的文件格式为.ipynb，jupyter会将.ipynb转为json进行保存，这样便于版本记录以及分享。 例如下图是用sublime打开的 02-notebook-demo.ipynb 下面，我们来研究notebook界面和常用的操作。 界面中需要认识的几个模块分别是：菜单栏、工具栏、单元格（cell） 菜单栏：用得最多的是Kernel，用于中断程序、重启解释器环境、切换解释器等；其它按键顾名思义。 工具栏：一些功能的按钮，高手都是用快捷键的。 单元格：这就是承载信息的地方，cell可分为code cells, markdown cells, raw cells。用得最多的是code cells和markdown cells。 右上角有一个小圆圈，用于观察当前kernel运行状态，如果是实心的，表明kernel正在运行某个cell，被运行的cell以及等待运行的cell的左边会有一个* notebook 的两种模式 Notebook中的单元，有两种模式：命令模式(Command Mode)与编辑模式(Edit Mode)，在不同模式下我们可以进行不同的操作。 命令模式：cell的边框为蓝色，此时可对cell进行操作。在编辑模式下，按esc键进入命令模式。 编辑模式：cell的边框为绿色，此时可在单元格内编辑代码或文档。在命令模式下，按enter或return键进入编辑模式。 常用快捷键 在命令模式下，按下“h”键，就会弹出快捷键的介绍，但是太多了，不方便初学者使用，这里总结一些常用的，实用的快捷键供大家参考。 命令模式： 插入单元格： A 键上方插入，B 键在下方插入 合并单元格：选中多个单元格，Shift + M 显示行号：L 删除单元格：连续按两次D 剪切单元格：X。 通常我用X代替删除，毕竟只用按一个键，哈哈。 复制粘贴单元格： C/V 撤销删除的单元格：要撤消已删除的单元格，请按 Z 键 编辑模式： 运行单元格：Ctrl + Enter 运行并创建新单元格：Alt + Enter 分割单元格：光标放到想要分割的地方，Ctrl + Shift + - 函数详情：Shift+Tab （注意，要把模块导入才会提示函数详情！） 请大家将以上快捷键都试用一遍，这些是高频快捷键，下面给大家列举所有快捷键，请收藏。 下面再介绍两个神奇操作，分别是在单元格中执行shell命令以及magic操作。 请自行尝试!+shell命令进行体会。 magic commands Magic关键字是 IPython 的高级用法，如%matplotlib将matplolib设置为交互式 %和%%分别代表 行Magic命令 和 单元格Magic命令 演示一个魔法命令 %%timeit %%timeit a = [] for i in range(10): a.append(i) 858 ns ± 50.3 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) 表示将代码段运行了100万次，并统计运行时间。 更多更全的magic commands请看这里Jupyter 魔术命令（magic commands） 更多奇淫技巧推荐大家看看Jupyter Notebook 有哪些奇技淫巧？ 更多官方信息请查看Jupyter Notebook docs Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-2/":{"url":"chapter-2/","title":"第二章 PyTorch 核心模块","keywords":"","body":"第二章 PyTorch 核心模块 上一章，对PyTorch的历史进行介绍，对开发环境的安装进行了详细的讲解。 本章将对PyTorch代码结构进行梳理，介绍核心模块，为后面应用PyTorch打下基础。 第二章 PyTorch 核心模块 2.1 PyTorch 模块结构 2.2 新冠肺炎分类 2.3 核心数据结构——Tensor 2.4 张量的相关函数 2.5 自动求导核心——计算图 2.6 Autograd——自动微分 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-2/2.1-module-tree.html":{"url":"chapter-2/2.1-module-tree.html","title":"2.1 PyTorch 模块结构","keywords":"","body":"2.1 PyTorch 模块结构 上一章安装好的PyTorch是一个庞大的python库，里边包含几十个模块，这一小节就来了解都有哪些模块，每个模块代码在哪里，对应文档在哪里。从而帮助大家具象化PyTorch，清楚地知道所用的PyTorch函数、模块都在哪里，是如何调用的。 你的代码在哪？ 很多朋友应该都用过pip/conda install 进行一键安装，但你的工具库代码装到哪里并不清楚。使用的时候也知道import *，但具体引用的功能函数又是如何实现的，是模糊的。 为了让大家知道自己调用的是什么，我们先来看你安装的pytorch在哪里。上一章案例中，我们装的pytorch在：D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\Lib\\site-packages\\torch 如果pycharm中配置好了虚拟环境，大家也可以通过pycharm的快捷键，快速定位到这个文件夹。方法是，找到import torch这一行代码，按住Ctrl键，鼠标左键单击torch，就可以跳转到D:\\Anacondadata\\envs\\pytorch1.10_gpu\\Lib\\site-packages\\torch__init.py 文件。 可以看到torch文件夹中有一系列子文件夹，我们平时常用的函数都藏在这里面了，下面挑些重点注意介绍。 _pycache_ 该文件夹存放python解释器生成的字节码，后缀通常为pyc/pyo。其目的是利用空间换时间，对应的模块直接读取pyc文件，而不需再次将.py语言转换为字节码的过程，从此节省了时间。 从文件夹名称可知，它是一个cache，缓存，如果需要，我们当然可以删掉它。更多关于pycache的内容，建议额外阅读：https://www.python.org/dev/peps/pep-3147/#proposal _C 从文件夹名称就知道它和C语言有关，其实它是辅助C语言代码调用的一个模块，该文件夹里存放了一系列pyi文件，pyi文件是python用来校验数据类型的，如果调用数据类型不规范，会报错。更多pyi知识，请查阅PEP 8 -->.pyi files that are read by the type checker in preference of the corresponding .py files. PyTorch的底层计算代码采用的是C++语言编写，并封装成库，供pytorch的python语言进行调用。这点非常重要，后续我们会发现一些pytorch函数无法跳转到具体实现，这是因为具体的实现通过C++语言，我们无法在Pycharm中跳转查看。 include 上面讲到pytorch许多底层运算用的是C++代码，那么C++代码在哪里呢？ 它们在这里,在torch/csrc文件夹下可以看到各个.h/.hpp文件，而在python库中，只包含头文件，这些头文件就在include文件夹下。 lib torch文件夹最重*3的一个模块，torch文件夹占3.2GB，98%的内容都在lib中，占了3.16GB。啥？装了那么大的pytorch，几乎都在lib里面了，倒要看看里面是什么宝贝。 lib文件夹下包含大量的.lib .dll文件（分别是静态链接库和动态链接库），例如大名鼎鼎的cudnn64_7.dll（占435MB）， torch_cuda.dll（940MB）。这些底层库都会被各类顶层python api调用。这里推荐大家自行了解什么是静态链接库和动态链接库。 autograd 该模块是pytorch的核心模块与概念，它实现了梯度的自动求导，极大地简化了深度学习研究者开发的工作量，开发人员只需编写前向传播代码，反向传播部分由autograd自动实现，再也不用手动去推导数学公式，然后编写代码了（很多朋友可能不知道，在早期的深度学习框架中是没有这个功能的，例如caffe，它需要手动编写反向传播的公式代码） nn 相信这个模块是99%pytorch开发者使用频率最高的模块，搭建网络的网络层就在nn.modules里边。nn.modules也将作为一章独立展开。我们可以到D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\Lib\\site-packages\\torch\\nn\\modules里面看看是否有你熟悉的网络层？ onnx pytorch模型转换到onnx模型表示的核心模块，进入文件夹可以看到大量的opset**.py， 这里留下一个问题，各版本opset是什么意思？有什么区别？ optim 优化模块，深度学习的学习过程，就是不断的优化，而优化使用的方法函数，都暗藏在了optim文件夹中，进入该文件夹，可以看到熟悉的优化方法：adam、sgd、asgd等。以及非常重要的学习率调整模块：lr_scheduler.py。本模块也将采用独立一章进行详细剖析。 utils utils是各种软件工程中常见的文件夹，其中包含的是各类常用工具，其中比较关键的是data文件夹，tensorboard文件夹，这些都将在后续章节详细展开。第三章将展开data里的dataloader与dataset等数据读取相关的模块。 其他文件夹不再一一介绍，大家可以到官方文档查看。 以上是torch库，针对不同的应用方向，pytorch还提供了torchvision\\torchtext\\torchaudio等模块，本书重点对torchvision进行剖析，其它两个模块类似。 torchvision 同理，我们来到D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\Lib\\site-packages\\torchvision文件夹下看看有什么模块。 datasets 这里是官方为常用的数据集写的数据读取函数，例如常见的cifar, coco, mnist,svhn,voc都是有对应的函数支持，可以愉快的调用轮子，同时也可以学习大牛们是如何写dataset的。 models 这里是宝藏库，里边存放了经典的、可复现的、有训练权重参数可下载的视觉模型，例如分类的alexnet、densenet、efficientnet、mobilenet-v1/2/3、resnet等，分割模型、检测模型、视频任务模型、量化模型。这个库里边的模型实现，也是大家可以借鉴学习的好资料，可以模仿它们的代码结构，函数、类的组织。 ops 视觉任务特殊的功能函数，例如检测中用到的 roi_align, roi_pool，boxes的生成，以及focal_loss实现，都在这里边有实现。 transforms 数据增强库，相信99%的初学者用到的第一个视觉数据增强库就是transforms了，transforms是pytorch自带的图像预处理、增强、转换工具，可以满足日常的需求。但无法满足各类复杂场景，因此后续会介绍更强大的、更通用的、使用人数更多的数据增强库——Albumentations。 通过torchvision\\transforms\\transforms.py , 可以看到 torchvision包含了这些功能。 __all__ = [\"Compose\", \"ToTensor\", \"PILToTensor\", \"ConvertImageDtype\", \"ToPILImage\", \"Normalize\", \"Resize\", \"Scale\", \"CenterCrop\", \"Pad\", \"Lambda\", \"RandomApply\", \"RandomChoice\", \"RandomOrder\", \"RandomCrop\", \"RandomHorizontalFlip\", \"RandomVerticalFlip\", \"RandomResizedCrop\", \"RandomSizedCrop\", \"FiveCrop\", \"TenCrop\", \"LinearTransformation\", \"ColorJitter\", \"RandomRotation\", \"RandomAffine\", \"Grayscale\", \"RandomGrayscale\", \"RandomPerspective\", \"RandomErasing\", \"GaussianBlur\", \"InterpolationMode\", \"RandomInvert\", \"RandomPosterize\", \"RandomSolarize\", \"RandomAdjustSharpness\", \"RandomAutocontrast\", \"RandomEqualize\"] 通过上面的内容，相信大家对所安装的代码结构有了清晰认识，也知道自己将调用的代码函数都在哪里，已经为下一步工作打好基础，下一节我们极简的代码，完成第一个深度学习任务—— 新冠肺炎X光分类 。其目的在于为大家搭建模型训练框架，构建各模块的认识，为后续核心模块讲解铺平道路。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-2/2.2-covid-19-cls.html":{"url":"chapter-2/2.2-covid-19-cls.html","title":"2.2 新冠肺炎分类","keywords":"","body":"2.2 新冠肺炎X光分类 上一节，我们学习了pytorch python API的结构，本节将以一个具体的案例介绍pytorch模型训练流程，并提出一系列问题，供大家思考。当然，这些问题也是本书后续章节一一解答的内容。 相信绝大多数朋友接触过或者看到的第一个Hello Word级图像分类都是Mnist，思来想去觉得还是换点东西，于是选择了当下与所有人都息息相关的案例——新型冠状病毒肺炎（Corona Virus Disease 2019，COVID-19），简称“新冠肺炎”。关于新冠的背景，已经无需多言，口罩、绿码、核酸检测已经融入了我们的生活。因此，想让大家更进一步的了解COVID-19，所以选用此案例。当然，最重要的目的是要了解pytorch如何完成模型训练。 案例背景 2020年1月底2月初的时候，新冠在国内/外大流行。而确定一个人是否感染新冠肺炎，是尤为重要的事情。新冠肺炎的确诊需要通过核酸检测完成，但是核酸检测并不是那么容易完成的，需要医护人员采样、送检、PCR仪器上机、出结果、发报告等一系列复杂工序，核酸检测产能完全达不到当时的检测需求。当时，就有医生提出，是否可以采用特殊方法进行诊断，例如通过CT、X光的方法，给病人拍个片，几分钟就能看出结果，比核酸检测快了不少。于是，新冠肺炎患者的胸片X光数据就不断的被收集，并发布到网上供全球科学家使用，共同抗击新冠疫情。这里就采用了https://github.com/ieee8023/covid-chestxray-dataset上的数据，同时采用了正常人的X光片，来自于：https://github.com/zoogzog/chexnet。 由于本案例目的是pytorch流程学习，因此数据仅选择了4张，分为2类，正常与新冠，训练集2张，验证集2张。标签信息存储于txt文件中。具体目录结构如下： ├─imgs │ ├─covid-19 │ │ auntminnie-a-2020_01_28_23_51_6665_2020_01_28_Vietnam_coronavirus.jpeg │ │ ryct.2020200028.fig1a.jpeg │ │ │ └─no-finding │ 00001215_000.png │ 00001215_001.png │ └─labels train.txt valid.txt 建模思路 这是一个典型的图像分类任务，这里采用面向过程的思路给大家介绍如何进行代码编写。 step 1 数据 首先，需要编写代码完成数据的读取，变成模型能够读取的格式。这里涉及pytorch的dataset，dataloader，transforms等模块。以及需要清楚地知道pytorch的模型需要怎样的格式？数据模块需要完整的工作大体如下图所示： 首先，需要将数据在硬盘上的信息，如路径，标签读取并存储起来，然后被使用，这一步骤主要是通过COVID19Dataset这个类。类里有四个函数，除了Dataset类必须要实现的三个外，我们通过get_img_info函数实现读取硬盘中的路径、标签等信息，并存储到一个列表中。后续大家可以根据不同的任务情况在这个函数中修改，只要能获取到数据的信息，供\\_getitem__函数进行读取。 接着，使用dataloader进行封装，dataloader是一个数据加载器，提供诸多方法进行数据的获取，如设置一个batch获取几个样本，采用几个进程进行数据读取，是否对数据进行打乱等功能。 其次，还需要设置对图像进行预处理(Preprocess)的操作，这里为了演示，仅采用resize 和 totensor两个方法，并且图片只需要缩放到8*8的大小，并不需要224,256,448,512,1024等大尺寸。(totensor与下一小节内容强相关) step 2 模型 数据模块构建完毕，需要扔到模型里，因此我们需要构建神经网络模型，模型接收数据并前向传播处理，输出二分类概率向量。这时就需要用到nn.Module模块和nn下的各个网络层进行搭建模型，模型的搭建就像搭积木，一层一层的摞起来。模型完成的任务就如下图所示：下图示意图是一张分辨率为4*4的图像输入到模型中，模型经过运算，输出二分类概率。中间的“?\"是什么内容呢？ 这里，“？”是构建一个极其简单的卷积神经网络，仅仅包含两个网络层，第一个层是包含1个33卷积核的2d卷积，第二个层是两个神经元的全连接层（pytorch也叫linear层）。模型的输入被限制在了8\\8，原因在于linear层设置了输入神经元个数为36， 8*8与36之间是息息相关的，他们之间的关系是为何呢？这需要大家对卷积层有一定了解了。（大家可以改一下36，改为35，或者transforms_func中的resize改为9*9，看看会报什么错，这些错或许是大家今后经常会遇到的） step3 优化 模型可以完成前向传播之后，根据什么规则对模型的参数进行更新学习呢？这就需要损失函数和优化器的搭配了，损失函数用于衡量模型输出与标签之间的差异，并通过反向传播获得每个参数的梯度，有了梯度，就可以用优化器对权重进行更新。这里就要涉及各种LossFunction和optim中的优化器，以及学习率调整模块optim.lr_scheduler。 这里，采用的都是常用的方法：交叉熵损失函数（CrossEntropyLoss）、随机梯度下降法（SGD）和按固定步长下降学习率策略（StepLR）。 step4 迭代 有了模型参数更新的必备组件，接下来需要一遍又一遍的给模型喂数据，并且监控模型训练状态，这时候就需要for循环登场，不断的从dataloader里取出数据进行前向传播，反向传播，参数更新，观察loss、acc，周而复始。当达到满足的条件，如最大迭代次数、某指标达到某个值时，进行模型保存，并break循环，停止训练。 以上就是一个经典的面向过程式的代码编写，先考虑数据怎么读进来，读进来之后喂给的模型如何搭建，模型如何更新，模型如何迭代训练到满意。请大家结合代码一步一步的观察整体过程。 在经过几十个epoch的训练之后达到了100%，模型可以成功区分从未见过的两张图片：auntminnie-a-2020_01_28_23_51_6665_2020_01_28_Vietnam_coronavirus.jpeg，00001215_000.png。 由于数据量少，随机性非常大，大家多运行几次，观察结果。不过本案例结果完全不重要！），可以看到模型的准确率（Accuracy）变化。 一系列问题 通过上述步骤及代码，虽然完成了一个图像分类任务，但其中很多细节想必大家还是弄不清楚，例如： 图像数据是哪用一行代码读取进来的？ transforms.Compose是如何工作对图像数据进行转换的？ ToTensor又有哪些操作？ 自己如何编写Dataset？ DataLoader有什么功能？如何使用？有什么需要注意的？ 模型如何按自己的数据流程搭建？ nn有哪些网络层可以调用？ 损失函数有哪些？ 优化器是如何更新model参数的？ 学习率调整有哪些方法？如何设置它们的参数？ model.train()与model.eval()作用是什么？ optimizer.zero_grad()是做什么？为什么要梯度清零？ scheduler.step() 作用是什么？应该放在哪个for循环里？ 等等 如果大家能有以上的问题提出，本小节的目的就达到了。大家有了模型训练的思路，对过程有了解，但是使用细节还需进一步学习，更多pytorch基础内容将会在后续章节一一解答。 下一小节我们将介绍流动在pytorch各个模块中的基础数据结构——Tensor（张量）。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-2/2.3-datastruct-tensor.html":{"url":"chapter-2/2.3-datastruct-tensor.html","title":"2.3 核心数据结构——Tensor","keywords":"","body":"2.3 核心数据结构——Tensor 张量初认识 经过前两小节的铺垫，大家一定对pytorch有了初步认识，本小节就展开讲pytorch的核心数据结构——Tensor（张量）。Tensor中文翻译张量，是一个词不达意的名字。张量在不同学科中有不同的意义，在深度学习中张量表示的是一个多维数组，它是标量、向量、矩阵的拓展。标量是零维张量，向量是一维张量，矩阵是二维张量，一个RGB图像数组就是一个三维张量，第一维是图像高，第二维是图像的宽，第三维是图像颜色通道。 在pytorch中，有两个张量的相关概念极其容易混淆，分别是torch.Tensor和torch.tensor。其实，通过命名规范，可知道torch.Tensor是一个类, torch.tensor是一个函数。通常我们调用torch.tensor进行创建张量，而不直接调用torch.Tensor类进行创建。为了进一步区分两者，我们来看看它们代码实现。 torch.Tensor：类定义与torch/_tensor.py#L80，它继承torch._C._TensorBase，这里看到_C就知道要接触C++代码了。 跳转到torch/C/\\_init__.pyi #L839 可以看到： # Defined in torch/csrc/autograd/python_variable.cpp class _TensorBase(metaclass=_TensorMeta): requires_grad: _bool shape: Size 张量类的底层实现是在python_variable.cpp代码中，感兴趣的朋友可以进一步探究。 torch.tensor：pytorch的一个函数，用于将数据变为张量形式的数据，例如list, tuple, NumPy ndarray, scalar等。同样的，它的底层实现也是C++代码，我们可以跳转到函数定义，发现是torch_C_VariableFunctions.pyi文件（2.1节中介绍了.pyi文件是用于pyi文件是python用来校验数据类型的，其底层实现在对应的cpp代码中。 后续将不再区分Tensor和tensor，主要用小写tensor表示张量这个数据类型（数据结构）。 张量的作用 tensor之于pytorch等同于ndarray之于numpy，它是pytorch中最核心的数据结构，用于表达各类数据，如输入数据、模型的参数、模型的特征图、模型的输出等。这里边有一个很重要的数据，就是模型的参数。对于模型的参数，我们需要它进行更新，而更新是需要记录它的梯度，梯度的记录功能正是被张量所实现的（求梯度是autograd实现的）。 张量的历史演变 讲tensor结构之前，还需要介绍一小段历史，那就是Variable与Tensor。在0.4.0版本之前，Tensor需要经过Variable的包装才能实现自动求导。从0.4.0版本开始，torch.Tensor与torch.autograd.Variable合并，torch.Tensor拥有了跟踪历史操作的功能。虽然Variable仍可用，但Variable返回值已经是一个Tensor（原来返回值是Variable），所以今后无需再用Variable包装Tensor。 虽然Variable的概念已经被摒弃，但是了解其数据结构对理解Tensor还是有帮助的。Variable不仅能对Tensor的包装，而且能记录生成Tensor的运算（这是自动求导的关键）。在Variable对象中主要包含5个属性：data，grad，grad_fn，is_leaf，requires_grad data: 保存的是具体数据，即被包装的Tensor； grad: data对应的梯度，形状与data一致； grad_fn: 记录创建该Tensor时用到的Function，该Function在反向传播计算中使用，因此是自动求导的关键； requires_grad: 用来指示是否需要梯度； is_leaf: 用来指示是否是叶子结点，为叶子结点时，反向传播结束，其梯度仍会保存，非叶子结点的梯度被释放，以节省内存。 从Variable的主要属性中可以发现，除了data外，grad，grad_fn，is_leaf和requires_grad都是为计算梯度服务，所以Variable在torch.autogard包中自然不难理解。 但是我们的数据载体是tensor，每次需要自动求导，都要用Variable包装，这明显太过繁琐，于是PyTorch从0.4.0版将torch.Tensor与torch.autograd.Variable合并。 张量的结构 tensor是一个类，我们先来认识它有哪些属性，再去观察它有哪些方法函数可使用。 Tensor主要有以下八个主要属性，data，dtype，shape，device，grad，grad_fn，is_leaf，requires_grad。 data：多维数组，最核心的属性，其它属性都是为其服务的; dtype：多维数组的数据类型，tensor数据类型如下，常用到的三种已经用红框标注出来； shape：多维数组的形状; device: tensor所在的设备，cpu或cuda; grad，grad_fn，is_leaf和requires_grad就与Variable一样，都是梯度计算中所用到的。 张量的属性还有很多，大家可以通过Pycharm的debug功能进行查看 更多关于张量的概念背景，请查看官方文档，下一小节，我们进行张量的操作介绍。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-2/2.4-method-tensor.html":{"url":"chapter-2/2.4-method-tensor.html","title":"2.4 张量的相关函数","keywords":"","body":"2.4 张量的相关函数 接下来开始学习各类张量的api，主要参考官方文档，通过右边目录栏可以看出有以下几个部分。 torchTensors Generators Random sampling Serialization Parallelism Locally disabling gradient computation Math operations Utilities 里面有上百个函数，这里只挑高频使用的进行讲解，建议大家自行浏览一遍官方文档，看看都有哪些功能，便于今后使用到的时候不必重复造轮子。 张量的创建 直接创建 torch.tensor torch.tensor(data, dtype=None, device=None, requires_grad=False, pin_memory=False) data(array_like) - tensor的初始数据，可以是list, tuple, numpy array, scalar或其他类型。 dtype(torch.dtype, optional) - tensor的数据类型，如torch.uint8, torch.float, torch.long等 device (torch.device, optional) – 决定tensor位于cpu还是gpu。如果为None，将会采用默认值，默认值在torch.set_default_tensor_type()中设置，默认为 cpu。 requires_grad (bool, optional) – 决定是否需要计算梯度。 pin_memory (bool, optional) – 是否将tensor存于锁页内存。这与内存的存在方式有关，通常为False。 import torch import numpy as np l = [[1., -1.], [1., -1.]] t_from_list = torch.tensor(l) arr = np.array([[1, 2, 3], [4, 5, 6]]) t_from_array = torch.tensor(arr) print(t_from_list, t_from_list.dtype) print(t_from_array, t_from_array.dtype) tensor([[ 1., -1.], ​ [ 1., -1.]]) torch.float32 tensor([[1, 2, 3], ​ [4, 5, 6]]) torch.int64 可以看到t_from_list是float32类型，而t_from_array是int64类型。如果想让tensor是其他数据类型，可以在创建tensor时使用dytpe参数确定数据类型。 import torch import numpy as np arr = np.array([[1, 2, 3], [4, 5, 6]]) t_from_array = torch.tensor(arr, dtype=torch.uint8) print(t_from_array) tensor([[1, 2, 3], ​ [4, 5, 6]], dtype=torch.uint8) torch.from_numpy 还有一种常用的通过numpy创建tensor方法是torch.from_numpy()。这里需要特别注意的是，创建的tensor和原array共享同一块内存（The returned tensor and ndarray share the same memory. ），即当改变array里的数值，tensor中的数值也会被改变。 import torch import numpy as np arr = np.array([[1, 2, 3], [4, 5, 6]]) t_from_numpy = torch.from_numpy(arr) print(\"numpy array: \", arr) print(\"tensor : \", t_from_numpy) print(\"\\n修改arr\") arr[0, 0] = 0 print(\"numpy array: \", arr) print(\"tensor : \", t_from_numpy) print(\"\\n修改tensor\") t_from_numpy[0, 0] = -1 print(\"numpy array: \", arr) print(\"tensor : \", t_from_numpy) > > numpy array: [[1 2 3] [4 5 6]] tensor : tensor([[1, 2, 3], ​ [4, 5, 6]]) 修改arr numpy array: [[0 2 3] [4 5 6]] tensor : tensor([[0, 2, 3], ​ [4, 5, 6]]) 修改tensor numpy array: [[-1 2 3] [ 4 5 6]] tensor : tensor([[-1, 2, 3], ​ [ 4, 5, 6]]) 可以看到虽然只改变了arr的值，但是tensor中的data也被改变了，这一点在使用过程中需要注意。 依数值创建 torch.zeros torch.zeros(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) 功能：依给定的size创建一个全0的tensor，默认数据类型为torch.float32（也称为torch.float）。 主要参数： layout(torch.layout, optional) - 参数表明张量在内存中采用何种布局方式。常用的有torch.strided, torch.sparse_coo等。 out(tensor, optional) - 输出的tensor，即该函数返回的tensor可以通过out进行赋值，请看例子。 example: import torch o_t = torch.tensor([1]) t = torch.zeros((3, 3), out=o_t) print(t, '\\n', o_t) print(id(t), id(o_t)) > > tensor([[0, 0, 0], ​ [0, 0, 0], ​ [0, 0, 0]]) tensor([[0, 0, 0], ​ [0, 0, 0], ​ [0, 0, 0]]) 4925603056 4925603056 可以看到，通过torch.zeros创建的张量不仅赋给了t，同时赋给了o_t，并且这两个张量是共享同一块内存，只是变量名不同。 torch.zeros_like torch.zeros_like(input, dtype=None, layout=None, device=None, requires_grad=False) 功能：依input的size创建全0的tensor。 主要参数： input(Tensor) - 创建的tensor与intput具有相同的形状。 example: import torch t1 = torch.tensor([[1., -1.], [1., -1.]]) t2 = torch.zeros_like(t1) print(t2) tensor([[0., 0.], ​ [0., 0.]]) 除了创建全0还有创建全1的tensor，使用方法是一样的，这里就不赘述。 torch.ones(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) 功能：依给定的size创建一个全1的tensor。 torch.ones_like(input, dtype=None, layout=None, device=None, requires_grad=False) 功能：依input的size创建全1的tensor。 torch.full(size, fill_value, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) 功能：依给定的size创建一个值全为fill_value的tensor。 主要参数: siz (int...) - tensor的形状。 fill_value - 所创建tensor的值 out(tensor, optional) - 输出的tensor，即该函数返回的tensor可以通过out进行赋值。 example: import torch print(torch.full((2, 3), 3.141592)) torch.full_like(input, fill_value, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) torch.full_like之于torch.full等同于torch.zeros_like之于torch.zeros，因此不再赘述。 torch.arange(start=0, end, step=1, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) 功能：创建等差的1维张量，长度为 (end-start)/step，需要注意数值区间为[start, end)。 主要参数： start (Number) – 数列起始值，默认值为0。the starting value for the set of points. Default: 0. end (Number) – 数列的结束值。 step (Number) – 数列的等差值，默认值为1。 out (Tensor, optional) – 输出的tensor，即该函数返回的tensor可以通过out进行赋值。 example: imort torch print(torch.arange(1, 2.51, 0.5)) torch.range()函数就不推荐及介绍了，因为官网说了“This function is deprecated in favor of torch.arange().” torch.linspace(start, end, steps=100, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) 功能：创建均分的1维张量，长度为steps，区间为[start, end]。 主要参数： start (float) – 数列起始值。 end (float) – 数列结束值。 steps (int) – 数列长度。 example: print(torch.linspace(3, 10, steps=5)) print(torch.linspace(1, 5, steps=3)) torch.logspace(start, end, steps=100, base=10.0, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) 功能：创建对数均分的1维张量，长度为steps, 底为base。 主要参数： start (float) – 确定数列起始值为base^start end (float) – 确定数列结束值为base^end steps (int) – 数列长度。 base (float) - 对数函数的底，默认值为10，此参数是在pytorch 1.0.1版本之后加入的。 example: torch.logspace(start=0.1, end=1.0, steps=5) torch.logspace(start=2, end=2, steps=1, base=2) torch.eye(n, m=None, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)** 功能：创建单位对角矩阵。 主要参数： n (int) - 矩阵的行数 m (int, optional) - 矩阵的列数，默认值为n，即默认创建一个方阵 example: import torch print(torch.eye(3)) print(torch.eye(3, 4)) torch.empty(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False, pin_memory=False) 功能：依size创建“空”张量，这里的“空”指的是不会进行初始化赋值操作。 主要参数： size (int...) - 张量维度 pin_memory (bool, optional) - pinned memory 又称page locked memory，即锁页内存，该参数用来指示是否将tensor存于锁页内存，通常为False，若内存足够大，建议设置为Ture，这样在转到GPU时会快一些。 torch.empty_like(input, dtype=None, layout=None, device=None, requires_grad=False) 功能：torch.empty_like之于torch.empty等同于torch.zeros_like之于torch.zeros，因此不再赘述。 torch.empty_strided(size, stride, dtype=None, layout=None, device=None, requires_grad=False, pin_memory=False) 功能：依size创建“空”张量，这里的“空”指的是不会进行初始化赋值操作。 主要参数： stride (tuple of python:ints) - 张量存储在内存中的步长，是设置在内存中的存储方式。 size (int...) - 张量维度 pin_memory (bool, optional) - 是否存于锁页内存。 依概率分布创建 torch.normal(mean, std, out=None) 功能：为每一个元素以给定的mean和std用高斯分布生成随机数 主要参数： mean (Tensor or Float) - 高斯分布的均值， std (Tensor or Float) - 高斯分布的标准差 特别注意事项： mean和std的取值分别有2种，共4种组合，不同组合产生的效果也不同，需要注意 mean为张量，std为张量，torch.normal(mean, std, out=None)，每个元素从不同的高斯分布采样，分布的均值和标准差由mean和std对应位置元素的值确定； mean为张量，std为标量，torch.normal(mean, std=1.0, out=None)，每个元素采用相同的标准差，不同的均值； mean为标量，std为张量，torch.normal(mean=0.0, std, out=None)， 每个元素采用相同均值，不同标准差； mean为标量，std为标量，torch.normal(mean, std, size, *, out=None) ，从一个高斯分布中生成大小为size的张量； example1 import mean = torch.arange(1, 11.) std = torch.arange(1, 0, -0.1) normal = torch.normal(mean=mean, std=std) print(\"mean: {}, \\nstd: {}, \\nnormal: {}\".format(mean, std, normal)) mean: tensor([ 1., 2., 3., 4., 5., 6., 7., 8., 9., 10.]), std: tensor([1.0000, 0.9000, 0.8000, 0.7000, 0.6000, 0.5000, 0.4000, 0.3000, 0.2000, ​ 0.1000]), normal: tensor([ 1.3530, -1.3498, 3.0021, 5.1200, 3.9818, 5.0163, 6.9272, 8.1171, ​ 9.0623, 10.0621]) 1.3530是通过均值为1，标准差为1的高斯分布采样得来， -1.3498是通过均值为2，标准差为0.9的高斯分布采样得来，以此类推 torch.rand(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) 功能：在区间[0, 1)上，生成均匀分布。 主要参数： size (int...) - 创建的张量的形状 torch.rand_like(input, dtype=None, layout=None, device=None, requires_grad=False) torch.rand_like之于torch.rand等同于torch.zeros_like之于torch.zeros，因此不再赘述。 torch.randint(low=0, high, size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) 功能：在区间[low, high)上，生成整数的均匀分布。 主要参数： low (int, optional) - 下限。 high (int) – 上限，主要是开区间。 size (tuple) – 张量的形状。 example print(torch.randint(3, 10, (2, 2))) torch.randint_like(input, low=0, high, dtype=None, layout=torch.strided, device=None, requires_grad=False) 功能：torch.randint_like之于torch.randint等同于torch.zeros_like之于torch.zeros，因此不再赘述。 torch.randn(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) 功能：生成形状为size的标准正态分布张量。 主要参数： size (int...) - 张量的形状 torch.randn_like(input, dtype=None, layout=None, device=None, requires_grad=False) 功能：torch.rafndn_like之于torch_randn等同于torch.zeros_like之于torch.zeros，因此不再赘述。 torch.randperm(n, out=None, dtype=torch.int64, layout=torch.strided, device=None, requires_grad=False) 功能：生成从0到n-1的随机排列。perm == permutation torch.bernoulli(input, *, generator=None, out=None) 功能：以input的值为概率，生成伯努力分布（0-1分布，两点分布）。 主要参数： input (Tensor) - 分布的概率值，该张量中的每个值的值域为[0-1] example: import torch p = torch.empty(3, 3).uniform_(0, 1) b = torch.bernoulli(p) print(\"probability: \\n{}, \\nbernoulli_tensor:\\n{}\".format(p, b)) probability: tensor([[0.7566, 0.2899, 0.4688], ​ [0.1662, 0.8341, 0.9572], ​ [0.6060, 0.4685, 0.6366]]), bernoulli_tensor: tensor([[0., 0., 1.], ​ [1., 1., 1.], ​ [1., 1., 1.]]) 张量的操作 熟悉numpy的朋友应该知道，Tensor与numpy的数据结构很类似，不仅数据结构类似，操作也是类似的，接下来介绍Tensor的常用操作。由于操作函数很多，这里就不一一举例，仅通过表格说明各个函数作用，详细介绍可查看官方文档 cat 将多个张量拼接在一起，例如多个特征图的融合可用。 concat 同cat, 是cat()的别名。 conj 返回共轭复数。 chunk 将tensor在某个维度上分成n份。 dsplit 类似numpy.dsplit().， 将张量按索引或指定的份数进行切分。 column_stack 水平堆叠张量。即第二个维度上增加，等同于torch.hstack。 dstack 沿第三个轴进行逐像素（depthwise）拼接。 gather 高级索引方法，目标检测中常用于索引bbox。在指定的轴上，根据给定的index进行索引。强烈推荐看example。 hsplit 类似numpy.hsplit()，将张量按列进行切分。若传入整数，则按等分划分。若传入list，则按list中元素进行索引。例如：[2, 3] and dim=0 would result in the tensors input[:2], input[2:3], and input[3:]. hstack 水平堆叠张量。即第二个维度上增加，等同于torch.column_stack。 index_select 在指定的维度上，按索引进行选择数据，然后拼接成新张量。可知道，新张量的指定维度上长度是index的长度。 masked_select 根据mask（0/1, False/True 形式的mask）索引数据，返回1-D张量。 movedim 移动轴。如0，1轴交换：torch.movedim(t, 1, 0) . moveaxis 同movedim。Alias for torch.movedim().（这里发现pytorch很多地方会将dim和axis混用，概念都是一样的。） narrow 变窄的张量？从功能看还是索引。在指定轴上，设置起始和长度进行索引。例如：torch.narrow(x, 0, 0, 2)， 从第0个轴上的第0元素开始，索引2个元素。x[0:0+2, ...] nonzero 返回非零元素的index。torch.nonzero(torch.tensor([1, 1, 1, 0, 1])) 返回tensor([[ 0], [ 1], [ 2], [ 4]])。建议看example，一看就明白，尤其是对角线矩阵的那个例子，太清晰了。 permute 交换轴。 reshape 变换形状。 row_stack 按行堆叠张量。即第一个维度上增加，等同于torch.vstack。Alias of torch.vstack(). scatter scatter_(dim, index, src, reduce=None) → Tensor。将src中数据根据index中的索引按照dim的方向填进input中。这是一个十分难理解的函数，其中index是告诉你哪些位置需要变，src是告诉你要变的值是什么。这个就必须配合例子讲解，请跳转到本节底部进行学习。 scatter_add 同scatter一样，对input进行元素修改，这里是 +=， 而scatter是直接替换。 split 按给定的大小切分出多个张量。例如：torch.split(a, [1,4])； torch.split(a, 2) squeeze 移除张量为1的轴。如t.shape=[1, 3, 224, 224]. t.squeeze().shape -> [3, 224, 224] stack 在新的轴上拼接张量。与hstack\\vstack不同，它是新增一个轴。默认从第0个轴插入新轴。 swapaxes Alias for torch.transpose().交换轴。 swapdims Alias for torch.transpose().交换轴。 t 转置。 take 取张量中的某些元素，返回的是1D张量。torch.take(src, torch.tensor([0, 2, 5]))表示取第0,2,5个元素。 take_along_dim 取张量中的某些元素，返回的张量与index维度保持一致。可搭配torch.argmax(t)和torch.argsort使用，用于对最大概率所在位置取值，或进行排序，详见官方文档的example。 tensor_split 切分张量，核心看indices_or_sections变量如何设置。 tile 将张量重复X遍，X遍表示可按多个维度进行重复。例如：torch.tile(y, (2, 2)) transpose 交换轴。 unbind 移除张量的某个轴，并返回一串张量。如[[1], [2], [3]] --> [1], [2], [3] 。把行这个轴拆了。 unsqueeze 增加一个轴，常用于匹配数据维度。 vsplit 垂直切分。 vstack 垂直堆叠。 where 根据一个是非条件，选择x的元素还是y的元素，拼接成新张量。看案例可瞬间明白。 scater_ scater是将input张量中的部分值进行替换。公式如下： self[index[i][j][k]][j][k] = src[i][j][k] # if dim == 0 self[i][index[i][j][k]][k] = src[i][j][k] # if dim == 1 self[i][j][index[i][j][k]] = src[i][j][k] # if dim == 2 设计两个核心问题： input哪个位置需要替换？ 替换成什么？ 答： 从公式可知道，依次从index中找到元素放到dim的位置，就是input需要变的地方。 变成什么呢？ 从src中找，src中与index一样位置的那个元素值放到input中。 案例1： >>> src = torch.arange(1, 11).reshape((2, 5)) >>> src tensor([[ 1, 2, 3, 4, 5], [ 6, 7, 8, 9, 10]]) >>> index = torch.tensor([[0, 1, 2, 0]]) >>> torch.zeros(3, 5, dtype=src.dtype).scatter_(0, index, src) tensor([[1, 0, 0, 4, 0], [0, 2, 0, 0, 0], [0, 0, 3, 0, 0]]) dim=0, 所以行号跟着index的元素走。其它跟index的索引走。 第一步：找到index的第一个元素index[0, 0]是0， 那么把src[0, 0]（是1）放到input[0, 0]第二步：找到index的第二个元素index[0, 1]是1， 那么把src[0, 1]（是2）放到input[1, 1]第三步：找到index的第三个元素index[0, 2]是2， 那么把src[0, 2]（是3）放到input[2, 2]第四步：找到index的第四个元素index[0, 3]是0， 那么把src[0, 3]（是4）放到input[0, 3] 案例2： >>> src = torch.arange(1, 11).reshape((2, 5)) >>> src tensor([[ 1, 2, 3, 4, 5], [ 6, 7, 8, 9, 10]]) >>> index = torch.tensor([[0, 2, 4], [1, 2, 3]]) >>> index tensor([[0, 2, 4], [1, 2, 3]]) >>> torch.zeros(3, 5, dtype=src.dtype).scatter_(1, index, src) tensor([[1, 0, 2, 0, 3], [0, 6, 7, 8, 0], [0, 0, 0, 0, 0]]) dim=1：告诉input（零矩阵）的索引，沿着列进行索引，行根据index走。 index：2*3，告诉input（零矩阵），你的哪些行是要被替换的。 src：input要替换成什么呢？从src里找，怎么找？通过index的索引对应的找。 第一步：找到index的第一个元素index[0, 0]是0， 那么把src[0, 0]（是1）放到input[0, 0]第二步：找到index的第二个元素index[0, 1]是2， 那么把src[0, 1]（是2）放到input[0, 2]第三步：找到index的第三个元素index[0, 2]是4， 那么把src[0, 2]（是3）放到input[0, 4]第四步：找到index的第四个元素index[1, 0]是1， 那么把src[1, 0]（是6）放到input[1, 1]第五步：找到index的第五个元素index[1, 1]是2， 那么把src[1, 1]（是7）放到input[1, 2]第六步：找到index的第六个元素index[1, 2]是3， 那么把src[1, 2]（是8）放到input[1, 3] 这里可以看到 index的元素是决定input的哪个位置要变 变的值是从src上对应于index的索引上找。可以看到src的索引与index的索引保持一致的 案例3：one-hot的生成 >>> label = torch.arange(3).view(-1, 1) >>> label tensor([[0], [1], [2]]) >>> torch.zeros(3, 3).scatter_(1, label, 1) tensor([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]]) 第一步：找到index的第一个元素index[0, 0]是0， 那么把src[0, 0]（是1）放到input[0, 0] 第二步：找到index的第二个元素index[1, 0]是1， 那么把src[1, 0]（是1）放到input[1, 1] 第三步：找到index的第三个元素index[2, 0]是2， 那么把src[2, 0]（是1）放到input[2, 2] （one-hot的案例不利于理解scater函数，因为它的行和列是一样的。。。其实input[x, y] 中的x,y是有区别的，x是根据index走，y是根据index的元素值走的，而具体的值是根据src的值。） 张量的随机种子 随机种子（random seed）是编程语言中基础的概念，大多数编程语言都有随机种子的概念，它主要用于实验的复现。针对随机种子pytorch也有一些设置函数。 seed 获取一个随机的随机种子。Returns a 64 bit number used to seed the RNG. manual_seed 手动设置随机种子，建议设置为42，这是近期一个玄学研究。说42有效的提高模型精度。当然大家可以设置为你喜欢的，只要保持一致即可。 initial_seed 返回初始种子。 get_rng_state 获取随机数生成器状态。Returns the random number generator state as a torch.ByteTensor. set_rng_state 设定随机数生成器状态。这两怎么用暂时未知。Sets the random number generator state. 以上均是设置cpu上的张量随机种子，在cuda上是另外一套随机种子，如torch.cuda.manual_seed_all(seed)， 这些到cuda模块再进行介绍，这里只需要知道cpu和cuda上需要分别设置随机种子。 张量的数学操作 张量还提供大量数学操作，估计了一下，有快一百个函数，这里就不再一一分析，只需要知道有哪几大类，用到的时候来查吧。 Pointwise Ops： 逐元素的操作，如abs, cos, sin, floor, floor_divide, pow等 Reduction Ops: 减少元素的操作，如argmax, argmin, all, any, mean, norm, var等 Comparison Ops：对比操作， 如ge, gt, le, lt, eq, argsort, isnan, topk, Spectral Ops: 谱操作，如短时傅里叶变换等各类信号处理的函数。 Other Operations：其它， clone， diag，flip等 BLAS and LAPACK Operations：BLAS（Basic Linear Algebra Subprograms）基础线性代数）操作。如, addmm, dot, inner, svd等。 小结 本节介绍了张量主要的操作函数，并归类到各个小结，这些仅是张量的部分操作，更多操作还请大家多多看官方文档。对于张量，主要是要理解2.3小节中张量的结构以及作用，对于它的操作就像numpy一样简单易用。 下一节就开始讲解pytorch的核心——autograd，autograd也是现代深度学习框架的核心，是实现自动微分的具体实现。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-2/2.5-computational-graphs.html":{"url":"chapter-2/2.5-computational-graphs.html","title":"2.5 自动求导核心——计算图","keywords":"","body":"2.5 计算图 前两小节对tensor进行了详细介绍，知道了tensor是pytorch的核心数据结构，各类数据均以tensor来表示，并且tensor类中有许多属性与求导/梯度有关，下面就深入学习pytorch的自动求导模块——autograd。在autograd正式开始之前，需要了解一个重要概念——计算图（Computational Graphs）。 在学习自动求导系统之前，需要了解计算图的概念。计算图（Computational Graphs）是一种描述运算的“语言”，它由节点(Node)和边(Edge)构成。 节点表示数据，如标量，向量，矩阵，张量等； 边表示运算，如加、减、乘、除、卷积、relu等； 记录所有节点和边的信息，可以方便的完成自动求导，假设有这么一个计算： y = (x+ w) * (w+1) 将每一步细化为： a = x + w b = w + 1 y = a * b 得到计算图如下： 有了计算图，我们可以尝试进行forward，带入x,w的输入数据，就得到结果y。 同样的，加入需要获取各参数的导数，也可以方便的获得。 计算图求导 假设我们要算y对w的导数，在计算图中要怎么做呢？ 先来看w和y之间的关系，w会通过左边这条路走到y，也会通过右边这条路走到y，所以梯度也是一样的，会经过这两条路返传回来。 所以y对w的偏导有两条路径，可以写成以下形式， ∂y/∂w = ∂y/∂a ∂a/∂w + ∂y/∂b ∂b/∂w，然后可以通过计算图依次求出。 如图所示： 这样我们得到 y对w的导数是5，我们可以拿纸和笔推一下，是否是一样的。 我们发现，所有的偏微分计算所需要用到的数据都是基于w和x的，这里，w和x就称为叶子结点。 叶子结点是最基础的结点，其数据不是由运算生成的，因此是整个计算图的基石，是不可轻易”修改“的。而最终计算得到的y就是根节点，就像一棵树一样，叶子在上面，根在下面。 叶子结点 叶子结点是最基础的结点，其数据不是由运算生成的，因此是整个计算图的基石，是不可轻易”修改“的。而最终计算得到的y就是根节点，就像一棵树一样，叶子在上面，根在下面。 张量有一个属性是is_leaf, 就是用来指示一个张量是否为叶子结点的属性。 我们通过代码，实现以上运算，并查看该计算图的叶子结点和梯度。 import torch w = torch.tensor([1.], requires_grad=True) x = torch.tensor([2.], requires_grad=True) a = torch.add(w, x) b = torch.add(w, 1) # retain_grad() y = torch.mul(a, b) y.backward() print(w.grad) # 查看叶子结点 print(\"is_leaf:\\n\", w.is_leaf, x.is_leaf, a.is_leaf, b.is_leaf, y.is_leaf) # 查看梯度 print(\"gradient:\\n\", w.grad, x.grad, a.grad, b.grad, y.grad) # 查看 grad_fn print(\"grad_fn:\\n\", w.grad_fn, x.grad_fn, a.grad_fn, b.grad_fn, y.grad_fn) tensor([5.]) is_leaf: True True False False False gradient: tensor([5.]) tensor([2.]) None None None grad_fn: None None 我们发现y就不是叶子结点了，因为它是由结点w和结点x通过乘法运算得到的。 补充知识点1：非叶子结点在梯度反向传播结束后释放 只有叶子节点的梯度得到保留，中间变量的梯度默认不保留；在pytorch中，非叶子结点的梯度在反向传播结束之后就会被释放掉，如果需要保留的话可以对该结点设置retain_grad() 补充知识点2：grad_fn是用来记录创建张量时所用到的运算，在链式求导法则中会使用到。 思考一下y对w求导的过程，我们知道只要记录下计算图中的结点（数据）和边（运算），就可以通过链式法则轻易的求取梯度。 所以在pytorch中，自动微分的关键就是记录数据和该结点的运算。回想一下张量的结构当中其实就记录了这两个重要的东西。 在张量中，数据对应着data，结点的运算对应着grad_fn，大家现在应该明白为什么结点的运算叫grad_fn而不叫fn了吧，因为这个运算是在求梯度的时候使用的。 静态图与动态图 以上就是计算图的简单介绍。计算图根据计算图的搭建方式可以划分为静态图和动态图。 pytorch是典型的动态图，TensorFlow是静态图（TF 2.x 也支持动态图模式）。 怎么样的搭建方式是动态的？怎么样的才是静态的呢？ 第一种判断：这就要看运算，是在计算图搭建之后，还是两者同步进行 先搭建计算图，再运算，这就是静态图机制。 而在运算的同时去搭建计算图，这就是动态图机制。 第二种判断：也可以通过判断运算过程中，计算图是否可变动来区分静态图与动态图。 在运算过程中，计算图可变动的，那么就是动态图，计算图不可变，是静止的，那么就是静态图。 下面来看两个示意图。 图1为pytorch的静态图示意，图2为TensorFlow的静态图示意。 动态图优点： 易懂性：程序按照编写命令的顺序进行执行 灵活性：可依据模型运算结果来决定计算图 静态图优点： 高效性：优化计算图，提高运算效率（但在gpu时代，这一点对于初学者而言可忽略不计） 缺点： 晦涩性：需要学习 seesion, placeholder等概念，debug难 以上是关于计算图概念的介绍，下一小节将详细剖析autograd机制及其常用的功能函数，预告一下，下一节内容也非常多，需要反复阅读。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-2/2.6-autograd.html":{"url":"chapter-2/2.6-autograd.html","title":"2.6 Autograd——自动微分","keywords":"","body":"2.6 Autograd 了解计算图后，我们可以开始学习autograd。这里再次回顾pytorch官网的一张示意图 在进行h2h、i2h、next_h、loss的计算过程中，逐步的搭建计算图，同时针对每一个变量（tensor）都存储计算梯度所必备的grad_fn，便于自动求导系统使用。当计算到根节点后，在根节点调用.backward()函数，即可自动反向传播计算计算图中所有节点的梯度。这就是pytorch自动求导机制，其中涉及张量类、计算图、grad_fn、链式求导法则等基础概念，大家可以自行补充学习。 autograd 官方定义 来看看官方文档中对autograd的解释： Conceptually, autograd keeps a record of data (tensors) and all executed operations (along with the resulting new tensors) in a directed acyclic graph (DAG) consisting of Function objects. In this DAG, leaves are the input tensors, roots are the output tensors. By tracing this graph from roots to leaves, you can automatically compute the gradients using the chain rule. In a forward pass, autograd does two things simultaneously: run the requested operation to compute a resulting tensor maintain the operation’s gradient function in the DAG. The backward pass kicks off when .backward() is called on the DAG root. autograd then: computes the gradients from each .grad_fn, accumulates them in the respective tensor’s .grad attribute using the chain rule, propagates all the way to the leaf tensors. from： https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html#more-on-computational-graphs 划重点： 自动求导机制通过有向无环图（directed acyclic graph ，DAG）实现 在DAG中，记录数据（对应tensor.data）以及操作（对应tensor.grad_fn） 操作在pytorch中统称为Function，如加法、减法、乘法、ReLU、conv、Pooling等，统统是Function autograd 的使用 autograd的使用有很多方法，这里重点讲解一下三个，并在最后汇总一些知识点。更多API推荐阅读官方文档 torch.autograd.backward torch.autograd.grad torch.autograd.Function torch.autograd.backward backward函数是使用频率最高的自动求导函数，没有之一。99%的训练代码中都会用它进行梯度求导，然后更新权重。 使用方法可以参考第二章第二节-新冠肺炎分类的代码，loss.backward()就可以完成计算图中所有张量的梯度求解。 虽然绝大多数都是直接使用，但是backward()里边还有一些高级参数，值得了解。 torch.autograd.backward(tensors, grad_tensors=None, retain_graph=None, create_graph=False, grad_variables=None, inputs=None) tensors (Sequence[Tensor] or Tensor) – 用于求导的张量。如上例的loss。 grad_tensors (Sequence[Tensor or None] or Tensor, optional) – 雅克比向量积中使用，详细作用请看代码演示。 retain_graph (bool, optional) – 是否需要保留计算图。pytorch的机制是在方向传播结束时，计算图释放以节省内存。大家可以尝试连续使用loss.backward()，就会报错。如果需要多次求导，则在执行backward()时，retain_graph=True。 create_graph (bool, optional) – 是否创建计算图，用于高阶求导。 inputs (Sequence[Tensor] or Tensor, optional) – Inputs w.r.t. which the gradient be will accumulated into .grad. All other Tensors will be ignored. If not provided, the gradient is accumulated into all the leaf Tensors that were used to compute the attr::tensors. 补充说明：我们到使用的时候都是在张量上直接调用.backward()函数，但这里却是torch.autograd.backward，为什么不一样呢？ 其实Tensor.backward()接口内部调用了autograd.backward。 请看使用示例 retain_grad参数使用 对比两个代码段，仔细阅读pytorch报错信息。 ##### retain_graph=True import torch w = torch.tensor([1.], requires_grad=True) x = torch.tensor([2.], requires_grad=True) a = torch.add(w, x) b = torch.add(w, 1) y = torch.mul(a, b) y.backward(retain_graph=True) print(w.grad) y.backward() print(w.grad) tensor([5.]) tensor([10.]) 运行上面代码段可以看到是正常的，下面这个代码段就会报错，报错信息提示非常明确：Trying to backward through the graph a second time。并且还给出了解决方法： Specify retain_graph=True if you need to backward through the graph a second time 。这也是pytorch代码写得好的地方，出现错误不要慌，仔细看看报错信息，里边可能会有解决问题的方法。 ##### retain_graph=False import torch w = torch.tensor([1.], requires_grad=True) x = torch.tensor([2.], requires_grad=True) a = torch.add(w, x) b = torch.add(w, 1) y = torch.mul(a, b) y.backward() print(w.grad) y.backward() print(w.grad) tensor([5.]) --------------------------------------------------------------------------- RuntimeError Traceback (most recent call last) in 10 y.backward() 11 print(w.grad) ---> 12 y.backward() 13 print(w.grad) D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\lib\\site-packages\\torch\\_tensor.py in backward(self, gradient, retain_graph, create_graph, inputs) 305 create_graph=create_graph, 306 inputs=inputs) --> 307 torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs) 308 309 def register_hook(self, hook): D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\lib\\site-packages\\torch\\autograd\\__init__.py in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs) 154 Variable._execution_engine.run_backward( 155 tensors, grad_tensors_, retain_graph, create_graph, inputs, --> 156 allow_unreachable=True, accumulate_grad=True) # allow_unreachable flag 157 158 RuntimeError: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward. grad_tensors使用 w = torch.tensor([1.], requires_grad=True) x = torch.tensor([2.], requires_grad=True) a = torch.add(w, x) b = torch.add(w, 1) y0 = torch.mul(a, b) # y0 = (x+w) * (w+1) dy0/dw = 2w + x + 1 y1 = torch.add(a, b) # y1 = (x+w) + (w+1) dy1/dw = 2 loss = torch.cat([y0, y1], dim=0) # [y0, y1] grad_tensors = torch.tensor([1., 2.]) loss.backward(gradient=grad_tensors) # Tensor.backward中的 gradient 传入 torch.autograd.backward()中的grad_tensors # w = 1* (dy0/dw) + 2*(dy1/dw) # w = 1* (2w + x + 1) + 2*(w) # w = 1* (5) + 2*(2) # w = 9 print(w.grad) tensor([9.]) torch.autograd.grad orch.autograd.grad(outputs, inputs, grad_outputs=None, retain_graph=None, create_graph=False, only_inputs=True, allow_unused=False) 功能：计算outputs对inputs的导数 主要参数： outputs (sequence of Tensor) – 用于求导的张量，如loss inputs (sequence of Tensor) – 所要计算导数的张量 grad_outputs (sequence of Tensor) – 雅克比向量积中使用。 retain_graph (bool, optional) – 是否需要保留计算图。pytorch的机制是在方向传播结束时，计算图释放以节省内存。大家可以尝试连续使用loss.backward()，就会报错。如果需要多次求导，则在执行backward()时，retain_graph=True。 create_graph (bool, optional) – 是否创建计算图，用于高阶求导。 allow_unused (bool, optional) – 是否需要指示，计算梯度时未使用的张量是错误的。 此函数使用上比较简单，请看案例： import torch x = torch.tensor([3.], requires_grad=True) y = torch.pow(x, 2) # y = x**2 # 一阶导数 grad_1 = torch.autograd.grad(y, x, create_graph=True) # grad_1 = dy/dx = 2x = 2 * 3 = 6 print(grad_1) # 二阶导数 grad_2 = torch.autograd.grad(grad_1[0], x) # grad_2 = d(dy/dx)/dx = d(2x)/dx = 2 print(grad_2) (tensor([6.], grad_fn=),) (tensor([2.]),) torch.autograd.Function 有的时候，想要实现自己的一些操作（op），如特殊的数学函数、pytorch的module中没有的网络层，那就需要自己写一个Function，在Function中定义好forward的计算公式、backward的计算公式，然后将这些op组合到模型中，模型就可以用autograd完成梯度求取。 这个概念还是很抽象，平时用得不多，但是自己想要魔改网络时，常常需要自己写op，那么它就很好用了，为了让大家掌握自定义op——Function的写法，特地从多处收集了四个案例，大家多运行代码体会Function如何写。 案例1： exp 案例1：来自 https://pytorch.org/docs/stable/autograd.html#function 假设需要一个计算指数的功能，并且能组合到模型中，实现autograd，那么可以这样实现 第一步：继承Function第二步：实现forward第三步：实现backward 注意事项： forward和backward函数第一个参数为ctx，它的作用类似于类函数的self一样，更详细解释可参考如下： In the forward pass we receive a Tensor containing the input and return a Tensor containing the output. ctx is a context object that can be used to stash information for backward computation. You can cache arbitrary objects for use in the backward pass using the ctx.save_for_backward method. backward函数返回的参数个数与forward的输入参数个数相同, 即，传入该op的参数，都需要给它们计算对应的梯度。 import torch from torch.autograd.function import Function class Exp(Function): @staticmethod def forward(ctx, i): # ============== step1: 函数功能实现 ============== result = i.exp() # ============== step1: 函数功能实现 ============== # ============== step2: 结果保存，用于反向传播 ============== ctx.save_for_backward(result) # ============== step2: 结果保存，用于反向传播 ============== return result @staticmethod def backward(ctx, grad_output): # ============== step1: 取出结果，用于反向传播 ============== result, = ctx.saved_tensors # ============== step1: 取出结果，用于反向传播 ============== # ============== step2: 反向传播公式实现 ============== grad_results = grad_output * result # ============== step2: 反向传播公式实现 ============== return grad_results x = torch.tensor([1.], requires_grad=True) y = Exp.apply(x) # 需要使用apply方法调用自定义autograd function print(y) # y = e^x = e^1 = 2.7183 y.backward() print(x.grad) # 反传梯度, x.grad = dy/dx = e^x = e^1 = 2.7183 # 关于本例子更详细解释，推荐阅读 https://zhuanlan.zhihu.com/p/321449610 tensor([2.7183], grad_fn=) tensor([2.7183]) 从代码里可以看到，y这个张量的 grad_fn 是 ExpBackward，正是我们自己实现的函数，这表明当y求梯度时，会调用ExpBackward这个函数进行计算这也是张量的grad_fn的作用所在 案例2：为梯度乘以一定系数 Gradcoeff 案例2来自： https://zhuanlan.zhihu.com/p/321449610 功能是反向传梯度时乘以一个自定义系数 class GradCoeff(Function): @staticmethod def forward(ctx, x, coeff): # ============== step1: 函数功能实现 ============== ctx.coeff = coeff # 将coeff存为ctx的成员变量 x.view_as(x) # ============== step1: 函数功能实现 ============== return x @staticmethod def backward(ctx, grad_output): return ctx.coeff * grad_output, None # backward的输出个数，应与forward的输入个数相同，此处coeff不需要梯度，因此返回None # 尝试使用 x = torch.tensor([2.], requires_grad=True) ret = GradCoeff.apply(x, -0.1) # 前向需要同时提供x及coeff，设置coeff为-0.1 ret = ret ** 2 print(ret) # 注意看： ret.grad_fn ret.backward() print(x.grad) tensor([4.], grad_fn=) tensor([-0.4000]) 在这里需要注意 backward函数返回的参数个数与forward的输入参数个数相同即，传入该op的参数，都需要给它们计算对应的梯度。 案例3：勒让德多项式 案例来自：https://github.com/excelkks/blog假设多项式为：$y = a+bx+cx^2+dx^3$时，用两步替代该过程 $y= a+b\\times P_3(c+dx), P_3(x) = \\frac{1}{2}(5x^3-3x)$ import torch import math from torch.autograd.function import Function class LegendrePolynomial3(Function): @staticmethod def forward(ctx, x): \"\"\" In the forward pass we receive a Tensor containing the input and return a Tensor containing the output. ctx is a context object that can be used to stash information for backward computation. You can cache arbitrary objects for use in the backward pass using the ctx.save_for_backward method. \"\"\" y = 0.5 * (5 * x ** 3 - 3 * x) ctx.save_for_backward(x) return y @staticmethod def backward(ctx, grad_output): \"\"\" In the backward pass we receive a Tensor containing the gradient of the loss with respect to the output, and we need to compute the gradient of the loss with respect to the input. \"\"\" ret, = ctx.saved_tensors return grad_output * 1.5 * (5 * ret ** 2 - 1) a, b, c, d = 1, 2, 1, 2 x = 1 P3 = LegendrePolynomial3.apply y_pred = a + b * P3(c + d * x) print(y_pred) 127.0 案例4：手动实现2D卷积 案例来自：https://pytorch.org/tutorials/intermediate/custom_function_conv_bn_tutorial.html案例本是卷积与BN的融合实现，此处仅观察Function的使用，更详细的内容，十分推荐阅读原文章下面看如何实现conv_2d的 import torch from torch.autograd.function import once_differentiable import torch.nn.functional as F def convolution_backward(grad_out, X, weight): \"\"\" 将反向传播功能用函数包装起来，返回的参数个数与forward接收的参数个数保持一致，为2个 \"\"\" grad_input = F.conv2d(X.transpose(0, 1), grad_out.transpose(0, 1)).transpose(0, 1) grad_X = F.conv_transpose2d(grad_out, weight) return grad_X, grad_input class MyConv2D(torch.autograd.Function): @staticmethod def forward(ctx, X, weight): ctx.save_for_backward(X, weight) # ============== step1: 函数功能实现 ============== ret = F.conv2d(X, weight) # ============== step1: 函数功能实现 ============== return ret @staticmethod def backward(ctx, grad_out): X, weight = ctx.saved_tensors return convolution_backward(grad_out, X, weight) weight = torch.rand(5, 3, 3, 3, requires_grad=True, dtype=torch.double) X = torch.rand(10, 3, 7, 7, requires_grad=True, dtype=torch.double) torch.autograd.gradcheck(Conv2D.apply, (X, weight)) # gradcheck 功能请自行了解，通常写完Function会用它检查一下 y = Conv2D.apply(X, weight) label = torch.randn_like(y) loss = F.mse_loss(y, label) print(weight.grad) loss.backward() print(weight.grad) None tensor([[[[1.4503, 1.3995, 1.4427], [1.4725, 1.4247, 1.4995], [1.4584, 1.4395, 1.5462]], ...... [[1.4645, 1.4461, 1.3604], [1.4523, 1.4556, 1.3755], [1.4204, 1.4346, 1.4323]]]], dtype=torch.float64) ​ autograd相关的知识点 autograd使用过程中还有很多需要注意的地方，在这里做个小汇总。 知识点一：梯度不会自动清零 知识点二： 依赖于叶子结点的结点，requires_grad默认为True 知识点三： 叶子结点不可执行in-place 知识点四： detach 的作用 知识点五： with torch.no_grad()的作用 知识点一：梯度不会自动清零 import torch w = torch.tensor([1.], requires_grad=True) x = torch.tensor([2.], requires_grad=True) for i in range(4): a = torch.add(w, x) b = torch.add(w, 1) y = torch.mul(a, b) y.backward() print(w.grad) # 梯度不会自动清零，数据会累加， 通常需要采用 optimizer.zero_grad() 完成对参数的梯度清零 # w.grad.zero_() tensor([5.]) tensor([5.]) tensor([5.]) tensor([5.]) 知识点二：依赖于叶子结点的结点，requires_grad默认为True 结点的运算依赖于叶子结点的话，它一定是要计算梯度的，因为叶子结点梯度的计算是从后向前传播的，因此与其相关的结点均需要计算梯度，这点还是很好理解的。 import torch w = torch.tensor([1.], requires_grad=True) # x = torch.tensor([2.], requires_grad=True) a = torch.add(w, x) b = torch.add(w, 1) y = torch.mul(a, b) print(a.requires_grad, b.requires_grad, y.requires_grad) print(a.is_leaf, b.is_leaf, y.is_leaf) True True True False False False 知识点三：叶子张量不可以执行in-place操作 叶子结点不可执行in-place，因为计算图的backward过程都依赖于叶子结点的计算，可以回顾计算图当中的例子，所有的偏微分计算所需要用到的数据都是基于w和x（叶子结点），因此叶子结点不允许in-place操作。 a = torch.ones((1, )) print(id(a), a) a = a + torch.ones((1, )) print(id(a), a) a += torch.ones((1, )) print(id(a), a) 2361561191752 tensor([1.]) 2362180999432 tensor([2.]) 2362180999432 tensor([3.]) w = torch.tensor([1.], requires_grad=True) x = torch.tensor([2.], requires_grad=True) a = torch.add(w, x) b = torch.add(w, 1) y = torch.mul(a, b) w.add_(1) y.backward() --------------------------------------------------------------------------- RuntimeError Traceback (most recent call last) in 6 y = torch.mul(a, b) 7 ----> 8 w.add_(1) 9 10 y.backward() RuntimeError: a leaf Variable that requires grad is being used in an in-place operation. 知识点四：detach 的作用 通过以上知识，我们知道计算图中的张量是不能随便修改的，否则会造成计算图的backward计算错误，那有没有其他方法能修改呢？当然有，那就是detach() detach的作用是：从计算图中剥离出“数据”，并以一个新张量的形式返回，并且新张量与旧张量共享数据，简单的可理解为做了一个别名。 请看下例的w，detach后对w_detach修改数据，w同步地被改为了999 w = torch.tensor([1.], requires_grad=True) x = torch.tensor([2.], requires_grad=True) a = torch.add(w, x) b = torch.add(w, 1) y = torch.mul(a, b) y.backward() w_detach = w.detach() w_detach.data[0] = 999 print(w) tensor([999.], requires_grad=True) 知识点五：with torch.no_grad()的作用 autograd自动构建计算图过程中会保存一系列中间变量，以便于backward的计算，这就必然需要花费额外的内存和时间。而并不是所有情况下都需要backward，例如推理的时候，因此可以采用上下文管理器——torch.no_grad()来管理上下文，让pytorch不记录相应的变量，以加快速度和节省空间。详见：https://pytorch.org/docs/stable/generated/torch.no_grad.html?highlight=no_grad#torch.no_grad 小结 本章终于结束，本章目的是为大家介绍pytorch的核心模块，包括pytorch代码库结构，以便于今后阅读源码，知道从哪里找代码；包括第一个分类模型训练，便于大家理解模型训练过程；包括核心数据结构——张量，便于理解整个pytorch的数据；包括计算图与autograd，便于大家熟悉自动微分的过程及自定义op的方法。 下一章将通过借助covid-19任务，详细介绍pytorch的数据读取机制，以及各种数据形式的读取，包括csv形式、txt形式、杂乱文件夹形式等一切关于数据读取、加载、操作的模块都将涉及。 小记：动笔一个多月，才写了两章，尤其autograd和tensor写了大半个月，希望后面能有更多时间精力早日完成，加油！2022年1月18日 ​ ​ Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-3/":{"url":"chapter-3/","title":"第三章 PyTorch 数据模块","keywords":"","body":"第三章 PyTorch 数据模块 第三章 PyTorch 数据模块 3.1 Dataset 3.2 DataLoader 3.3 Dataset及常用API 3.4 transforms 3.5 torchvision 经典dataset学习 第三章简介 经过前两章的铺垫，本章终于可以讲讲项目代码中重要的模块——数据模块。 数据模块包括哪些内容呢？相信大家多少会有一些感觉，不过最好结合具体任务来剖析数据模块。 我们回顾2.2中的COVID-19分类任务，观察一下数据是如何从硬盘到模型输入的。 我们倒着推， 模型接收的训练数据是 data：outputs = model(data) data来自train_loader： for data, labels in train_loader: train_loader 来自 DataLoader与train_data：train_loader = DataLoader(dataset=train_data, batch_size=2) train_data 来自 COVID19Dataset：train_data = COVID19Dataset(root_dir=img_dir, txt_path=path_txt_train, transform=transforms_func) COVID19Dataset继承于Dataset：COVID19Dataset(Dataset) 至此，知道整个数据处理过程会涉及pytorch的两个核心——Dataset， DataLoader。 Dataset是一个抽象基类，提供给用户定义自己的数据读取方式，最核心在于getitem中间对数据的处理。 DataLoader是pytorch数据加载的核心，其中包括多个功能，如打乱数据，采样机制（实现均衡1:1采样），多进程数据加载，组装成Batch形式等丰富的功能。 本章将围绕着它们两个展开介绍pytorch的数据读取、预处理、加载等功能。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-3/3.1-dataset.html":{"url":"chapter-3/3.1-dataset.html","title":"3.1 Dataset","keywords":"","body":"3.1 torch.utils.data.Dataset 数据交互模块——Dataset 虽然说pytorch数据模块的核心是DataLoader，但是对于使用者而言，改动最多的、与源数据最接近的是Dataset， 本小节就详细分析Dataset的作用，并通过三个案例学习如何编写自定义Dataset来读取自己的数据集。 Dataset的功能 pytorch提供的torch.utils.data.Dataset类是一个抽象基类An abstract class representing a Dataset，供用户继承，编写自己的dataset，实现对数据的读取。在Dataset类的编写中必须要实现的两个函数是__getitem__和__len__(由于markdown语法问题，后续双下划线就省略了)。 getitem：需要实现读取一个样本的功能。通常是传入索引（index，可以是序号或key），然后实现从磁盘中读取数据，并进行预处理（包括online的数据增强），然后返回一个样本的数据。数据可以是包括模型需要的输入、标签，也可以是其他元信息，例如图片的路径。getitem返回的数据会在dataloader中组装成一个batch。即，通常情况下是在dataloader中调用Dataset的getitem函数获取一个样本。 len：返回数据集的大小，数据集的大小也是个最要的信息，它在dataloader中也会用到。如果这个函数返回的是0，dataloader会报错：\"ValueError: num_samples should be a positive integer value, but got num_samples=0\" 这个报错相信大家经常会遇到，这通常是路径没写对，导致你的dataset找不到数据，数据个数为0。 了解Dataset类的概念，下面通过一幅示意图，来理解Dataset与DataLoader的关系。 dataset负责与磁盘打交道，将磁盘上的数据读取并预处理好，提供给DataLoader，而DataLoader只需要关心如何组装成批数据，以及如何采样。采样的体现是出现在传入getitem函数的索引，这里采样的规则可以通过sampler由用户自定义，可以方便地实现均衡采样、随机采样、有偏采样、渐进式采样等，这个留在DataLoader中会详细展开。 在这里，我们先关心一下Dataset如何与磁盘构建联系。 从2.2的例子中可以看到，我们为COVID19Dataset定义了一个_get_img_info函数，它就是用来建立磁盘关系的，在这个函数中处理样本的路径信息、标签信息，存储到一个list中，供getitem函数使用。getitem函数只需要拿到序号，就可获得图片的路径信息、标签信息，接着进行图片预处理，最后返回一个样本信息。 希望大家体会_get_img_info函数的作用，对于各式各样的数据形式，都可以用这个模板实现Dataset的构建，只需要在_get_img_info中把数据信息（路径、标签等）读取进来放到list中，供getite使用即可。 三个Dataset案例 相信大家在做自己的任务时，遇到的第一个问题就是，怎么把自己的数据放到github的模型上跑起来。很多朋友通常会把自己的数据制作到与现成项目数据一模一样的数据形式，然后调用代码。这样虽然快捷，但是缺少灵活性。 为了让大家能掌握各类数据形式的读取，这里构建三个不同的数据形式进行编写Dataset。 第一个：2.2中的类型。数据的划分及标签在txt中。 第二个：数据的划分及标签在文件夹中体现 第三个：数据的划分及标签在csv中 详细请结合 配套代码，深刻体会_get_img_info及Dataset做了什么事情。 代码输出主要有两部分， 第一部分是两种dataset的getitem输出。 第二部分是结合DataLoader进行数据加载。 先看第一部分，输出的是 PIL对象及图像标签，这里可以进入getitem函数看到采用了 img = Image.open(path_img).convert('L') 对图片进行了读取，得到了PIL对象，由于transform为None，不对图像进行任何预处理，因此getitem函数返回的图像是PIL对象。 2 (, 1) 2 (, 1) 第二部分是结合DataLoader的使用，这种形式更贴近真实场景，在这里为Dataset设置了一些transform，有图像的缩放，ToTensor， normalize三个方法。因此，getitem返回的图像变为了张量的形式，并且在DataLoader中组装成了batchsize的形式。大家可以尝试修改缩放的大小来观察输出，也可以注释normalize来观察它们的作用。 0 torch.Size([2, 1, 4, 4]) tensor([[[[-0.0431, -0.1216, -0.0980, -0.1373], [-0.0667, -0.2000, -0.0824, -0.2392], [-0.1137, 0.0353, 0.1843, -0.2078], [ 0.0510, 0.3255, 0.3490, -0.0510]]], [[[-0.3569, -0.2863, -0.3333, -0.4118], [ 0.0196, -0.3098, -0.2941, 0.1059], [-0.2392, -0.1294, 0.0510, -0.2314], [-0.1059, 0.4118, 0.4667, 0.0275]]]]) torch.Size([2]) tensor([1, 0]) 关于transform的系列方法以及工作原理，将在本章后半部分讲解数据增强部分再详细展开。 小结 本小结介绍了torch.utils.data.Dataset类的结构及工作原理，并通过三个案例实践，加深大家对自行编写Dataset的认识，关于Dataset的编写，torchvision也有很多常用公开数据集的Dataset模板，建议大家学习，本章后半部分也会挑选几个Dataset进行分析。下一小节将介绍DataLoader类的使用。 额外学习建议 IDE的debug： 下一小节的代码将采用debug模式进行逐步分析，建议大家提前熟悉pycharm等IDE的debug功能。 python的迭代器：相信很多初学者对代码中的“next(iter(train_set))”不太了解，这里建议大家了解iter概念、next概念、迭代器概念、以及双下划线函数概念。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-3/3.2-dataloader.html":{"url":"chapter-3/3.2-dataloader.html","title":"3.2 DataLoader","keywords":"","body":"3.2 DataLoader dataloader简介 按照上图的顺序，本小节就来到pytorch数据加载最核心模块——DataLoader。 torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, sampler=None, batch_sampler=None, num_workers=0, collate_fn=None, pin_memory=False, drop_last=False, timeout=0, worker_init_fn=None, multiprocessing_context=None, generator=None, *, prefetch_factor=2, persistent_workers=False) 从以上可以看到，DataLoader类有14个变量，因此称为最核心模块，一点不为过。 DataLoader功能繁多，这里根据官方文档可总结为以下5大点： 支持两种形式数据集读取：map-style and iterable-style datasets, 自定义采样策略：customizing data loading order, 自动组装成批数据：automatic batching, 多进程数据加载：single- and multi-process data loading, 自动实现锁页内存（Pinning Memory）：automatic memory pinning. 支持两种形式数据集读取 两种形式的数据集分别是映射式(Map-style)与迭代式(Iterable-style)，在3.1小结中讲解的Dataset类就是映射式，因为它（getitem）提供了序号到数据的映射。迭代式则是编写一个可迭代对象，从中依次获取数据，此处不详细展开，感兴趣可以了解IterableDataset 注：往后不做特别说明，Dataset均表示映射式Dataset。 自定义采样策略 DataLoader可借助Sampler自定义采样策略，包括为每个类别设置采样权重以实现1:1的均衡采样，或者是自定义采样策略，关于Sampler会在后面小结详细展开，它是一个涨点神奇。 自动组装成批数据 mini-batch形式的训练称为了深度学习的标配，如何把数据组装成一个batch数据？DataLoader内部自动实现了该功能，并且可以通过batch_sampler、collate_fn来自定义组装的策略，十分灵活。 多进程数据加载 通常GPU运算消耗数据会比CPU读取加载数据要快，CPU“生产”跟不上GPU“消费”，因此需要多进程进行加载数据，以满足GPU的消费需求。通常指要设置num_workers 为CPU核心数，如16核的CPU就设置为16。 自动实现锁页内存（Pinning Memory） 锁页内存的概念通常在操作系统课程里才会涉及，非CS的同学可能会很懵，感兴趣的可以去了解一下。Pinning Memory是空间换时间的做法，将指定的数据“锁”住，不会被系统移动（交换）到磁盘中的虚拟内存，因此可以加快数据的读取速率。简单的可以理解为常用的衣服就“锁”在你的衣柜里，某些时候（如夏天），暂时不用的衣服——冬季大衣，则会移动到收纳柜里，以腾出空间放其它常用的衣服，等到冬天来临，需要用到大衣的时候，再从收纳柜里把大衣放到衣柜中。但是冬天拿大衣的时候就会慢一些，如果把它“锁”在你的衣柜，那么冬天获取它的时候自然快了，但占用了你的空间。这就是空间换时间的一个例子。这里的“锁”就是固定的意思，大家可补充学习一下OS的内容。 DataLoader API DataLoader提供了丰富的功能，下面介绍常用的功能，高阶功能等到具体项目中再进行分析。 dataset：不用说，它是一个Dataset实例，要能实现从索引（indices/keys）到样本的映射。（即getitem函数） batch_size：每个batch的样本量 shuffle：是否对打乱样本顺序。训练集通常要打乱它！验证集和测试集无所谓。 sampler：设置采样策略。后面会详细展开。 batch_sampler：设置采样策略， batch_sampler与sampler二选一，具体选中规则后面代码会体现。 num_workers： 设置多少个子进程进行数据加载（data loading） collate_fn：组装数据的规则， 决定如何将一批数据组装起来。 pin_memory：是否使用锁页内存，具体行为是“the data loader will copy Tensors into CUDA pinned memory before returning them” drop_last：每个epoch是否放弃最后一批不足batchsize大小的数据，即无法被batchsize整除时，最后会有一小批数据，是否进行训练，如果数据量足够多，通常设置为True。这样使模型训练更为稳定，大家千万不要理解为某些数据被舍弃了，因为每个epoch，dataloader的采样都会重新shuffle，因此不会存在某些数据被真正的丢弃。 下面通过配套代码加深dataloader的理解，并且观察DataLoader 与 Dataset是如何配合使用的。 运行代码，可看到输出如下信息： 0 torch.Size([2, 3, 224, 224]) torch.Size([2]) tensor([1, 0]) 1 torch.Size([2, 3, 224, 224]) torch.Size([2]) tensor([0, 1]) 2 torch.Size([1, 3, 224, 224]) torch.Size([1]) tensor([0]) 0 torch.Size([3, 3, 224, 224]) torch.Size([3]) tensor([0, 0, 1]) 1 torch.Size([2, 3, 224, 224]) torch.Size([2]) tensor([1, 0]) 0 torch.Size([2, 3, 224, 224]) torch.Size([2]) tensor([0, 0]) 1 torch.Size([2, 3, 224, 224]) torch.Size([2]) tensor([0, 1]) 这里主要观察batch_size和drop_last的作用，以及图片组装成batch之后的shape。 这里构建一个数据量为5的dataset，这样可以采用batchsize=2和3来观察drop_last的作用。 dataloader内部代码 下一步，我们将采用debug模式，深入dataloader内部，观察它是如何进行采样的，如何调用dataset的getitem获取数据，如何组装一个batch的。这里我们仅观察单进程模式，因此大家的num_works注意设置为0。 首先在for i, (inputs, target) in enumerate(train_loader_bs2) 设置一个断点，然后debug模式运行代码，接着持续采用 Step Into方式运行代码，下面就列出依次会进入的代码： 第一步：初始化dataloader迭代器 for i, (inputs, target) in enumerate(train_loader_bs2) DataLoader的iter() DataLoader的_get_iterator() SingleProcessDataLoaderIter的_init。 注：至此，仅完成了DataLoader的初始化，需要再一次进入dataloader才开始读取数据。 第二步：依次循环该迭代器 来到 BaseDataLoaderIter的_next：进入521行：data = self._next_data() 来到 _SingleProcessDataLoaderIter的_next_data：此函数调用了两个重要功能，第一个获取一个batch的索引，第二个获取此batch的数据。下面一个一个来看。 进入 _SingleProcessDataLoaderIter的_next_data：进入560行， index = self._next_index() 来到 _BaseDataLoaderIter的_next_index()： 这里是对sampler的包装，调用sampler获取一批索引，进入512行 来到BatchSampler的iter()：函数中有yield，这是一个迭代器，从这里可以看到sampler是如何工作的。默认情况下，这里用的是RandomSampler， 它会实现采样的顺序及频率。在本函数中，对self.sampler依次迭代，拿到足够一个batchsize的索引时，就yield。 回到 _SingleProcessDataLoaderIter的_next_data：第561行，经过index = self._next_index() ，已经获得一个batch所对应的index，接着进入self._dataset_fetcher.fetch(index) 来到 _MapDatasetFetcher的fetch：mapdataset就是前面讲到的map-style dataset。看到第49行，是一个列表生成式，在这里，调用了我们自己写的dataset，继续进入。 来到 AntsBeesDataset的getitem：进入到这里，大家就豁然开朗了吧，知道dataset是如何被dataloader使用的。下面，直接跳出去，回到 fetch看看如何组装的。 来到 _MapDatasetFetcher的fetch：第52行self.collate_fn(data)， 这里采用collate_fn对数据进行组装，继续进入。 来到 collate.py的default_collate()：这是pytorch默认的组装函数，值得大家认真学习。这个函数通常是一个递归函数，第一次进入时可以发现会来到第84行：return [default_collate(samples) for samples in transposed]。会依次再进入一次default_collate()。 这里的逻辑是这样的： 首先将dataset返回的一系列数据解包再zip，为的是将相同数据放到一起。即getitem的return返回有img和label，这里就是为了将多个img放到一起，多个label放到一起，当然大家可以在getitem返回其它有用信息（例如图片的路径）。 接着再次进入default_collate函数时，会对实际的数据进行组装。例如img的数据会进入if isinstance(elem, torch.Tensor)，然后会看到img数据是这样被组装起来的：torch.stack(batch, 0, out=out)，因此可知一个batch的图像数据第一个维度是B，整体是BCH*W。 至此，一个batch数据已经读取、加载完毕，依次跳出函数，可回到for i, (inputs, target) in enumerate(train_loader_bs2)。 这个时候，再观察inputs, target，一定会更清晰了，知道它们是如何从硬盘到模型需要的形式。并且通过上述debug过程，我们可以知道sampler的机制、collate_fn的机制，方便今后进行高级的改造。希望大家一定要debug几遍上述过程，并且记录。 小结 以上就是关于DataLoader的概念的介绍，通过两个小节相信大家对数据读取有了初步认识，可pytorch的数据处理远不止于此，它还提供了很多使用的方法，例如数据集的拼接，数据集的截取，数据的划分等，想了解怎么使用，请接着往下看。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-3/3.3-dataset-useful-api.html":{"url":"chapter-3/3.3-dataset-useful-api.html","title":"3.3 Dataset及常用API","keywords":"","body":"3.3 系列api 前言：2022-1月至4月完全没有更新，这三个月发生的事情太多了，国际上有俄乌，国内有上海，公司里有xxx项目，不管怎么样，过去的终将过去，继续学习PyTorch吧，加油！ 前几个小节已经把pytorch的数据读取、加载、预处理机制和逻辑关系理清楚了，下面讲一下实用的API，包括数据集的拼接、截取、划分，以及十分重要的采样策略——sampler。 concat 在实际项目中，数据的来源往往是多源的，可能是多个中心收集的，也可能是多个时间段收集，很难将可用数据统一到一个数据形式。通常有两种做法，一种是固定一个数据形式，所有获取到的数据经过整理，变为统一格式，然后用一个Dataset即可读取。还有一种更为灵活的方式是为每批数据编写一个Dataset，然后使用torch.utils.data.ConcatDataset类将他们拼接起来，这种方法可以灵活的处理多源数据，也可以很好的使用别人的数据及Dataset。 下面还是来看COVID-19的例子，大家知道想要获取大量的COVID-19数据，肯定是多源的，不同国家、不同机构、不同时间的X光片收集过来之后，如何把他们整理起来供模型训练呢？先看这个github仓库covid-chestxray-dataset，他们是这样做的，将采集到的数据统一整理，并生成metadata（元信息），但有的时候有现成的Dataset之后，我们可通过拼接的方法将所有数据拼接成一个大的dataset进行使用。 请结合代码阅读，在2.2与3.2中分别实现了COVID19Dataset、COVID19Dataset2、COVID19Dataset3，假设在项目开始时拿到了COVID19Dataset，做了一段时间来了新数据2和3，那么像把他们放到一起充当训练集，可以用concat完成。可以看到代码将3个数据集拼接得到总的数据集，数据量为2+2+2=6。这里的concatdataset其实还是一个dataset类，它内部还是有len和getitem，里面的getitem代码思路值得学习。concatdataset通过给数据集编号、所有样本编号，然后在__getitem函数中将dataloader传进来的整体样本序号进行计算，得到匹配的数据集序号，以及在该数据集内的样本编号。 可能有点绕，请看图：假设dataloader想要第5个样本，传入index=4， 这时getitem会计算第五个样本在第三个数据集的第1个位置。然后通过self.datasets[datasetidx][sampleidx]来获取数据。这样对外进行一层封装，内部实现仍旧调用各个dataset的__getitem，这样是不是很巧妙呢？ def __getitem__(self, idx): if idx len(self): raise ValueError(\"absolute value of index should not exceed dataset length\") idx = len(self) + idx dataset_idx = bisect.bisect_right(self.cumulative_sizes, idx) if dataset_idx == 0: sample_idx = idx else: sample_idx = idx - self.cumulative_sizes[dataset_idx - 1] return self.datasets[dataset_idx][sample_idx] Subset subset可根据指定的索引获取子数据集，Subset也是Dataset类，同样包含_len_和__getitem\\，其代码编写风格也可以学习一下. CLASStorch.utils.data.Subset(dataset, indices)[SOURCE] Subset of a dataset at specified indices. Parameters dataset (Dataset) – The whole Dataset indices (sequence) – Indices in the whole set selected for subset def __init__(self, dataset: Dataset[T_co], indices: Sequence[int]) -> None: self.dataset = dataset self.indices = indices def __getitem__(self, idx): if isinstance(idx, list): return self.dataset[[self.indices[i] for i in idx]] return self.dataset[self.indices[idx]] def __len__(self): return len(self.indices) 使用上非常简单，代码看一眼就明白， 这里不再赘述 random_split 该函数的功能是随机的将dataset划分为多个不重叠的子集，适合用来划分训练、验证集（不过不建议通过它进行，因为对用户而言，其划分不可见，不利于分析）。 使用也非常简单，只需要设置每个子集的数据量，传给lengths即可。 torch.utils.data.random_split(dataset, lengths, generator=)[SOURCE] Randomly split a dataset into non-overlapping new datasets of given lengths. Optionally fix the generator for reproducible results, e.g.: Parameters dataset (Dataset) – Dataset to be split lengths (sequence) – lengths of splits to be produced generator (Generator) – Generator used for the random permutation ---------------------------------------------------------------------- 分割线 ------------------------------------------------------------------ sampler 下面进入另外一个主题——sampler， sampler是在dataloader中起到挑选数据的功能，主要是设置挑选策略，如按顺序挑选、随机挑选、按类别分概率挑选等等，这些都可以通过自定义sampler实现。 在上一节我们已经用过了一个sampler，那就是batch_sampler，我们先学习一下它的用法，然后再去了解 RandomSampler， SequentialSampler， 以及SubsetRandomSampler和WeightedRandomSampler。 sampler的概念比较复杂，建议大家将BatchSampler、RandomSampler和SequentialSampler放在一起学习。 sampler 与 batch_sampler 首先讲一下dataloader类的sampler变量与batch_sampler变量的区别，在dataloader里会有这两个变量，第一次碰到时候很懵，怎么还有两个采样器，dataloader到底用的哪一个？还是两个都用？经过一番调试，终于搞清楚了。 本质上它们两个都是采样器，当采用auto_collation时，采用batch_sampler。依据如下：dataloader.py 365行 @property def _index_sampler(self): ​ if self._auto_collation: ​ return self.batch_sampler ​ else: ​ return self.sampler 来看一下两者定义： sampler (Sampler or Iterable, optional) – defines the strategy to draw samples from the dataset. Can be any Iterable with len implemented. If specified, shuffle must not be specified. batch_sampler (Sampler or Iterable, optional) – like sampler, but returns a batch of indices at a time. Mutually exclusive with batch_size, shuffle, sampler, and drop_last. 从定义可知道batch_sampler是一次返回一个batch的索引。通常我们用的都是batch_sampler，其对应的是BatchSampler类。 BatchSampler 下面先学习BatchSampler类。回顾3.3的dataloader获取一个样本的机制，会在一个self.nextindex()中调用实际的sampler迭代器，继续进入会来到BatchSampler类的__iter函数，dataloader初始化的时候根据参数配置，自动设置了采样策略为BatchSampler， 依据如下：dataloader.py 第272行代码 if batch_size is not None and batch_sampler is None: # auto_collation without custom batch_sampler batch_sampler = BatchSampler(sampler, batch_size, drop_last) dataloader.py 365行 @property def _index_sampler(self): if self._auto_collation: return self.batch_sampler else: return self.sampler 定位到了BatchSampler，下面来看看类的定义以及传进去的参数是什么。 torch.utils.data.BatchSampler(sampler, batch_size, drop_last) 后两个参数好理解，第一个参数传入的是一个sampler采样器，在这里会有两种情况，如果需要shuffle，则传入RandomSampler，不需要打乱，则传入SequentialSampler。 依据如下, dataloader.py 267行。 if shuffle: sampler = RandomSampler(dataset, generator=generator) else: sampler = SequentialSampler(dataset) 到这里，BatchSampler、RandomSampler和SequentialSampler三者之间的关系逐渐清晰. BatchSampler是在其它两者之上封装了一个批抽取的功能，一次yield一个batch的index，而样本采样的顺序取决于RandomSampler和SequentialSample。 来学习一下BatchSampler如何产生一个batch的序号，并且支持drop_last的功能。 def __iter__(self) -> Iterator[List[int]]: batch = [] for idx in self.sampler: batch.append(idx) if len(batch) == self.batch_size: yield batch batch = [] # 当for循环结束，且batch的数量又不满足batchsize时，则进入以下代码 # 其实就是drop_last的逻辑代码 if len(batch) > 0 and not self.drop_last: yield batch 理解了三者的关系（BatchSampler、RandomSampler和SequentialSampler），RandomSampler和SequentialSampler就很容易理解，来看它们的核心iter函数，学习一下如何编写顺序迭代器以及随机迭代器。 SequentialSampler 顺序迭代器没啥好说的，得到一个按顺序的迭代器。这个顺序就来自 range()函数。 def __iter__(self) -> Iterator[int]: return iter(range(len(self.data_source))) RandomSampler RandomSampler的iter函数核心在于设置一个随机策略，随机策略委托给generator实现，在使用的时候非常简单，默认情况下会使用这行代码实现：yield from torch.randperm(n, generator=generator).tolist()， 利用torch的随机方法生成一个随机整数序列，对于generator默认采用的是随机一个随机种子进行设置。更多的随机概念可以自行了解torch.Generator()、torch.randperm()。 def __iter__(self) -> Iterator[int]: n = len(self.data_source) if self.generator is None: seed = int(torch.empty((), dtype=torch.int64).random_().item()) generator = torch.Generator() generator.manual_seed(seed) else: generator = self.generator if self.replacement: for _ in range(self.num_samples // 32): yield from torch.randint(high=n, size=(32,), dtype=torch.int64, generator=generator).tolist() yield from torch.randint(high=n, size=(self.num_samples % 32,), dtype=torch.int64, generator=generator).tolist() else: yield from torch.randperm(n, generator=generator).tolist() 下面学习另外两个实用的采样器：SubsetRandomSampler和WeightedRandomSampler。 SubsetRandomSampler 顾名思义，可以通过索引定义一个子集的随机采样器，直接看代码 ``` ​ def iter(self) -> Iterator[int]: ​ for i in torch.randperm(len(self.indices), generator=self.generator): ​ yield self.indices[i] 从代码可知道，这个采样器返回的样本总数是传入的索引的长度，这里体现了subset，而随机则是每次会随机的从子集里挑选1个数据返回。 ---------------------------------------------------------------------- 分割线 ------------------------------------------------------------------ WeightedRandomSampler 不知大家是否自行处理过数据均衡采样？最简单粗暴的方法是否是把数据少的样本复制n份，直到所有类别样本数量一致，这是一种“笨”办法，其实可以通过采样器进行加权的采样，下面来看看WeightedRandomSampler。 先来看它的原型： torch.utils.data.WeightedRandomSampler(weights, num_samples, replacement=True, generator=None) Samples elements from [0,..,len(weights)-1] with given probabilities (weights). weights (sequence) – 每个样本的采样权重，权重之和不必为1，只需要关心各样本之间的比例即可。 num_samples (int) – 采样数量，一般设为样本总量。 replacement (bool) –是否有放回采样。 True，表示有放回。 generator (Generator) – 自定义生成器，通常用默认的。 在pytorch的机制里，sampler为每个sample设置权重，因此在设置的时候不仅要指定每个类的采样概率，还要把各类采样概率分发到每个样本上，再传给WeightedRandomSampler。这个机制与常识有一点点不一样，直观的理解应该是为每个类别设置采样概率就好，但这却是为每个样本设置权重，因此需要额外操作两行代码。 下面通过两个案例学习如何使用WeightedRandomSampler。 案例1： sampler初认识 # 第一步：计算每个类的采样概率 weights = torch.tensor([1, 5], dtype=torch.float) # 第二步：生成每个样本的采样概率 train_targets = [sample[1] for sample in train_data.img_info] samples_weights = weights[train_targets] # 第三步：实例化WeightedRandomSampler sampler_w = WeightedRandomSampler( ​ weights=samples_weights, ​ num_samples=len(samples_weights), ​ replacement=True) sampler的构建分三步： 计算各类的采样概率：这里手动设置，是为了让大家可以调整不同的比率，观察dataloader采出样本的变化。下一个例子中采用样本数量进行计算，来达到均衡采样。 生成每个样本的概率：从pytorch机制了解到，需要为每个样本设置采样概率，这里采用的方法是按类别分发即可。在这里有一点需要注意，就是样本标签的顺序需要与dataset中的getitem中的索引顺序保持一致！由于这里采用了dataset.img_info来维护这个顺序，因此可以轻松获得样本顺序。 实例化WeightedRandomSampler 通过运行配套代码可以看到 > torch.Size([2]) tensor([1, 1]) torch.Size([2]) tensor([1, 1]) torch.Size([2]) tensor([1, 1]) torch.Size([2]) tensor([1, 1]) torch.Size([2]) tensor([1, 0]) torch.Size([2]) tensor([1, 1]) torch.Size([2]) tensor([1, 1]) torch.Size([2]) tensor([1, 1]) torch.Size([2]) tensor([1, 1]) torch.Size([2]) tensor([1, 1]) 这里发现出现了很多次[1, 1]。这是因为有放回采样，并且样本1的采样概率比0高很多。 通过这个例子，希望大家能了解 WeightedRandomSampler的使用流程 WeightedRandomSampler采样机制可以为有放回的 有的样本在整个loader中可能不会选中 案例2：不均衡数据集进行均衡采样 点击进入配套代码 下面利用WeightedRandomSampler实现一个10类别的不均衡数据集采样，使它变为1:1的采样。 下面制作了一个虚拟的不均衡数据集，每个类别数量分别是 10， 20，..., 100。总共550张样本，下面希望通过WeightedRandomSampler实现一个dataloader，每次采样550张样本，各类别的数量大约为55。 代码的核心在于统计各类样本的数量，可仔细阅读 # 第一步：计算各类别的采样权重 # 计算每个类的样本数量 train_targets = [sample[1] for sample in train_data.img_info] label_counter = collections.Counter(train_targets) class_sample_counts = [label_counter[k] for k in sorted(label_counter)] # 需要特别注意，此list的顺序！ # 计算权重，利用倒数即可 weights = 1. / torch.tensor(class_sample_counts, dtype=torch.float) 最后可以看到每个epoch采样到的数据几乎实现1:1，可以很好的实现按照设置的权重比例采样。 > Counter({9: 100, 8: 90, 7: 80, 6: 70, 5: 60, 4: 50, 3: 40, 2: 30, 1: 20, 0: 10}) Counter({9: 100, 8: 90, 7: 80, 6: 70, 5: 60, 4: 50, 3: 40, 2: 30, 1: 20, 0: 10}) Counter({9: 100, 8: 90, 7: 80, 6: 70, 5: 60, 4: 50, 3: 40, 2: 30, 1: 20, 0: 10}) Counter({9: 100, 8: 90, 7: 80, 6: 70, 5: 60, 4: 50, 3: 40, 2: 30, 1: 20, 0: 10}) Counter({9: 100, 8: 90, 7: 80, 6: 70, 5: 60, 4: 50, 3: 40, 2: 30, 1: 20, 0: 10}) Counter({9: 100, 8: 90, 7: 80, 6: 70, 5: 60, 4: 50, 3: 40, 2: 30, 1: 20, 0: 10}) Counter({9: 100, 8: 90, 7: 80, 6: 70, 5: 60, 4: 50, 3: 40, 2: 30, 1: 20, 0: 10}) Counter({9: 100, 8: 90, 7: 80, 6: 70, 5: 60, 4: 50, 3: 40, 2: 30, 1: 20, 0: 10}) Counter({9: 100, 8: 90, 7: 80, 6: 70, 5: 60, 4: 50, 3: 40, 2: 30, 1: 20, 0: 10}) Counter({9: 100, 8: 90, 7: 80, 6: 70, 5: 60, 4: 50, 3: 40, 2: 30, 1: 20, 0: 10}) 接下来运用sampler Counter({0: 62, 4: 62, 8: 61, 9: 58, 6: 57, 3: 54, 1: 51, 7: 50, 5: 48, 2: 47}) Counter({5: 72, 7: 59, 6: 59, 8: 57, 1: 57, 0: 55, 4: 53, 2: 49, 9: 48, 3: 41}) Counter({0: 71, 3: 64, 5: 60, 9: 57, 4: 56, 2: 54, 1: 54, 6: 51, 8: 43, 7: 40}) Counter({4: 64, 7: 62, 3: 60, 8: 58, 1: 54, 5: 54, 0: 53, 6: 51, 2: 50, 9: 44}) Counter({8: 68, 0: 62, 7: 60, 6: 58, 2: 55, 3: 51, 9: 50, 5: 50, 1: 50, 4: 46}) Counter({5: 66, 4: 59, 9: 57, 0: 56, 1: 55, 3: 54, 7: 53, 2: 51, 8: 51, 6: 48}) Counter({3: 72, 9: 68, 5: 65, 6: 58, 4: 56, 8: 49, 1: 47, 2: 47, 0: 45, 7: 43}) Counter({4: 63, 2: 62, 7: 60, 9: 59, 3: 58, 8: 57, 6: 52, 0: 50, 5: 45, 1: 44}) Counter({8: 73, 3: 62, 6: 55, 0: 55, 2: 54, 4: 53, 7: 51, 1: 50, 9: 49, 5: 48}) Counter({5: 61, 3: 61, 2: 60, 9: 57, 1: 57, 7: 55, 6: 55, 4: 53, 8: 47, 0: 44}) 进一步地，为了便于大家理解“weights (sequence) – a sequence of weights, not necessary summing up to one”这句话，在代码中增加了 > # weights = 12345. / torch.tensor(class_sample_counts, dtype=torch.float) 大家可以随机修改weight的尺度，观察采样结果 关于采样策略有很多的研究，也有现成的工具库可以使用，推荐大家看看这个repo 小结 本小结将常用的dataset、dataloader配套方法进行了讲解，包括数据集的拼接、子集挑选、子集划分和sampler。其中sampler是涨点神器，推荐掌握。在sampler中，先通过代码单步调试了解RandomSampler，然后顺藤摸瓜找到SequentialSampler和SubsetRandomSampler, 最后通过两个案例详细介绍涨点神器——WeightedRandomSampler的代码编写。 同时推荐大家拓展阅读关于数据采样策略对模型精度的论文，典型的主题是——长尾分布（Long Tail） 下一小节将介绍另外一个涨点首选神器——数据增强模块。先从torchvision的transform模块讲起，然后拓展到更强大的Albumentations Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-3/3.4-transforms.html":{"url":"chapter-3/3.4-transforms.html","title":"3.4 transforms","keywords":"","body":"3.4 transforms 本结分为两部分，首先介绍pytorch的图像数据增强函数库——transforms，分析它的工作机制，同时介绍常用的方法。 transforms简介 数据增强（Data augmentation）已经成为深度学习时代的标配，数据增强目的是为了增加训练数据的丰富度，让模型见过多样性的数据以增加模型的泛化能力。更多关于数据增强的概念，推荐大家阅读动手学的image-augmentation章节 一般地，数据增强可分为在线(online)与离线(offline)两种方式，离线方式指的是在训练开始之前将数据进行变换，变换后的图片保存到硬盘当中，在线方式则是在训练过程中，每一次加载训练数据时对数据进行变换，以实现让模型看到的图片都是增强之后的。其实，这两种方法理论上是等价的，一般的框架都采用在线方式的数据增强，pytorch的transforms就是在线方式。后续不做特别说明，数据增强特指在线数据增强。 transforms是常见图像变换库，包含二十多种基础方法以及多种组合功能，通常可以用Compose把各方法串联在一起使用。大多数的transforms类都有对应的 functional transforms ，可供用户自定义调整。transforms提供的主要是PIL格式和Tensor的变换，并且对于图像的通道也做了规定，默认情况下一个batch的数据是(B, C, H, W) 形状的张量。 在transforms库中包含二十多种对变换方法，那么多的方法里应该如何挑选，以及如何设置参数呢？ 这是值得大家仔细思考的地方，数据增强的方向一定是测试数据集中可能存在的情况。 举个例子，做人脸检测可以用水平翻转（如前置相机的镜像就是水平翻转），但不要用垂直翻转（这里指一般业务场景，特殊业务场景有垂直翻转的人脸就另说）。因为真实应用场景不存在倒转（垂直翻转）的人脸，因此在训练过程选择数据增强时就不能加垂直翻转。 运行机制 在正式介绍transforms的系列方法前，先来了解pytorch对数据增强的运行机制，我们继续通过debug模式在dataloader部分进行调试，观察一张图片是如何进行数据增强的。 同样的，我们回顾2.2小结的COVID-19代码，在dataloader中设置断点，进行debug。这里有一个小技巧，我们可以到dataset的getitem函数里设置一个断点，因为我们前面知道了图像的读取及处理是在dataset的getitem里，因此可以直接进入dataset，不必在dataloader里绕圈。当然，前提是需要大家熟悉dataloader的运行机制。 在第48行img = self.transform(img)设置断点，可以看到self.transform是一个Compose对象，继续进入self.transform(img) 来到 transforms.py 的Compose类的 __call__函数：这个函数的逻辑是依次调用compose对象里的变换方法，从此处也可看出数据是串联的，上一个方法的输出是下一个方法输入，这就要求各个方法之间传输的数据对象要一致。继续单步运行，进入第一个t(img)， 第一个t是Resize。 来到D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py的Module类的_call_impl函数：Module类是pytorch模型、网络层的核心，这个类有1854行代码，下一章将详细介绍模型模块以及Module。在这里我们暂且知道Resize这个变换方法是一个Module类，它实际的调用在1102行，进入1102行会来到Resize类的forward方法。 来到 D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\Lib\\site-packages\\torchvision\\transforms\\transforms.py的Resize类的forward函数：可以看到此函数仅一行代码F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)，继续进入它。 来到D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\Lib\\site-packages\\torch\\nn\\functional.py 的resize函数：functional模块是对一系列操作的封装，这里看到419行，resize功能的实现。继续进入419行。 来到 D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\Lib\\site-packages\\torchvision\\transforms\\functional_pil.py的resize函数：这里终于进入到最核心的Resize方法实现了，这个函数里需要时间缩放的w,h，这里的计算代码非常值得大家学习，同时函数进来之后对参数的一系列判断，也值得借鉴。从此函数可以看到它利用了PIL库的resize函数对PIL图像进行resize。最终对图像resize是这265行代码：return img.resize(size[::-1], interpolation) 然后依次返回，回到transforms.py的Compose类的call函数，此时 img = t(img)完成了1次对图像的变换。接着继续执行for循环，把compose中的变换执行完毕，就对图像做完了变换、增强。 总结一下，一开始采用transforms.Compose把变换的方法包装起来，放到dataset中；在dataloader依次读数据时，调用dataset的getitem，每个sample读取时，会根据compose里的方法依次地对数据进行变换，以此完成在线数据增强。而具体的transforms方法通常包装成一个Module类，具体实现会在各functional中。 熟悉此运行机制，便于大家今后自己编写数据增强方法，嵌入到自己的工程中。 系列API 通过单步debug，了解了transforms运行机制，下面看看transforms库提供的一系列方法及使用。更全面的方法介绍请直接看官方文档，官方文档配备了一个图解transforms的教程 这里不再一一展开各方法介绍，只挑选几个代表性的方法展开讲解，其余方法可以到第一版中阅读transforms的二十二个方法 在这里，结合COVID-2019 X光分类场景进行系列API的使用介绍。主要内容包括： 具体变换方法使用：resize、Normalize、totensor、FiveCrop、TenCrop 特殊方法使用：RandomChoice、RandomOrder、Lambda 自动数据增强：AutoAugmentPolicy、AutoAugment、RandAugment 具体变换方法使用 Compose 此类用于包装一系列的transforms方法，在其内部会通过for循环依次调用各个方法。这个在上面的代码调试过程中已经分析清楚了。 Resize Resize(size, interpolation=, max_size=None, antialias=None) 功能：支持对PIL或Tensor对象的缩放，关于size的设置有些讲究，请结合代码尝试int方式与tuple方式的差异。int方式是会根据长宽比等比例的缩放图像，这个在AlexNet论文中提到先等比例缩放再裁剪出224*224的正方形区域。 ToTensor 功能：将PIL对象或nd.array对象转换成tensor，并且对数值缩放到[0, 1]之间，并且对通道进行右移。具体地，来看源代码 ...\\Lib\\site-packages\\torchvision\\transforms\\functional.py 下的to_tensor函数 ···python img = img.permute((2, 0, 1)).contiguous() if isinstance(img, torch.ByteTensor): ​ return img.to(dtype=default_float_dtype).div(255) 对PIL对象的通道进行右移，由原来的(H x W x C)变为了(C x H x W) ， 接着对数值进行除以255，若是正常的图像像素，那么数值被缩放到了[0, 1]之间。 Normalize Normalize(mean, std, inplace=False) 功能：对tensor对象进行逐通道的标准化，具体操作为减均值再除以标准差，一般使用imagenet的128万数据R\\G\\B三通道统计得到的mean和std，mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]。相信大家今后再看到这一组数据就明白它们到底怎么来的了。 FiveCrop&TenCrop 这两个方法是AlexNet论文中提及，是一个涨点神器，具体使用方式是一张图片经过多区域裁剪得到5/10张图片，同时放到模型进行推理，得到5/10个概率向量，然后取它们的平均/最大/最小得到这一张图片的概率。 FiveCrop表示对图片进行上下左右以及中心裁剪，获得 5 张图片，并返回一个list，这导致我们需要额外处理它们，使得他们符合其它transforms方法的形式——3D-tensor。 TenCrop同理，在FiveCrop的基础上增加水平镜像，获得 10 张图片，并返回一个 list。 它们的使用与普通的transforms有一点区别，需要代码层面的一些改变，下面就通过具体例子讲解它们的注意事项。 代码 授人以渔：其余的二十多个不在一一介绍，只需要到官方文档上查看，并到配套代码中运行，观察效果即可。 特殊方法使用 PyTorch 不仅可设置对数据的操作，还可以对这些操作进行随机选择、组合，让数据增强更加灵活。 具体有以下4个方法： Lambda RandomChoice RandomOrder RandomApply Lambda 功能：可进行自定义的操作，例如上文的FiveCrop中利用lambda很好的处理了上下游transforms数据维度不一致的问题。transforms.Lambda(lambda crops: torch.stack([ToTensor()(crop) for crop in crops])) RandomChoice 功能：以一定的概率从中选择一个变换方法执行。 RandomOrder 功能：随机打乱一串变换方法。 RandomApply 功能：以一定的概率执行这一串变换方法。这与RandomChoice的区别仅在于它将一组变换看成一个选择单位，RandomChoice是一次选一个，RandomApply是一次选一组（list） 具体使用可配合配套代码 自动数据增强 从transforms丰富的变换方法以及灵活的组合函数可以知道，数据增强的策略可以千变万化，怎样的策略会更好？Google Brain团队就针对这个问题，利用它们的钞能力进行研究，采用RNN网络自动搜索组合策略，寻找较好的数据增强策略，详细可以看这篇文章AutoAugment: Learning Augmentation Strategies from Data。文章中利用RNN搜索出来的策略，可以在Imagenet、Cifar-10和SVHN三个数据集上达到当时的SOTA，pytorch中也提供了基于AutoAugment论文的三个数据集的自动数据增强策略，下面一起来学习它们。 AutoAugmentPolicy 通过论文AutoAugment: Learning Augmentation Strategies from Data我们知道它研究出了针对三个数据集的数据增强策略，在pytorch中同样的提供对应的策略，并设计了AutoAugmentPolicy来指示，直接看源代码，一目了然envs\\pytorch_1.10_gpu\\Lib\\site-packages\\torchvision\\transforms\\autoaugment.py： class AutoAugmentPolicy(Enum): \"\"\"AutoAugment policies learned on different datasets. Available policies are IMAGENET, CIFAR10 and SVHN. \"\"\" IMAGENET = \"imagenet\" CIFAR10 = \"cifar10\" SVHN = \"svhn\" AutoAugment torchvision.transforms.AutoAugment(policy: torchvision.transforms.autoaugment.AutoAugmentPolicy = , interpolation: torchvision.transforms.functional.InterpolationMode = , fill: Optional[List[float]] = None) 功能：自动数据增强方法的封装，支持三种数据增强策略，分别是IMAGENET、CIFAR10 和SVHN 参数： policy ：需要是AutoAugmentPolicy类 interpolation：设置插值方法 fill ：设置填充像素的像素值，默认为0，黑色。 AutoAugment也是一个Module类，具体的变换操作在forward()函数中体现，建议大家看看源代码，pytorch_1.10_gpu\\Lib\\site-packages\\torchvision\\transforms\\autoaugment.py 里面有详细的三组数据增强策略的顺序与参数 例如ImageNet的数据增强策略总共有25组变换，共50个变换： return [ ((\"Posterize\", 0.4, 8), (\"Rotate\", 0.6, 9)), ((\"Solarize\", 0.6, 5), (\"AutoContrast\", 0.6, None)), ((\"Equalize\", 0.8, None), (\"Equalize\", 0.6, None)), ((\"Posterize\", 0.6, 7), (\"Posterize\", 0.6, 6)), ((\"Equalize\", 0.4, None), (\"Solarize\", 0.2, 4)), ((\"Equalize\", 0.4, None), (\"Rotate\", 0.8, 8)), ((\"Solarize\", 0.6, 3), (\"Equalize\", 0.6, None)), ((\"Posterize\", 0.8, 5), (\"Equalize\", 1.0, None)), ((\"Rotate\", 0.2, 3), (\"Solarize\", 0.6, 8)), ((\"Equalize\", 0.6, None), (\"Posterize\", 0.4, 6)), ((\"Rotate\", 0.8, 8), (\"Color\", 0.4, 0)), ((\"Rotate\", 0.4, 9), (\"Equalize\", 0.6, None)), ((\"Equalize\", 0.0, None), (\"Equalize\", 0.8, None)), ((\"Invert\", 0.6, None), (\"Equalize\", 1.0, None)), ((\"Color\", 0.6, 4), (\"Contrast\", 1.0, 8)), ((\"Rotate\", 0.8, 8), (\"Color\", 1.0, 2)), ((\"Color\", 0.8, 8), (\"Solarize\", 0.8, 7)), ((\"Sharpness\", 0.4, 7), (\"Invert\", 0.6, None)), ((\"ShearX\", 0.6, 5), (\"Equalize\", 1.0, None)), ((\"Color\", 0.4, 0), (\"Equalize\", 0.6, None)), ((\"Equalize\", 0.4, None), (\"Solarize\", 0.2, 4)), ((\"Solarize\", 0.6, 5), (\"AutoContrast\", 0.6, None)), ((\"Invert\", 0.6, None), (\"Equalize\", 1.0, None)), ((\"Color\", 0.6, 4), (\"Contrast\", 1.0, 8)), ((\"Equalize\", 0.8, None), (\"Equalize\", 0.6, None)), ] 特别说明：这里反复提到的自动数据增强在实际应用中它们是固定的一组变换策略，这是获得这一组策略的过程是通过强化学习自动搜素的，所以称之为自动数据增强策略。 RandAugment RandAugment是进行N次（num_ops ）变换，变换方法从策略池中随机挑选。pytorch官方文档对于RandAugment给了较高的评价——“RandAugment is a simple high-performing Data Augmentation technique which improves the accuracy of Image Classification models.” 参数： num_ops ：执行多少次变换 magnitude ：每个变换的强度， num_magnitude_bins：与变化强度的采样分布有关 如果对autoaugmentation不熟悉的话，理解RandAugment的参数可能有点困难，这里结合代码看一看就知道了。 RandAugment仍旧是一个Module类，来看它的forward()， def forward(self, img: Tensor) -> Tensor: \"\"\" img (PIL Image or Tensor): Image to be transformed. Returns: PIL Image or Tensor: Transformed image. \"\"\" fill = self.fill if isinstance(img, Tensor): if isinstance(fill, (int, float)): fill = [float(fill)] * F.get_image_num_channels(img) elif fill is not None: fill = [float(f) for f in fill] for _ in range(self.num_ops): op_meta = self._augmentation_space(self.num_magnitude_bins, F.get_image_size(img)) op_index = int(torch.randint(len(op_meta), (1,)).item()) op_name = list(op_meta.keys())[op_index] magnitudes, signed = op_meta[op_name] magnitude = float(magnitudes[self.magnitude].item()) if magnitudes.ndim > 0 else 0.0 if signed and torch.randint(2, (1,)): magnitude *= -1.0 img = _apply_op(img, op_name, magnitude, interpolation=self.interpolation, fill=fill) return img 前面的代码段主要是根据规则获取需要进行的变换方法名称：op_name；变换的强度：magnitude，从 op_index = int(torch.randint(len(op_meta), (1,)).item()) op_name = list(op_meta.keys())[op_index] 这两行代码可以看到，每次采用的变换是随机的选择。 而变换强度magnitude则是根据一个区间里选择，不同变换方法的强度区间在这里： def _augmentation_space(self, num_bins: int, image_size: List[int]) -> Dict[str, Tuple[Tensor, bool]]: return { # op_name: (magnitudes, signed) \"Identity\": (torch.tensor(0.0), False), \"ShearX\": (torch.linspace(0.0, 0.3, num_bins), True), \"ShearY\": (torch.linspace(0.0, 0.3, num_bins), True), \"TranslateX\": (torch.linspace(0.0, 150.0 / 331.0 * image_size[0], num_bins), True), \"TranslateY\": (torch.linspace(0.0, 150.0 / 331.0 * image_size[1], num_bins), True), \"Rotate\": (torch.linspace(0.0, 30.0, num_bins), True), \"Brightness\": (torch.linspace(0.0, 0.9, num_bins), True), \"Color\": (torch.linspace(0.0, 0.9, num_bins), True), \"Contrast\": (torch.linspace(0.0, 0.9, num_bins), True), \"Sharpness\": (torch.linspace(0.0, 0.9, num_bins), True), \"Posterize\": (8 - (torch.arange(num_bins) / ((num_bins - 1) / 4)).round().int(), False), \"Solarize\": (torch.linspace(255.0, 0.0, num_bins), False), \"AutoContrast\": (torch.tensor(0.0), False), \"Equalize\": (torch.tensor(0.0), False), } TrivialAugmentWide TrivialAugment是采用NAS技术搜索得到的一组数据增强策略，推荐阅读原文TrivialAugment: Tuning-free Yet State-of-the-Art Data Augmentation 使用方法也非常简单，直接看代码即可。 想了解细节，请查看D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\Lib\\site-packages\\torchvision\\transforms\\autoaugment.py TrivialAugment核心 def _augmentation_space(self, num_bins: int) -> Dict[str, Tuple[Tensor, bool]]: return { # op_name: (magnitudes, signed) \"Identity\": (torch.tensor(0.0), False), \"ShearX\": (torch.linspace(0.0, 0.99, num_bins), True), \"ShearY\": (torch.linspace(0.0, 0.99, num_bins), True), \"TranslateX\": (torch.linspace(0.0, 32.0, num_bins), True), \"TranslateY\": (torch.linspace(0.0, 32.0, num_bins), True), \"Rotate\": (torch.linspace(0.0, 135.0, num_bins), True), \"Brightness\": (torch.linspace(0.0, 0.99, num_bins), True), \"Color\": (torch.linspace(0.0, 0.99, num_bins), True), \"Contrast\": (torch.linspace(0.0, 0.99, num_bins), True), \"Sharpness\": (torch.linspace(0.0, 0.99, num_bins), True), \"Posterize\": (8 - (torch.arange(num_bins) / ((num_bins - 1) / 6)).round().int(), False), \"Solarize\": (torch.linspace(255.0, 0.0, num_bins), False), \"AutoContrast\": (torch.tensor(0.0), False), \"Equalize\": (torch.tensor(0.0), False), } 小结 本小节详细剖析transforms运行机制，熟悉内部工作原理，大家可自行编写变换方法嵌入模型训练中。同时教授大家学习使用transforms的二十多种方法的方法——授人以渔，最后介绍了自动数据增强策略的原理及代码实践。 希望大家利用好数据增强，给自己的模型涨点，一定要记住数据增强的方向是朝着测试集（真实应用场景情况下）的数据分布、数据情况去变换，千万不要什么都往上加。 预告：原计划在本章节介绍albumentations，但由于本章未涉及图像分割、目标检测，以及本章内容也不少了，因此将albumentations放到后续章节，适时进行讲解。 为什么要用albumentations？ pytorch的transforms有什么不足么？ 当然有不足了， pytorch的transforms在处理图像分割与目标检测这一类需要图像与标签同时变换的时候不太方便（也能处理，只是不方便）。尽请期待。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-3/3.5-torchvision-dataset.html":{"url":"chapter-3/3.5-torchvision-dataset.html","title":"3.5 torchvision 经典dataset学习","keywords":"","body":"3.5 torchvision 经典dataset学习 前面已经学习了Dataset，DataLoader，以及常用的函数，已经可以满足绝大多数的需求，但距离熟练编写自己的Dataset可能还有一段距离。 为了让大家能轻松掌握各种情况下的dataset编写，本小节对torchvision中提供的几个常见dataset进行剖析，观察它们的代码共性，总结编写dataset的经验。 X-MNIST 由于MNIST数据使用广泛，在多领域均可基于这个小数据集进行初步的研发与验证，因此基于MNIST数据格式的各类X-MNIST数据层出不穷，在mnist.py文件中也提供了多个X-MNIST的编写，这里需要大家体会类继承。 可以看到FashionMNIST、KMNIST两个dataset仅需要修改数据url（mirrors、resources）和类别名称（classes），其余的函数均可复用MNIST中写好的功能，这一点是面向对象编程优点的体现。 来看dataset的 getitem，十分简洁，因为已经把图片和标签处理好，存在self.data和self.targets中使用了： def __getitem__(self, index: int) -> Tuple[Any, Any]: img, target = self.data[index], int(self.targets[index]) img = Image.fromarray(img.numpy(), mode='L') if self.transform is not None: img = self.transform(img) if self.target_transform is not None: target = self.target_transform(target) return img, target 代码参阅：D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\Lib\\site-packages\\torchvision\\datasets\\mnist.py cifar-10 cifar-10是除MNIST之外使用最多的一个公开数据集，同样的来看它dataset的编写，奔主题 def __getitem__(self, index: int) -> Tuple[Any, Any]: img, target = self.data[index], self.targets[index] # doing this so that it is consistent with all other datasets # to return a PIL Image img = Image.fromarray(img) if self.transform is not None: img = self.transform(img) if self.target_transform is not None: target = self.target_transform(target) return img, target 核心代码还是这一行： img, target = self.data[index], self.targets[index] 那么去看看self.data和self.targets是如何从磁盘上获取的？通过代码搜索可以看到它们来自这里(D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\Lib\\site-packages\\torchvision\\datasets\\cifar.py CIFAR10 类的 init函数)： # now load the picked numpy arrays for file_name, checksum in downloaded_list: file_path = os.path.join(self.root, self.base_folder, file_name) with open(file_path, 'rb') as f: entry = pickle.load(f, encoding='latin1') self.data.append(entry['data']) if 'labels' in entry: self.targets.extend(entry['labels']) else: self.targets.extend(entry['fine_labels']) self.data = np.vstack(self.data).reshape(-1, 3, 32, 32) self.data = self.data.transpose((0, 2, 3, 1)) # convert to HWC 这一段的作用于MNIST的_load_data()， 我们的_get_img_info()一样，就是读取数据信息。 总结： getitem函数中十分简洁，逻辑简单 初始化时需完成数据信息的采集，存储到变量中，供getitem使用 VOC 前面介绍的都是玩具数据集，比较复杂的目标检测数据会不会很难写？答案是，不会，仍旧可以用我们分析出来的逻辑进行编写。 下面来看第一个大规模应用的目标检测数据集——PASCAL VOC， D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\Lib\\site-packages\\torchvision\\datasets\\voc.py的 VOCDetection类的getitem函数： def __getitem__(self, index: int) -> Tuple[Any, Any]: \"\"\" Args: index (int): Index Returns: tuple: (image, target) where target is a dictionary of the XML tree. \"\"\" img = Image.open(self.images[index]).convert(\"RGB\") target = self.parse_voc_xml(ET_parse(self.annotations[index]).getroot()) if self.transforms is not None: img, target = self.transforms(img, target) return img, target 更简洁了，与我们的案例中的getitem一样一样的，那么images和annotations从哪里来？相比大家已经知道答案了，那就是初始化的时候根据数据格式、数据组织结构，从磁盘中读取。 COCO 说到目标检测就不得不提COCO数据集，COCO数据集是微软提出的大规模视觉数据集，主要用于目标检测，它从数据量、类别量都远超VOC，对于深度学习模型的落地应用起到了推动作用。 对于CV那么重要的COCO，它的dataset难吗？答案是，不，更简单了。整个类仅40多行！ getitem函数连注释都显得是多余的： def __getitem__(self, index: int) -> Tuple[Any, Any]: id = self.ids[index] image = self._load_image(id) target = self._load_target(id) if self.transforms is not None: image, target = self.transforms(image, target) return image, target 其实，这一切得益于COCO的应用过于广泛，因此有了针对COCO数据集的轮子——pycocotools，它非常好用，建议使用COCO数据集的话，一定要花几天时间熟悉pycocotools。pycocotools里面把getitem需要的东西都准备好了，因此这个类只需要40多行代码。 小结 本章从数据模块中两个核心——Dataset&Dataloader出发，剖析pytorch是如何从硬盘中读取数据、组装数据和处理数据的。在数据处理流程中深入介绍数据预处理、数据增强模块transforms，并通过notebook的形式展示了常用的transforms方法使用，最后归纳总结torchvision中常见的dataset，为大家将来应对五花八门的任务时都能写出dataset代码。 下一章将介绍模型模块，敬请期待。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-4/":{"url":"chapter-4/","title":"第四章 PyTorch 模型模块","keywords":"","body":"第四章 PyTorch 模型模块 第四章 PyTorch 模型模块 4.1 Module&Parameter 4.2 Module的容器 4.3 常用网络层 4.4 Module常用API函数 4.5 Hook函数及Grad-CAM 4.6 经典模型代码分析 4.7 权重初始化方法 第四章简介 上一章介绍了数据相关的Dataset、DataLoader、transforms，已经能把数据从磁盘中有序的读取并处理以及加载成batch形式。接下来就需要一个强大的模型来处理它，本章就针对模型部分进行展开，这也是深度学习最核心的地方，其中包括一个模型如何创建各网络层、各网络层如何搭建、参数如何管理与初始化、如何截取某些层的特征图等一系列问题。 首先介绍核心类——Module 再介绍常用的模块容器——Containers 接着讲解常用网络层的使用 再学习module常用函数与hook函数应用 最后介绍权重初始化方法——nn.init Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-4/4.1-module&Parameter.html":{"url":"chapter-4/4.1-module&Parameter.html","title":"4.1 Module&Parameter","keywords":"","body":"4.1 Module & parameter Module初认识 深度学习指深度神经网络，也是我们常说的模型（Model），一个模型包含很多个网络层，多个网络层拼接构建成一个模型。在pytorch中模型是一个Module，各网络层、模块也是Module，本小节就介绍模型/模块的抽象——Module。后续不加以说明的话，模型、模块、网络层都可指代Module。 Module是所有神经网络的基类，所有的模型都必须继承于Module类，并且它可以嵌套，一个Module里可以包含另外一个Module。要想理解清楚这句话就必须清楚了解一个Module是如何工作的。在第二章我们就构建了一个Module——TinnyCNN，第三章讲解transform的时候也用到了Module，并且知道它的前向传播具体执行是在forward()函数当中，其实Module定义了一些列属性来管理模块的功能，分别用8个有序字典进行管理，分别是： self._modules = OrderedDict() self._parameters = OrderedDict() self._buffers = OrderedDict() self._backward_hooks = OrderedDict() self._forward_hooks = OrderedDict() self._forward_pre_hooks = OrderedDict() self._state_dict_hooks = OrderedDict() self._load_state_dict_pre_hooks = OrderedDict() 它们的作用分别是 modules : 存储管理nn.Module类 parameters: 存储管理nn.Parameter类 buffers：存储管理缓冲属性，如BN层中的running_mean *_hooks：存储管理钩子函数 讲到这，大家估计很懵，因为与前面接触到的内容完全搭不上边。但是这些又是Module的核心知识点，为了降低大家的学习曲线斜率，在这里暂且只需要知道一个Module有这些关键属性用于管理Module，以及在哪里找到它们——debug模式下的Protected Attributes看到它们的详情。 forward函数 除了八大核心属性之外，还有一个函数不得不了解，那就是forward函数，forward之于Module等价于getitem之于Dataset。forward函数是模型每次调用的具体实现，所有的模型必须实现forward函数，否则调用时会报错 Traceback (most recent call last): File \"E:/pytorch-tutorial-2nd/code/chapter-2/02_COVID_19_cls.py\", line 150, in main() File \"E:/pytorch-tutorial-2nd/code/chapter-2/02_COVID_19_cls.py\", line 111, in main outputs = model(data) File \"D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1102, in _call_impl return forward_call(*input, **kwargs) File \"D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 201, in _forward_unimplemented raise NotImplementedError NotImplementedError Process finished with exit code 1 到这里，总结一下Module： Module是所有模型的基类 每个module有8个字典管理它的核心属性 一个module可以包含多个子module 一个module相当于一个运算，必须实现forward函数 一个模型的创建 下面通过简单的代码慢慢去熟悉Module，回顾TinnyCNN的创建与使用，可以总结出一个模型的创建需要考虑两个要素： 构建子模块：构建网络所需要的网络层，如卷积层，池化层，全联接层等等 拼接子模块：在forward函数中定义需要执行的功能，即将子模块以一定的方式拼接起来，完成对数据的前向传播 模型的创建就像搭积木，首先收集到需要的基础部件，是三角形、正方形还是六边形，然后以一定的方式拼接起来，如果要一个屋子就先放正方形，然后放三角形。如果需要一个汽车就先放两个圆形，再放一个长方形。 同理，模型搭建也是，先知道有哪些网络层是需要的，那么再init函数里进行初始化，先让此类获得这些网络层可用。具体如何用，需要在forward函数中写清楚。就像下面这个图一样。 知道了Module有哪些关键属性，以及一个模型如何创建，下面回顾2.2小结的COVID-19分类代码，采用debug方式观察TinnyCNN的创建——model = TinnyCNN(2)， 以及它的推理： outputs = model(data) TinnyCNN的创建 代码在：code/chapter-2/02_COVID_19_cls.py 模型实例化的代码是这行： model = TinnyCNN(2) 我们打下断点，采用debug运行，进行分析如下： 进入 TinnyCNN 类的init函数：这里进行初始化，可以看到第一行就是调用父类的init函数，父类是Module，因此我们继续step into进去看看； 来到 Module类的init函数：这里会初始化那8个有序字典，以及一些关键属性，如training等。我们跳出去； 回到TinnyCNN 类的init函数：父类init函数结束，就来到自定义的组件定义部分，这里我们需要一个卷积层、一个全连接层供搭积木使用。这里的nn.Conv2d也是一个module，大家可以自行step into进去观察它的创建，这里暂且知道它是一个module即可。同理，nn.Linear也是。init函数里收集了需要搭积木的组件，下面跳出去。 回到主代码：model = TinnyCNN(2)，这样一个模型就创建好了，我们可以看到model下面就有了这些属性： 重点看红框的三个内容，分别是convolution_layer、fc和_modules。前两个没啥好说的，是init函数中自定义的类属性名称，而第三个_modules什么时候“悄悄”地记录了我们自己定义的convolution_layer和fc呢？ 这就需要大家了解一下python的基础了，请看这行代码： self.convolution_layer = nn.Conv2d(1, 1, kernel_size=(3, 3)) 在类属性赋值的时候，即这行代码中的“=”号，会调用类的__setattr__方法，在module.py的1180行代码是setatrr的实现，里面会将“=”号右边的值放到相应的地方去，如module会放到_modules里，parameter会放到_parameters里。 至此，对于模型的创建流程有了解后，下面看看模型的推理是如何进行的，它可不是简单的进入forward函数就完事了，中间还有复杂的辅助功能，一起往下看。 TinnyCNN的推理 继续采用debug，往下看。 先来到模型调用的地方：outputs = model(data)，采用step into进入； 来到Module类的call_impl函数：熟悉python的朋友就疑惑了，为什么进入的是它而不是\\_call__函数？（python规定可被调用的对象，其实现是在__call__\\函数里）其实并没有错，只Module类对call函数重命名了罢了，可以看到1148行 __call__ : Callable[..., Any] = _call_impl 在早期版本的pytorch中还没有这一层包装，请各位专家指导一下为什么采用这种方式？ 在_call_impl函数当中才会调用forward函数来实现数据的前向传播，但module除了forward调用之外，还有一些辅助功能，那就是一系列的hook函数的使用，这里暂且放下，后续会展开hook函数的作用。这里只需要关心怎么进入forward的。如果没有设置任何hook函数，则直接进行forward函数的调用 if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks or _global_forward_hooks or _global_forward_pre_hooks): return forward_call(*input, **kwargs) step into 进入 return forward_call(input, *kwargs)，就会发现来到了自定义的forward函数。 来到TinnyCNN类的forward函数：这里就是我们如何拼接网络层，组装积木的地方了。 通常会在这里调用其他module来完成数据的处理，例如使用nn.Conv2d来进行卷及操作，除了使用module对象，其它的数学运算、功能函数（如torch.nn.functionals里的系列函数）、for循环等都是可以使用的。 值得说的一点是，一些激活函数它没有可训练参数，也不是module类，因此会在forward函数中直接调用，而不需要在init中初始化。比如 ：out = F.relu(self.conv1(x)) 中的F.relu。 最后要强调一点是：forward函数中需要注意前后层数据的格式，类似transforms的实现一样，上一层的输出一定要对得上下一层的输入，否则会报错，常见的报错是Linear层接收到了不合适的数据。建议大家把TinnyCNN的forward函数的第二行注释掉：# x = x.view(x.size(0),-1)，运行代码并观察错误，这个错误是90%以上的朋友都会遇到的：RuntimeError: mat1 and mat2 shapes cannot be multiplied (12x6 and 36x2)。 到这里一个模型的搭建以及前向推理就很清晰了，构建自己的网络只需要三步： 写一个类继承于Module init函数中把需要的网络层创建好 forward函数中把模型如何搭建的规则写好 Parameter 在Module中有一个重要的对象——Parameter，参数。它继承于Tensor，与Tensor差别不太大，主要作用是用来区分可训练的参数与常规的Tensor。 在这里要做一下说明，权重、参数和超参数，它们的含义。一般情况下模型的权重就表示模型的参数，它们是可训练的，通过反向传播算法不断的更新；而超参数如卷积核大小、学习率、迭代次数是不能通过反向传播算法去更新的。很明显Parameter就指模型的参数，如卷积层的卷积核权重和偏置，Linear层的权重和偏置，BN层的α和β等等。 Module中对于参数是采用_parameters 进行管理的，并且提供相应的api可以对module内所有参数进行调用与读取。回顾2.2 COVID-19的优化器实例化这行代码： optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4) 代码中表示把model.parameters()返回的内容给优化器，让优化器更新model.parameters()，从这里可进一步理解parameter类的作用，以及各网络层它们的参数都会初始化为parameter类。 可以看看 D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\Lib\\site-packages\\torch\\nn\\modules\\conv.py的131行代码 self.weight = Parameter(torch.empty( (out_channels, in_channels // groups, *kernel_size), **factory_kwargs)) 对默认的卷积核采用empty初始化数值，然后包装成Parameter类。 小结 到这里，一个简单模型是如何创建、如何工作的我们就已经讲解完了。但随着深度神经网络的拓扑结构越来越复杂，层数越来越多，只靠上面的方法无法很好的构建神经网络，还需要借助一些容器把固定的模块封装起来，循环地进行调用。下一节将介绍Module的容器，包括以下5个 - - Sequential A sequential container. ModuleList Holds submodules in a list. ModuleDict Holds submodules in a dictionary. ParameterList Holds parameters in a list. Parameter DictHolds parameters in a dictionary. Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-4/4.2-containers.html":{"url":"chapter-4/4.2-containers.html","title":"4.2 Module的容器","keywords":"","body":"4.2 Module容器——Containers 容器的概念出现在日常生活的方方面面，每天喝水的杯子用来装一些水，书包用来装一些办公用品，衣柜用来装一些衣服。因此，不难抽象出来容器，它是将一些东西放到一个地方进行有效管理、使用。 在深度学习模型里面，有一些网络层需要放在一起使用，如 conv + bn + relu 的组合。在module的容器是将一组操作捆绑在一起的东西，在pytorch官方文档中把Module也定义为Containers，或许是因为“Modules can also contain other Modules”。 对于Module类可查看4.1小结，这里详细介绍两个常用的容器Sequential与ModuleList，同时介绍ModuleDict，ParameterList，ParameterDict。 Sequential sequential是pytorch里使用最广泛的一个容器，它的作用是将一系列网络层按固定的先后顺序串起来，当成一个整体，调用时数据从第一个层按顺序执行到最后一个层。回顾一下transforms的Compose就可以体会到按顺序的含义了。 sequential可以直接传module，也可以传OrderedDict，OrderedDict可以让容器里的每个module都有名字，方便调用。 请看两段官方代码： model = nn.Sequential( nn.Conv2d(1,20,5), nn.ReLU(), nn.Conv2d(20,64,5), nn.ReLU() ) # Using Sequential with OrderedDict. This is functionally the # same as the above code model = nn.Sequential(OrderedDict([ ('conv1', nn.Conv2d(1,20,5)), ('relu1', nn.ReLU()), ('conv2', nn.Conv2d(20,64,5)), ('relu2', nn.ReLU()) ])) 来看一个实际案例： AlexNet是新一代CNN的开山之作，也是这一轮深度学习潮流里，计算机视觉任务的开山之作。对于现代CNN，通常会把前面的卷积层、池化层称为特征提取部分，最后的全连接层当作分类器，这一点在代码编写上将有所体现。 例如，在D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\Lib\\site-packages\\torchvision\\models\\alexnet.py 下的AlexNet，它把前面的卷积池化都放到Sequential这个容器当中，并且命名为self.features。在最后还有一个名为self.classifier的Sequential容器，它包含3个Linear层及激活函数、Dropout。这里正如下图所示，把模型大卸两块。 def forward(self, x: torch.Tensor) -> torch.Tensor: x = self.features(x) x = self.avgpool(x) x = torch.flatten(x, 1) x = self.classifier(x) return x ​ Sequential的调用 Sequential容器把一堆module包起来之后，它在forward中是如何使用的呢？ 下面请看配套代码，主要采用debug模式，观察Alexnet的forward中，两个Sequential容器是如何forward的，同时也要看看Alexnet这个模型的属性。 在 output = model(fake_input) 设置断点，step into，然后进入熟悉的_call_impl，关于module内部的代码这里直接略过，不熟悉的朋友请回到4.1小节阅读。 这里直接跳到Alexnet类的forward函数，第一行就是执行x = self.features(x)，继续step into观察这个sequential容器是如何工作的，进入它 来到了Module类下的_call_impl函数：没错，又来到了_call_impl，因为sequential它也是一个module，因此在调用self.features的时候，会进入_call_impl， 下面需要大家有耐心的进入self.features的forward函数，其实就是1102行进去； 来到Sequential类的forward函数，它十分简洁，如下所示： def forward(self, input): ​ for module in self: ​ input = module(input) ​ return input 这段代码是不是十分的熟悉呢？ transforms当中也是这样去实现一个Compose里的变换的。 从此处可知道，Sequential类的功能是将一系列网络层按固定的先后顺序串起来，当成一个整体，调用时数据从第一个层按顺序执行到最后一个层，各层之间的数据必须能对接起来。 接着回到 Alexnet的forward函数下，观察一下Alexnet这个module的属性 重点看_modules属性，它有3个key-value，其中有2个是Sequential类，因为Sequential属于module类，继续展开一个Sequential来看看 可以看到该容器下的一系列网络层，并且是排了序的，这些对于后续理解网络结构、理解网络权重加载的key是十分重要的 ModuleList ModuleList 是将各个网络层放到一个“列表”中，便于迭代的形式调用。 ModuleList与python List的区别 这里注意是“列表”而不是列表，因为ModuleList管理的module与python的List管理的module是有不同的，大家是否还记得module的setattr函数？在那里会对类属性进行判断管理，只有ModuleList里的网络层才会被管理，如果是List里的网络层则不会被管理，也就不能迭代更新了。 ModuleList 代码使用 假设要构建一个10层的全连接网络，如果用Sequential，那就要手写10行nn.Linear，而用ModuleList是这样的： class MyModule(nn.Module): def __init__(self): super(MyModule, self).__init__() self.linears = nn.ModuleList([nn.Linear(10, 10) for i in range(10)]) # self.linears = [nn.Linear(10, 10) for i in range(10)] # 观察model._modules，将会是空的 def forward(self, x): for sub_layer in self.linears: x = sub_layer(x) return x 需要对python的 list进行一个ModuleList封装，这样才可以在model的_modules属性下看到创建的10个Linear层。 推荐大家看看class ModuleList(Module)的实现，里边并不会像Sequential那样提供forward，即管理的网络层由用户自行调用，可以for循环全用，也可以通过if判断，有条件的选择部分网络层使用。同时ModuleList也提供了类似List的方法，insert\\append\\extend等。 ModuleDict ModuleList可以像python的List一样管理各个module，但对于索引而言有一些不方便，因为它没有名字，需要记住是第几个元素才能定位到指定的层，这在深度神经网络中有一点不方便。 而ModuleDict就是可以像python的Dict一样为每个层赋予名字，可以根据网络层的名字进行选择性的调用网络层。 请看代码 class MyModule2(nn.Module): def __init__(self): super(MyModule2, self).__init__() self.choices = nn.ModuleDict({ 'conv': nn.Conv2d(3, 16, 5), 'pool': nn.MaxPool2d(3) }) self.activations = nn.ModuleDict({ 'lrelu': nn.LeakyReLU(), 'prelu': nn.PReLU() }) def forward(self, x, choice, act): x = self.choices[choice](x) x = self.activations[act](x) return x ParameterList & ParameterDict 除了Module有容器，Parameter也有容器。与ModuleList和ModuleDict类似的，Paramter也有List和Dict，使用方法一样，这里就不详细展开，可以参考Module的容器。 可以看两段官方文档代码感受一下 class MyModule(nn.Module): def __init__(self): super(MyModule, self).__init__() self.params = nn.ParameterDict({ 'left': nn.Parameter(torch.randn(5, 10)), 'right': nn.Parameter(torch.randn(5, 10)) }) def forward(self, x, choice): x = self.params[choice].mm(x) return x # ParaemterList class MyModule(nn.Module): def __init__(self): super(MyModule, self).__init__() self.params = nn.ParameterList([nn.Parameter(torch.randn(10, 10)) for i in range(10)]) def forward(self, x): # ParameterList can act as an iterable, or be indexed using ints for i, p in enumerate(self.params): x = self.params[i // 2].mm(x) + p.mm(x) return x 小结 随着深度神经网络拓扑结构越来越复杂，网络模块多、杂、乱，因此需要Module容器来管理、组织各个网络层，便于forward函数中调用。 使用频率最高的是Sequential，其次是ModuleList，其余的均为进阶用法，在各类魔改网络中才会涉及。 这里深刻理解Sequential的机制、理解一个module是如何把Sequential里的module管理到自己的_modules属性中，对于后续使用模型是非常重要的。 熟悉了Module类，各种容器封装，下一小节将介绍一些常用的网络层，如卷积、池化、全连接、激活函数等。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-4/4.3-common-module.html":{"url":"chapter-4/4.3-common-module.html","title":"4.3 常用网络层","keywords":"","body":"4.3 常用网络层 本小节将介绍几个常用的layers，核心目的是传授如何学习各layers的方法，今后更多layers也可自行从官方文档中学习。 Convolutional Layers 卷积整体分两大类，正常卷积与转置卷积（Transpose Convolution），除此之外还有Lazy系列的正常卷积与转置卷积，Lazy系列就是懒惰系列，为那些懒得计算输入特征图的通道数的人设计的，经过第一次forward之后，该网络层的in_channels将被确定。 下面通过官方文档详细学习Conv2d这个卷积层，在文档中会详细介绍该层的功能，各参数含义，计算公式，以及示例代码。 torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros') 主要功能：对多个二维平面组成的信号进行二维卷积 主要参数： in_channels (int) – Number of channels in the input image。输入这个网络层的图像的通道数是多少。 out_channels (int) – Number of channels produced by the convolution。此网络层输出的特征图的通道数是多少，等价于卷积核数量是多少。 kernel_size (int or tuple) – Size of the convolving kernel。卷积核大小。 stride (int or tuple, optional) – Stride of the convolution. Default: 1。卷积核卷积过程的步长。 padding (int, tuple or str, optional) – Padding added to all four sides of the input. Default: 0。对于输入图像的四周进行填充的数量进行控制，可指定填充像素数量，也可以指定填充模式，如\"same\", \"valid\"，具体含义参见文档，这是从TF中借鉴过来的。 padding_mode (string, optional) – 'zeros', 'reflect', 'replicate' or 'circular'. Default: 'zeros'。填充的像素值如何确定。默认填充0。 dilation (int or tuple, optional) – Spacing between kernel elements. Default: 1。孔洞卷积的孔洞大小。 groups (int, optional) – Number of blocked connections from input channels to output channels. Default: 1。分组卷积的分组。 bias (bool, optional) – If True, adds a learnable bias to the output. Default: True。是否采用偏置。 nn.Conv2d是图像领域里99%模型都用到的，它的计算公式及细节需要大家了如指掌，具体公式如下：` 这里建议大家结合各种动图进行学习，推荐这个repo， Pooling Layers Pooling layer叫池化层，池化是形象词，就像下雨天篮球场上低洼的地方会聚集周围的雨水一样，由大变小的过程。 自然它的作用是将特征图分辨率变小，通常减小一半。如下图所示，相同颜色的区域”池化“为1个像素，4x4的图像变为了2x2的图像。 图片来源:https://www.geeksforgeeks.org/cnn-introduction-to-pooling-layer/ 1个像素代替4个像素，那应该用什么值呢？针对这个问题的解决方法，可对池化层进行划分为最大值池化、平均值池化、分数阶池化、基于范数的池化。分别对应torch.nn中的Maxpool, Avgpool, FractionalMaxPool, LPPool。 由于它们只是在计算像素时才用的方法不同，下面就以Maxpool为例讲解池化层。 torch.nn.MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False) 功能：2D最大池化 参数： kernel_size – 池化窗口大小 stride – 滑窗步长 padding – 原图填充大小 dilation – 孔洞大小 return_indices – 是否返回最大值所在位置，主要在 torch.nn.MaxUnpool2d 中使用，是上采样的一种策略 ceil_mode – 当无法整除时，是向下取整还是向上取整，默认为向下。 池化层输出特征图的大小计算公式如下，细心的朋友会发现它与卷积层是一样的。 针对最大池化还有一个特殊的地方是它可以记录最大值所在的位置，供上采样时（MaxUnpool2d）所用，这个在图像分割任务中会有涉及。MaxUnpool2d的使用非常简单，参数设置很容易。原型如下： torch.nn.MaxUnpool2d(kernel_size, stride=None, padding=0)，具体使用可看配套代码。 自适应池化层 上面针对池化像素如何取值进行划分，其实针对窗口大小的选择也可划分，还有另外一种特殊的池化方法，那就是AdaptiveXpool， 它的作用是自适应窗口大小，保证经过池化层之后的图像尺寸是固定的，这个在接入全连接层之前经常会见到。 使用也很方便，只需要设置想要的输出大小即可，详细可见配套代码。torch.nn.AdaptiveMaxPool2d(output_size, return_indices=False) Padding Layers Padding layer在许多魔改网络中常用到，功能是给特征图周围填充一定的像素，调整特征图分辨率的一种方法。既然是填充就涉及两个问题，填充多少个像素？像素应该如何确定？ 针对第二个问题，可将padding layer划分为三类，镜像填充、边界重复填充，指定值填充、零值填充，分别对应nn的三大类，nn.ReflectionPad2d， nn.ReplicationPad2d， nn.ZeroPad2d， nn.ConstantPad2d，使用非常简单，详细可见配套代码。 Linear Layers Linear Layers包含4个层分别是nn.Identity，nn.Linear， nn.Bilinear， nn.LazyLinear nn.Identity 是恒等映射，不对输入做任何变换，它通常用于占位。 nn.Linear 就是大家熟悉的全连接层(Fully Connection Layer)，可实现 y= Wx + b nn.Bilinear 是双线性层，它有两个输入，实现公式 y = x1Wx2 +b nn.LazyLinear 是nn.Linear的lazy版本，也就是懒惰的Linear层，它在第一次推理时自动根据输入特征图的尺寸来设定in_features，免去了手动计算in_features的麻烦。 Linear层十分简单，就不用代码演示了。 Normaliation Layers Normaliation Layers 里包含主流的标准化网络层，分别有BN、LN、IN、GN以及早期的LRN。这一些列的层已经成为现在深度学习模型的标配，它们充当一种正则，对数据的分布进行变换，使数据分布变到0均值，1标准差的形式。实验结果发现这样做可以加速模型训练，让模型更稳定，精度更高。 其中最出名的当属2015年提出的BatchNorm, 来自于Google团队的Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift，关于BN的介绍网上有很多文章，大家可自行学习，在代码实现上我们需要熟悉网络层内部的参数，以及训练与推理过程中的差异。 BatchNorm 会对输入进行减均值、除以标准差、乘以γ、加β的操作。如下图所示： 其中γ与β是Parameter，是可训练的参数，与卷积层的卷积核、FC层的权重一样，容易理解。 均值与标准差就没那么简单了，在训练过程，它们是通过指数移动平均统计得来，在测试时则是用固定的、不会再变化的均值和方差。 从此也可知道，当模型设置在训练状态(model.train() )与推理状态(model.eval() )时，BN层的操作输出是会不一样的。 方法原型如下： torch.nn.BatchNorm2d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, device=None, dtype=None) num_features – 输入的通道数，该参数将决定BN层有多少个γ和β eps – 分母增加的一个小数，防止除以0，默认值为1e-5 momentum – 指数滑动平均的动量值，Default: 0.1 affine – 是否执行乘以γ、加β的操作，要理解为什么叫affine需要去看论文。Default: True track_running_stats – 是否需要执行记录统计均值、统计方差。默认是开启的，如果不开启，则计算时的均值方差只来自当前batch的计算值。 Default: True 具体使用方法详细可见配套代码，请尝试调整各个参数，观察输出的变化以及网络层本身参数的变化。 BN提出之后几乎成了深度学习模型的标配，但在一些任务中BN的均值、方差计算方式就不太适用了，针对均值、方差的统计方式不同，就有了GN、LN、IN。 GN是针对batch size小（一些任务占显存大，只能用小batch跑），统计的均值方差存在较大差异而提出的分组进行统计，详细参见：Group Normalization LN是针对RNN这样的序列网络设计的，以层为单位进行统计均值、方差，详细参见：Layer Normalization IN是针对风格迁移这类GAN任务中，不同风格实例的差异较大，以实例为单位进行统计均值、方差，详细参见：Instance Normalization: The Missing Ingredient for Fast Stylization LRN是2012年深度学习图像领域开山之作——AlexNet中采用的正则化方法，现在很少采用，详细参见：ImageNet Classifification with Deep Convolutional Neural Networks Dropout Layers Dropout——随机失活和LRN一样在Alexnet论文中所采用，以防止模型过拟合，针对它的正则化作用探讨可参见由Hinton一作发表的论文Improving neural networks by preventing co-adaptation of feature detectors。 Dropout 的操作非常简单，以概率p随机的让部分神经元暂时失活，失活表示它不与任何神经元连接，如下图所示： 图片出自：《Dropout: A Simple Way to Prevent Neural Networks from Overfitting》 训练过程的每一次forward，都会重新进行随机失活。在测试（推理）过程，所有神经元都参与工作，不再采用随机失活。更详细的操作及理论分析，推荐阅读《Dropout: A Simple Way to Prevent Neural Networks from Overfitting》。 Dropout使用注意事项： Dropout通常用于nn.Linear层之前； Dropout执行后，神经元个数会减少，导致数据尺度发生变化. 论文中给出的方法是在测试时，需要将神经元数据尺度缩放 1/p倍，因为在训练时候减少了p倍。（p为随机失活的概率）。但在工程应用的时候，最好是减少推理的步骤，于是pytorch把数据尺度的缩放弄到了训练中，在训练时，对数据进行1/(1-p)的放大。（Furthermore, the outputs are scaled by a factor of 1/(1-p) during training. ） 关于数据尺度缩放，这里设计了验证实验，可到配套代码中运行并查看。 Alpha Dropout Dropout的随机失活会导致数据分布的变化，而数据分布对于模型训练的稳定是非常关键的，因此有针对这个问题提出了一种保持输入均值和方差不变的Dropout——Alpha Dropout。理论分析建议阅读论文Self-Normalization Neural Networks FeatureAlphaDropout是基于通道维度进行的，并且不同于Dropout的置零，它是将神经元设置为SELU激活函数的负饱和值，通常 Alpha Dropout都是搭配SELU激活函数的，具体推导还是要看论文Self-Normalization Neural Networks，一篇102页的论文。 Non-linear Layers 非线性激活函数是深度学习的命根子，倘若没有非线性变换函数，那么1亿层的Linear层堆叠，也只能等价于1层网络（通过矩阵乘法法则可推导）。因此非线性激活函数是深度学习之所以能称之为深度的重要因素。 对于非线性激活函数，pytorch划分为了两大类，这是非常合理的！分别是Non-linear Activations (weighted sum, nonlinearity) 和Non-linear Activations (other)。 其实可以作用进行划分 为了对神经元进行非线性变换的称为非线性激活函数 为了对输出神经元进行Softmax的、变为概率分布形式的称为特殊非线性激活函数 更通俗的划分是： 非softmx的； softmax系列； 对于非softmax，大家肯定不陌生，如sigmoid、tanh、ReLU、PReLU等，这些就不过多介绍，请大家自行查阅文档 对于softmax需要简单讲一讲，softmax的作用是将一个向量转换为一个概率分布的形式，以便于实现loss的计算，计算过程如下图所示： 计算公式如下： 看着一头雾水，其实很好理解。一个概率向量它的要求至少有这两个 非负 求和等于1 对于非负，用上幂函数，就可以实现了； 对于求和对于1，那就所有元素除以一个求和项，所有元素再加起来的时候分子就等于分母，自然求和等于1了，Softmax的设计思路真巧妙！ 对于Softmax系列的激活函数，可参考文档 小结 到这里对pytorch常用的网络层接口进行了介绍与代码分析，由于深度学习模型发展迅速，难以详尽介绍每一个网络层的使用，但pytorch都有详细的文档可以学习，希望大家可以通过本节内容学习如何学习pytorch的系列函数、类方法使用。 本小节配套代码中有这些网络层的演示： 更多更详细的网络层使用介绍，可查看文档中的目录，这里简介每个主题的内容 Containers： 模型容器 Convolution Layers：卷积层 Pooling layers：池化层 Padding Layers：填充层 Non-linear Activations (weighted sum, nonlinearity)：非线性激活函数 Non-linear Activations (other)：Softmax系列激活函数 Normalization Layers：标准化层 Recurrent Layers：RNN 网络层 Transformer Layers： Transformer 网络层 Linear Layers：线性层 Dropout Layers： 随机失活层 Sparse Layers：稀疏网络层 Distance Functions：计算距离函数 Loss Functions：计算损失函数 Vision Layers：CV任务网络层 Shuffle Layers：随机打乱功能层 DataParallel Layers (multi-GPU, distributed)：多GPU网络层，多gpu需要用层的概念进行包装 Utilities：各功能函数层 Quantized Functions：量化功能函数 Lazy Modules Initialization：“懒惰”初始化功能模块 到这里，Module的类型就介绍完毕，下一小节将学习Module内部有哪些api，如何使用它们对一个Module进行管理，如模型的网络层查看、管理，模型的参数查看、管理，以及Hook函数的用法。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-4/4.4-module-api.html":{"url":"chapter-4/4.4-module-api.html","title":"4.4 Module常用API函数","keywords":"","body":"4.4 Module常用函数 本小节汇总介绍Module常用的方法，由于文档中是按首字母排序进行展示所有方法，未按用途进行归类，不便于理解各函数之间的关系。在这里，特地把相同功能、成对的函数放到一起，供大家参考学习。 常用方法包括： 设置模型训练、评估模式 eval train 设置模型存放在cpu/gpu/xpu cpu cuda to xpu 获取模型参数、加载权重参数 load_state_dict state_dict 管理模型的modules, parameters, sub_module parameters children modules named_children named_modules named_parameters get_parameter get_submodule add_module 设置模型的参数精度，可选半精度、单精度、双精度等 bfloat16 half float double 对子模块执行特定功能 apply zero_grad 以上是不完全的列举，有些非高频使用的函数请到文档中查阅。下面通过简介和配套代码的形式学习上述函数的使用。 设置模型训练、评估模式 eval：设置模型为评估模式，这一点与上小节介绍的BN，Dropout息息相关，即评估模式下模型的某些层执行的操作与训练状态下是不同的。 train：设置模型为训练模式，如BN层需要统计runing_var这些统计数据，Dropout层需要执行随机失活等。 使用方法太简单，不做代码展示。 设置模型存放在cpu/gpu 对于gpu的使用会在后面设置单独小节详细介绍，由于这里是基础学习，暂时可不考虑运算速度问题。这里既然遇到了相关的概念，就简单说一下。 pytorch可以利用gpu进行加速运算，早期只支持NVIDIA公司的GPU，现在也逐步开始支持AMD的GPU。使用gpu进行运算的方法很简单，就是把需要运算的数据放到gpu即可。方法就是 xxx.cuda()，若想回到cpu运算，那就需要xxx.cpu()即可。不够有一种更好的方法就是to()，to方法可将对象放到指定的设备中去，如to.(\"cpu\") 、 to.(\"cuda)、to(\"cuda:0\") 等。 cpu：将Module放到cpu上。 cuda：将Module放到cuda上。为什么是cuda不是gpu呢？因为CUDA（Compute Unified Device Architecture）是NVIDIA推出的运算平台，数据是放到那上面进行运算，而gpu可以有很多个品牌，因此用cuda更合理一些。 to：将Module放到指定的设备上。 关于to通常会配备torch.cuda.is_available()使用，请看配套代码学习。 获取模型参数、加载权重参数 模型训练完毕后，我们需要保存的核心内容是模型参数，这样可以供下次使用，或者是给别人进行finetune。相信大家都用ImageNet上的预训练模型，而使用方法就是官方训练完毕后保存模型的参数，供我们下载，然后加载到自己的模型中。在这里就涉及两个重要操作：保存模型参数与加载模型参数，分别要用到以下两个函数。 state_dict：返回参数字典。key是告诉你这个权重参数是放到哪个网络层。 load_state_dict：将参数字典中的参数复制到当前模型中。这里的复制要求key要一一对应，若key对不上，自然模型不知道要把这个参数放到哪里去。绝大多数开发者都会在load_state_dict这里遇到过报错，如 RuntimeError: Error(s) in loading state_dict for ResNet: Missing key(s) in state_dict: xxxxxxxx 　　Unexpected key(s) in state_dict: xxxxxxxxxx 这通常是拿到的参数字典与模型当前的结构不匹配。 对于load_state_dict函数，还有两个参数可以设置，请看原型： 参数： state_dict (dict) – a dict containing parameters and persistent buffers. strict (bool, optional) – whether to strictly enforce that the keys in state_dict match the keys returned by this module’s state_dict() function. Default: True 返回项 missing_keys is a list of str containing the missing keys unexpected_keys is a list of str containing the unexpected keys 上述两个方法具体的使用请看配套代码。 管理模型的modules, parameters, sub_module 模型中需要管理的主要是parameter与module，每个对象都有两种方式读取，分别是带名字和不带名字的。针对module还有一个称为children的方法，它与modules方法最大的不同在于modules会返回module本身。具体差异通过配套代码一看便明了。 parameters：返回一个迭代器，迭代器可抛出Module的所有parameter对象 named_parameters：作用同上，不仅可得到parameter对象，还会给出它的名称 modules：返回一个迭代器，迭代器可以抛出Module的所有Module对象，注意：模型本身也是module，所以也会获得自己。 named_modules：作用同上，不仅可得到Module对象，还会给出它的名称 children：作用同modules，但不会返回Module自己。 named_children：作用同named_modules，但不会返回Module自己。 获取某个参数或submodule 当想查看某个部分数据时，可以通过get_xxx方法获取模型特定位置的数据，可获取parameter、submodule，使用方法也很简单，只需要传入对应的name即可。 get_parameter get_submodule 设置模型的参数精度，可选半精度、单精度、双精度等 为了调整模型占存储空间的大小，可以设置参数的数据类型，默认情况是float32位（单精度），在一些场景可采用半精度、双精度等，以此改变模型的大小或精度。Module提供了几个转换权重参数精度的方法，分别如下： half：半精度 float：单精度 double：双精度 bfloat16：Brain Floating Point 是Google开发的一种数据格式，详细参见wikipedia 对子模块执行特定功能 zero_grad：将所有参数的梯度设置为0，或者None apply：对所有子Module执行指定fn(函数)，常见于参数初始化。这个可以参见配套代码。 小结 本节对Module的常用API函数进行了介绍，包括模型两种状态，模型存储于何种设备，模型获取参数，加载参数，管理模型的modules，设置模型参数的精度，对模型子模块执行特定功能。 由于Module是核心模块，其涉及的API非常多，短时间不好消化，建议大家结合代码用例，把这些方法都过一遍，留个印象，待日后项目开发需要的时候知道有这些函数可以使用即可。 下一小节将介绍Module中的Hook函数。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-4/4.5-hook-func.html":{"url":"chapter-4/4.5-hook-func.html","title":"4.5 Hook函数及Grad-CAM","keywords":"","body":"4.5 hook函数 注：本小节主要参考《PyTorch模型训练实用教程》（第一版），主要更新了PyTorch新版本的函数——torch.nn.Module.register_full_backward_hook。 -------------------------------------------------分割线--------------------------------------------------------------- 本小节将介绍Module中的三个Hook函数以及Tensor的一个Hook函数 torch.Tensor.register_hook torch.nn.Module.register_forward_hook torch.nn.Module.register_forward_pre_hook torch.nn.Module.register_full_backward_hook 同时使用hook函数优雅地实现Grad-CAM，效果如下图所示： ​ Grad-CAM是CAM(class activation map，类激活图)的改进，可对任意结构的CNN进行类激活可视化，不需要修改网络结构或者重新训练，详细理论请参见Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization 什么是hook？ Hook函数在多门编程语言中均有出现，是一个经典的编程方式。hook意为钩、挂钩、鱼钩。 引用知乎用户“马索萌”对hook的解释：“(hook)相当于插件。可以实现一些额外的功能，而又不用修改主体代码。把这些额外功能实现了挂在主代码上，所以叫钩子，很形象。” 简单讲，就是不修改主体，而实现额外功能。对应到在pytorch中，主体就是forward和backward，而额外的功能就是对模型的变量进行操作，如“提取”特征图，“提取”非叶子张量的梯度，修改张量梯度等等。 hook的出现与pytorch运算机制有关，pytorch在每一次运算结束后，会将中间变量释放，以节省内存空间，这些会被释放的变量包括非叶子张量的梯度，中间层的特征图等。 但有时候，想可视化中间层的特征图，又不能改动模型主体代码，该怎么办呢？这时候就要用到hook了。 举个例子演示hook提取非叶子张量的梯度： import torch def grad_hook(grad): y_grad.append(grad) y_grad = list() x = torch.tensor([[1., 2.], [3., 4.]], requires_grad=True) y = x+1 y.register_hook(grad_hook) z = torch.mean(y*y) z.backward() print(\"type(y): \", type(y)) print(\"y.grad: \", y.grad) print(\"y_grad[0]: \", y_grad[0]) >>> ('type(y): ', ) >>> ('y.grad: ', None) >>> ('y_grad[0]: ', tensor([[1.0000, 1.5000], [2.0000, 2.5000]])) 可以看到y.grad的值为None，这是因为y是非叶子结点张量，在z.backward()完成之后，y的梯度被释放掉以节省内存，但可以通过torch.Tensor的类方法register_hook将y的梯度提取出来。 torch.Tensor.register_hook torch.Tensor.register_hook (Python method, in torch.Tensor.register_hook) 功能：注册一个反向传播hook函数，这个函数是Tensor类里的，当计算tensor的梯度时自动执行。 为什么是backward？因为这个hook是针对tensor的，tensor中的什么东西会在计算结束后释放？ 那就是gradient，所以是backward hook. 形式： hook(grad) -> Tensor or None ，其中grad就是这个tensor的梯度。 返回值：a handle that can be used to remove the added hook by calling handle.remove() 应用场景举例：在hook函数中可对梯度grad进行in-place操作，即可修改tensor的grad值。 这是一个很酷的功能，例如当浅层的梯度消失时，可以对浅层的梯度乘以一定的倍数，用来增大梯度； 还可以对梯度做截断，限制梯度在某一区间，防止过大的梯度对权值参数进行修改。 下面举两个例子，例1是如何获取中间变量y的梯度，例2是利用hook函数将变量x的梯度扩大2倍。 例1： import torch y_grad = list() def grad_hook(grad): y_grad.append(grad) x = torch.tensor([2., 2., 2., 2.], requires_grad=True) y = torch.pow(x, 2) z = torch.mean(y) h = y.register_hook(grad_hook) z.backward() print(\"y.grad: \", y.grad) print(\"y_grad[0]: \", y_grad[0]) h.remove() # removes the hook >>> ('y.grad: ', None) >>> ('y_grad[0]: ', tensor([0.2500, 0.2500, 0.2500, 0.2500])) 可以看到当z.backward()结束后，张量y中的grad为None，因为y是非叶子节点张量，在梯度反传结束之后，被释放。 在对张量y的hook函数（grad_hook）中，将y的梯度保存到了y_grad列表中，因此可以在z.backward()结束后，仍旧可以在y_grad[0]中读到y的梯度为tensor([0.2500, 0.2500, 0.2500, 0.2500]) 例2： import torch def grad_hook(grad): grad *= 2 x = torch.tensor([2., 2., 2., 2.], requires_grad=True) y = torch.pow(x, 2) z = torch.mean(y) h = x.register_hook(grad_hook) z.backward() print(x.grad) h.remove() # removes the hook >>> tensor([2., 2., 2., 2.]) 原x的梯度为tensor([1., 1., 1., 1.])，经grad_hook操作后，梯度为tensor([2., 2., 2., 2.])。 torch.nn.Module.register_forward_hook 功能：Module前向传播中的hook,module在前向传播后，自动调用hook函数。 形式：hook(module, input, output) -> None or modified output 。注意不能修改input和output 返回值：a handle that can be used to remove the added hook by calling handle.remove() 举例：假设网络由卷积层conv1和池化层pool1构成，输入一张4*4的图片，现采用forward_hook获取module——conv1之后的feature maps，示意图如下： ​ import torch import torch.nn as nn class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv1 = nn.Conv2d(1, 2, 3) self.pool1 = nn.MaxPool2d(2, 2) def forward(self, x): x = self.conv1(x) x = self.pool1(x) return x def farward_hook(module, data_input, data_output): fmap_block.append(data_output) input_block.append(data_input) if __name__ == \"__main__\": # 初始化网络 net = Net() net.conv1.weight[0].fill_(1) net.conv1.weight[1].fill_(2) net.conv1.bias.data.zero_() # 注册hook fmap_block = list() input_block = list() net.conv1.register_forward_hook(farward_hook) # inference fake_img = torch.ones((1, 1, 4, 4)) # batch size * channel * H * W output = net(fake_img) # 观察 print(\"output shape: {}\\noutput value: {}\\n\".format(output.shape, output)) print(\"feature maps shape: {}\\noutput value: {}\\n\".format(fmap_block[0].shape, fmap_block[0])) print(\"input shape: {}\\ninput value: {}\".format(input_block[0][0].shape, input_block[0])) 首先初始化一个网络，卷积层有两个卷积核，权值分别为全1和全2，bias设置为0，池化层采用2*2的最大池化。 在进行forward之前对module——conv1注册了forward_hook函数，然后执行前向传播（output=net(fake_img)），当前向传播完成后， fmap_block列表中的第一个元素就是conv1层输出的特征图了。 这里注意观察farward_hook函数有data_input和data_output两个变量，特征图是data_output这个变量，而data_input是conv1层的输入数据， conv1层的输入是一个tuple的形式。 hook函数调用逻辑 下面剖析一下module是怎么样调用hook函数的呢？ output = net(fakeimg) net是一个module类，对module执行 module(input)是会调用module._call module.call ：会进入_call_impl，回顾Module那一小节，call_impl是有很多其它代码，这就是对hook函数的处理，可以看到，让注册了hook函数，模型的forward不再是4.1小节里分析的1102行代码进行，而是分别执行对应的hook函数。1109行是执行每个forward_pre_hook的，1120行是执行forward的，1123行是执行forward_hook的， 1144行是执行full_backward_hook的。 def _call_impl(self, *input, **kwargs): forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward) # If we don't have any hooks, we want to skip the rest of the logic in # this function, and just call forward. if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks or _global_forward_hooks or _global_forward_pre_hooks): return forward_call(*input, **kwargs) # Do not call functions when jit is used full_backward_hooks, non_full_backward_hooks = [], [] if self._backward_hooks or _global_backward_hooks: full_backward_hooks, non_full_backward_hooks = self._get_backward_hooks() if _global_forward_pre_hooks or self._forward_pre_hooks: for hook in (*_global_forward_pre_hooks.values(), *self._forward_pre_hooks.values()): result = hook(self, input) if result is not None: if not isinstance(result, tuple): result = (result,) input = result bw_hook = None if full_backward_hooks: bw_hook = hooks.BackwardHook(self, full_backward_hooks) input = bw_hook.setup_input_hook(input) result = forward_call(*input, **kwargs) if _global_forward_hooks or self._forward_hooks: for hook in (*_global_forward_hooks.values(), *self._forward_hooks.values()): hook_result = hook(self, input, result) if hook_result is not None: result = hook_result if bw_hook: result = bw_hook.setup_output_hook(result) # Handle the non-full backward hooks if non_full_backward_hooks: var = result while not isinstance(var, torch.Tensor): if isinstance(var, dict): var = next((v for v in var.values() if isinstance(v, torch.Tensor))) else: var = var[0] grad_fn = var.grad_fn if grad_fn is not None: for hook in non_full_backward_hooks: wrapper = functools.partial(hook, self) functools.update_wrapper(wrapper, hook) grad_fn.register_hook(wrapper) self._maybe_warn_non_full_backward_hook(input, result, grad_fn) return result 这里需要注意两点： hook_result = hook(self, input, result)中的input和result不可以修改。这里的input对应forward_hook函数中的data_input，result对应forward_hook函数中的data_output，在conv1中，input就是该层的输入数据，result就是经过conv1层操作之后的输出特征图。虽然可以通过hook来对这些数据操作，但是不能修改这些值，否则会破坏模型的计算。 注册的hook函数是不能带返回值的，否则抛出异常，这个可以从代码中看到 if hook_result is not None: raise RuntimeError 总结一下调用流程： net(fake_img) --> net.call : result = self.forward(input, *kwargs) --> net.forward: x = self.conv1(x) --> conv1.call:hook_result = hook(self, input, result) hook就是注册了的forward_hook函数。 torch.nn.Module.register_forward_pre_hook 功能：执行forward()之前调用hook函数。 形式：hook(module, input) -> None or modified input 应用场景：register_forward_pre_hook与forward_hook一样，是在module.call中注册的，与forward_hook不同的是，其在module执行forward之前就运行了，具体可看module.call中的代码。 torch.nn.Module.register_full_backward_hook 功能：Module反向传播中的hook,每次计算module的梯度后，自动调用hook函数。 形式：hook(module, grad_input, grad_output) -> tuple(Tensor) or None 注意事项： 当module有多个输入或输出时，grad_input和grad_output是一个tuple。 register_full_backward_hook 是修改过的版本，旧版本为register_backward_hook，不过官方已经建议弃用，不需要再了解。 返回值：a handle that can be used to remove the added hook by calling handle.remove() 应用场景举例：提取特征图的梯度 Grad-CAM 实现 采用register_full_backward_hook实现特征图梯度的提取，并结合Grad-CAM（基于类梯度的类激活图可视化）方法对卷积神经网络的学习模式进行可视化。 关 于Grad-CAM请看论文：《Grad-CAM Visual Explanations from Deep Networks via Gradient-based Localization》 简单介绍Grad-CAM的操作，Grad-CAM通过对最后一层特征图进行加权求和得到heatmap，整个CAM系列的主要研究就在于这个加权求和中的权值从那里来。 Grad-CAM是对特征图进行求梯度，将每一张特征图上的梯度求平均得到权值（特征图的梯度是element-wise的）。求梯度时并不采用网络的输出，而是采用类向量，即one-hot向量。 下图是ResNet的Grad-CAM示意图，上图类向量采用的是猫的标签，下图采用的是狗的标签，可以看到在上图模型更关注猫（红色部分），下图判别为狗的主要依据是狗的头部。 ​ 下面采用一个LeNet-5演示backward_hook在Grad-CAM中的应用。 简述代码过程： 创建网络net； 注册forward_hook函数用于提取最后一层特征图； 注册backward_hook函数用于提取类向量（one-hot）关于特征图的梯度 对特征图的梯度进行求均值，并对特征图进行加权； 可视化heatmap。 PS：需要注意的是在backward_hook函数中，grad_out是一个tuple类型的，要取得特征图的梯度需要这样grad_block.append(grad_out[0].detach()) 思考 这里对3张飞机的图片进行观察heatmap，如下图所示，第一行是原图，第二行是叠加了heatmap的图片。 这里发现一个有意思的现象，模型将图片判为飞机的依据是蓝天，而不是飞机（图1-3）。 那么我们喂给模型一张纯天蓝色的图片，模型会判为什么呢？如图4所示，发现模型判为了飞机 从这里发现，虽然能将飞机正确分类，但是它学到的却不是飞机的特征！ 这导致模型的泛化性能大打折扣，从这里我们可以考虑采用trick让模型强制的学习到飞机而不是常与飞机一同出现的蓝天，或者是调整数据。 ​ 对于图4疑问：heatmap蓝色区域是否对图像完全不起作用呢？是否仅仅通过红色区域就可以对图像进行判别呢？ 接下来将一辆正确分类的汽车图片（图5）叠加到图4蓝色响应区域（即模型并不关注的区域），结果如图6所示，汽车部分的响应值很小，模型仍通过天蓝色区域将图片判为了飞机。 接着又将汽车叠加到图4红色响应区域（图的右下角），结果如图7所示，仍将图片判为了飞机。 有意思的是将汽车叠加到图7的红色响应区域，模型把图片判为了船，而且红色响应区域是蓝色区域的下部分，这个与船在大海中的位置很接近。 ​ 通过以上代码学习full_backward_hook的使用及其在Grad-CAM中的应用，并通过Grad-CAM能诊断模型是否学习到了关键特征。 关于CAM( class activation maping，类激活响应图)是一个很有趣的研究，有兴趣的朋友可以对CAM、Grad-CAM和Grad-CAM++进行研究。 小结 本小节介绍了编程语言中经典的思想——Hook函数，并讲解了pytorch中如何使用它们，最后还采用full_backward_hook实现有趣的Grad-CAM可视化，本节代码较多，建议对着配套代码单步调试进行学习，掌握hook函数的妙用，在今后使用pytorch进行模型分析、魔改的时候更游刃有余。 下一小结会把本章所学的Module相关容器、网络层的知识点串起来使用，通过剖析torchvision中经典模型的源代码，了解所学习的知识点是如何使用的。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-4/4.6-classic-model.html":{"url":"chapter-4/4.6-classic-model.html","title":"4.6 经典模型代码分析","keywords":"","body":"4.6 经典Model代码分析 torchvision中提供了一些经典的卷积神经网络模型实现，本小节将挑选部分进行分析，学习torchvision是如何构建复杂的网络模型，学习它们的代码风格、代码规范。 AlexNet 出自：ImageNet Classification with Deep Convolutional Neural Networks 模型结构图如下图所示：整体可分为前半部分的特征提取与后半部分的分类。 ​ 代码分析： D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\Lib\\site-packages\\torchvision\\models\\alexnet.py 代码中定义了一个AlexNet类与一个alexnet函数，这样的封装形式贯穿整个torchvision的模型定义。 AlexNet类是nn.Module，其中定义了AlexNet模型的具体结构，而alexnet函数则是对Alexnet类的包装，并且实现加载预训练参数的功能，即以下代码： model = AlexNet(**kwargs) if pretrained: state_dict = load_state_dict_from_url(model_urls[\"alexnet\"], progress=progress) model.load_state_dict(state_dict) return model 从此也知道，torchvision中定义模型所采用的预训练模型均是通过指定的url下载，并存储于本地磁盘供下一次使用。 由于“网络问题”，通常建议大家通过代码中给出的url自行下载权重文件，然后在自己的代码中使用load_state_dict方法加载预训练参数。 分析了alexnet.py整体结构，下面回到AlexNet类本身，看看具体模型如何写的。 class AlexNet(nn.Module): def __init__(self, num_classes: int = 1000) -> None: def forward(self, x: torch.Tensor) -> torch.Tensor: AlexNet采用熟悉的方式定义了两个函数，熟悉4.1小结中的知识点的话，这里不比多说。 forward函数中第48行代码值得注意，二维特征图要输入到Linear层，通常通过flatten函数对特征图进行变换。 def forward(self, x: torch.Tensor) -> torch.Tensor: x = self.features(x) x = self.avgpool(x) x = torch.flatten(x, 1) # Line 48 x = self.classifier(x) return x 总结： 采用函数形式封装模型类，额外提供预训练权重加载功能； Linear层之前可通过torch.flatten将数据变为一维向量； VGG VGG出自：Very Deep Convolutional Networks For Large-Scale Image Recognition 其共有4种深度，分别是11， 13， 16， 19层，用得比较多的VGG16、19。VGG的代码就比AlexNet复杂了，因为它涉及8个具体的网络模型定义，因此不能再使用面向过程的方式进行编写，需要将共性的部分抽象出来，这一份代码值得新手仔细、认真学习。 首先是大体了解VGG整体结构，网络结构示意图如下图所示： ​ VGG最大特点是2个3x3、3个3x3卷积层的堆叠，并且堆叠总共分5次，最后接入三个FC层。从此可知，核心是如何将特征提取部分进行抽象，请大家带着这个问题观察代码：D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\Lib\\site-packages\\torchvision\\models\\vgg.py vgg.py中定义了VGG类、_vgg函数、make_layers函数、cfgs字典，以及一系列具体网络模型封装的函数，如vgg11，vgg13， vgg16等。 看过alexnet.py，这里能猜出VGG类是一个nn.module。 _vgg函数：vgg函数接收具体的网络参数，以此决定返回哪一个vgg模型； vggxxx：定义了具体VGG所需要的参数，并调用_vgg函数得到具体模型； make_layers函数：创建可抽象出来、共性的网络层函数，即网络结构图中的5次堆叠部分。 cfgs字典：配置各具体vgg模型所需要的参数，主要在make_layers中使用。 下面以vgg16为例，观察vgg.py是如何实现它的。 看到153行代码： def vgg16(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG: return _vgg(\"vgg16\", \"D\", False, pretrained, progress, **kwargs) 可知道，vgg16是对_vgg的封装，并且固定了两个参数\"vgg16\" 和 \"D\"。 跳到94行代码： def _vgg(arch: str, cfg: str, batch_norm: bool, pretrained: bool, progress: bool, **kwargs: Any) -> VGG: if pretrained: kwargs[\"init_weights\"] = False model = VGG(make_layers(cfgs[cfg], batch_norm=batch_norm), **kwargs) if pretrained: state_dict = load_state_dict_from_url(model_urls[arch], progress=progress) model.load_state_dict(state_dict) return model 可知道_vgg调用了VGG类得到最终的模型，并且给VGG传入了make_layers函数创建的网络层； 通过这行代码可知道，需要进入make_layers去观察如何创建网络层的。进入make_layers前，需要知道cfgs[cfg]当前传入的是： 'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'], 跳到69行代码： def make_layers(cfg: List[Union[str, int]], batch_norm: bool = False) -> nn.Sequential: layers: List[nn.Module] = [] in_channels = 3 for v in cfg: if v == \"M\": layers += [nn.MaxPool2d(kernel_size=2, stride=2)] else: v = cast(int, v) conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1) if batch_norm: layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)] else: layers += [conv2d, nn.ReLU(inplace=True)] in_channels = v return nn.Sequential(*layers) 从这里可知道是对cfg中进行for循环，不断的构建网络层，并且添加到list中，最后组装成一个Sequential的形式。这里的代码逻辑就是网络结构图中的抽象，把四种模型的共性地方抽象出来，然后通过不同的配置参数可生成vgg11, vgg13, vgg16, vgg19。这里的代码值得学习。 弄清楚make_layers是生成前面一系列卷积层的堆叠Sequential之后，继续进入VGG类观察。 跳到25行代码，看一个Module，可以先看forward函数，再看forward中的属性是怎么来的。 def forward(self, x: torch.Tensor) -> torch.Tensor: x = self.features(x) x = self.avgpool(x) x = torch.flatten(x, 1) x = self.classifier(x) return x 可以发现它的forward十分简洁，因为vgg模型就是以简洁出名的，像一个糖葫芦一样串起来即可。接着去看看self.features是什么，怎么来的，这个需要到init函数中寻找。 跳到34行代码：self.features = features 由此可知道，VGG特征提取部分的网络层均是通过make_layers函数定义的那个Sequential。 接着36行代码的classifier就没啥好说的。 接着的第45行代码出现了新内容，权重初始化。调用了_initialize_weights函数对VGG模型进行权重初始化。众所周知，良好的权重初始化对模型训练是至关重要的，早期对于权重初始化有许多的研究，比较著名的有Xavier方法、MSRA（Kaiming）方法。 预告：具体的权重初始化方法将在下一小节详细介绍。 下面观察如何编写函数对VGG进行权重初始化：跳转55行 def _initialize_weights(self) -> None: for m in self.modules(): if isinstance(m, nn.Conv2d): nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\") if m.bias is not None: nn.init.constant_(m.bias, 0) elif isinstance(m, nn.BatchNorm2d): nn.init.constant_(m.weight, 1) nn.init.constant_(m.bias, 0) elif isinstance(m, nn.Linear): nn.init.normal_(m.weight, 0, 0.01) nn.init.constant_(m.bias, 0) 此函数的逻辑就是遍历所有Module，并判断Module类型，根据不同的Module类型设置不同的初始化方法，如卷积层则用kaiming方法设置weight，bias全部设置为0；BN层的weight设置为1，bias设置为0；全连接层的weight用正态分布进行随机初始化，bias设置为0。 到这里一个具体的VGG模型定义就讲完了，下面总结一下它们的调用关系与逻辑。 vgg16() --> _vgg() --> make_layers --> VGG：最核心在于如何构建一个模块（函数也好、类也好）可以接收不同的参数（cfgs）就能生成对应VGG的特征提取部分的网络层（一个大的Sequential）。 GoogLeNet GoogLeNet-V1 出自 Going deeper with convolutions，后续也有V2，V3，V4，这里不进行介绍。 V1的提出最大的特点在于提出Inception模块，它是一个多分支的特征提取模块，如下图所示： ​ 网络结构如下图所示： ​ 代码并不复杂，但其中的Inception模块的编写，是之前没有遇到的，可以借鉴学习。 观察D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\Lib\\site-packages\\torchvision\\models\\googlenet.py 可以看到熟悉的定义了具体的Module——GoogLeNet类，模型的封装调用函数——googlenet，以及从GoogLeNet模型抽象出来的、反复需要使用的模块——Inception、InceptionAux、BasicConv2d。 这里面的代码并不复杂，这里不逐行分析，只把GoogLeNet类的逻辑关系理一理。 首先，将反复使用的模块抽象成一个类，这样在使用的时候只需要一行代码即可定义好，如BasicConv2d：包含了卷积层+BN层； Inception：包含四个分支的处理并合并最终特征图； InceptionAux：辅助分类层输出。 然后在init函数中像搭积木一样，把需要用到的模块逐一定义 最后在forward函数中调用定义好的网络层即可。 总结： 反复使用的模块抽象为一个Moudle类，并作为参数进行调用。好处在于当想修改这些基础元素模块的时候，仅需要重新写一个Module类替换即可，并不需要改动GoogLeNet类当中的任何代码（在resnet中会有体现）。要想理解好这一点，请仔细体会这几行代码 blocks = [BasicConv2d, Inception, InceptionAux] conv_block = blocks[0] inception_block = blocks[1] inception_aux_block = blocks[2] Resnet ResNet出自何恺明的《Deep Residual Learning for Image Recognition》，是目前工业界应用最广泛的卷积神经网络。 网络结构如下图所示，有ResNet-18， 34， 50， 101， 152，使用较多的为ResNet-50。其结构特点也是模块的堆叠，如表格中看到的x2， x3，x4, x6表示的是一个模块堆叠2次、3次、4次、6次。 ​ 在resnet模型中，最大的特点在于采用了残差结构的模块，如下图所示： ​ 这里有两种形式，一种是BasicBlock，另外一种是resnet50/101/152用的Bottleneck。 下面就来看看D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\Lib\\site-packages\\torchvision\\models\\resnet.py 是如何实现这一系列复杂的resnet模型。 提示：pycharm中按住Ctrl+Shift+ \"-\" ，可以把代码块收起来，可以快速浏览resnet.py下的主要内容，可以发现，还是熟悉的结构，分别有 ResNet类 _resnet函数 resnet18\\34\\50...一系列具体模型函数 抽象出来的基础模块：BasicBlock、Bottleneck、conv1x1和conv3x3。 这其中最为特色的是BasicBlock和Bottleneck，分别对应论文图5中的两个结构，它们将在不同的模型中使用。 下面就看看BasicBlock和Bottleneck到底是如何使用的。 跳到144行代码：class ResNet(nn.Module)，观察init函数里是如何使用block的。 跳到第178行代码：self.layer1 = self._make_layer(block, 64, layers[0])，在make_layer函数中使用了block进行网络层的构建。这点与VGG中的make_layers类似。 跳到205行代码： def _make_layer( self, block: Type[Union[BasicBlock, Bottleneck]], planes: int, blocks: int, stride: int = 1, dilate: bool = False, ) -> nn.Sequential: norm_layer = self._norm_layer downsample = None previous_dilation = self.dilation if dilate: self.dilation *= stride stride = 1 if stride != 1 or self.inplanes != planes * block.expansion: downsample = nn.Sequential( conv1x1(self.inplanes, planes * block.expansion, stride), norm_layer(planes * block.expansion), ) layers = [] layers.append( block( self.inplanes, planes, stride, downsample, self.groups, self.base_width, previous_dilation, norm_layer ) ) self.inplanes = planes * block.expansion for _ in range(1, blocks): layers.append( block( self.inplanes, planes, groups=self.groups, base_width=self.base_width, dilation=self.dilation, norm_layer=norm_layer, ) ) return nn.Sequential(*layers) 在此函数中使用block（是一个基础模块的类，是BasicBlock或Bottleneck）定义网络层，然后堆叠起来，最后使用Sequential进行包装，构成一个整体。 回到init函数可知道，178-184行代码所构建的模块对应了网络结构的四个部分，对应关系如下图所示： self.layer1 = self._make_layer(block, 64, layers[0]) self.layer2 = self._make_layer(block, 128, layers[1], stride=2, dilate=replace_stride_with_dilation[0]) self.layer3 = self._make_layer(block, 256, layers[2], stride=2, dilate=replace_stride_with_dilation[1]) self.layer4 = self._make_layer(block, 512, layers[3], stride=2, dilate=replace_stride_with_dilation[2]) ​ 在这里，可以发现resnet18和34用的是BasicBlock， resnet50/101/152用的是Bottleneck def resnet18(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> ResNet: return _resnet(\"resnet18\", BasicBlock, [2, 2, 2, 2], pretrained, progress, **kwargs) def resnet50(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> ResNet: return _resnet(\"resnet50\", Bottleneck, [3, 4, 6, 3], pretrained, progress, **kwargs) BasicBlock和Bottleneck的使用与googlenet中的blocks呼应上了，请大家仔细对比。 resnet总结 resnet的搭建是将block抽象出来提供接口，由用户自行传入，并且设定堆叠次数，如resnet18就是BasicBlock, [2, 2, 2, 2]， resnet50就是 Bottleneck, [3, 4, 6, 3]，处处体现了面向对象的编程思维，值得学习。 总结 本小节从简单的AlexNet到复杂的ResNet进行了代码分析，剖析了pytorch的代码结构，编写逻辑以及思想，其中面向对象的思维值得认真学习借鉴。 VGG中的make_layers()：通过参数配置形式搭建一个大的Sequential； GoogLeNet的BasicConv2d, Inception, InceptionAux、ResNet的BasicBlock、Bottleneck、conv1x1、conv3x3都是抽象的基础模块。 本小节在多出看到了权重初始化方法，好的权重初始化是模型训练的第一步，下一小节将介绍pytorch提供的系列权重初始化方法及其应用。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-4/4.7-weight-init.html":{"url":"chapter-4/4.7-weight-init.html","title":"4.7 权重初始化方法","keywords":"","body":"4.7 权重初始化方法 https://pytorch.org/docs/stable/nn.init.html 良好的模型权重初始化，有利于模型的训练，在torch.nn.init中提供了数十个初始化方法，本小节对它们进行介绍。 回顾上一小节中VGG的初始化代码，先总结出权重初始化的流程与步骤。 for m in self.modules(): if isinstance(m, nn.Conv2d): nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\") if m.bias is not None: nn.init.constant_(m.bias, 0) elif isinstance(m, nn.BatchNorm2d): nn.init.constant_(m.weight, 1) nn.init.constant_(m.bias, 0) elif isinstance(m, nn.Linear): nn.init.normal_(m.weight, 0, 0.01) nn.init.constant_(m.bias, 0) 首先对每一个子module进行遍历，对不同的网络层进行设置对应的权重初始化方法，初始化方法采用的是nn.init.xxx函数。 接下来nn.init.xxx就是本节的主角，下面依次介绍nn.init.xxx函数。 主要分为三部分： Xavier 系列 kaiming 系列 常数方法 Xavier 系列 torch.nn.init.xavieruniform(tensor, gain=1.0) xavier 初始化方法中服从均匀分布 U(-a,a) ，分布的参数 a = gain * sqrt(6/fan_in+fan_out)， 这里有一个 gain，表示增益，它的大小是依据激活函数类型来设定。本方法也称为 Glorot initialization。 torch.nn.init.xaviernormal(tensor, gain=1.0) xavier初始化方法中服从正态分布， mean=0,std = gain * sqrt(2/fan_in + fan_out) Xavier初始化方法的理论分析可见《Understanding the difficulty of training deep feedforward neural networks - Glorot, X. & Bengio, Y. (2010),》 Kaiming系列 ​ 3.### torch.nn.init.kaiminguniform(tensor, a=0, mode='fan_in', nonlinearity='leaky_relu') 此为均匀分布，U～（-bound, bound）, bound = sqrt(6/(1+a^2)*fan_in) 其中，a为激活函数的负半轴的斜率，relu是0 mode- 可选为fan_in 或 fan_out, fan_in使正向传播时，方差一致; fan_out使反向传播时，方差一致 nonlinearity- 可选 relu 和 leaky_relu ，默认值为 :leaky_relu torch.nn.init.kaimingnormal(tensor, a=0, mode='fan_in', nonlinearity='leaky_relu') 此为0均值的正态分布，N～ (0,std)，其中std = sqrt(2/(1+a^2)*fan_in) 其中，a为激活函数的负半轴的斜率，relu是0 mode- 可选为fan_in 或 fan_out, fan_in使正向传播时，方差一致;fan_out使反向传播时，方差一致 nonlinearity- 可选 relu 和 leaky_relu ，默认值为： leaky_relu Kaiming系列的初始化方法理论分析可参阅《Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification - He, K. et al. (2015》 其它方法 均匀分布初始化 torch.nn.init.uniform_(tensor, a=0, b=1) 使值服从均匀分布U(a,b) 正态分布初始化 torch.nn.init.normal_(tensor, mean=0, std=1) 使值服从正态分布N(mean, std)，默认值为0，1 常数初始化 torch.nn.init.constant_(tensor, val) 使值为常数val nn.init.constant_(w, 0.3) 单位矩阵初始化 torch.nn.init.eye_(tensor) 将二维tensor初始化为单位矩阵（the identity matrix） 正交初始化 torch.nn.init.orthogonal_(tensor, gain=1) 使得tensor是正交的，论文:Exact solutions to the nonlinear dynamics of learning in deep linear neural networks” - Saxe, A. et al. (2013) 稀疏初始化 torch.nn.init.sparse_(tensor, sparsity, std=0.01) 从正态分布N～（0. std）中进行稀疏化，使每一个column有一部分为0 sparsity- 每一个column稀疏的比例，即为0的比例 nn.init.sparse_(w, sparsity=0.1) 全零初始化 torch.nn.init.zeros_(tensor) 所有参数置零。 全1初始化 torch.nn.init.ones_(tensor) 所有参数置一。 狄拉克初始化 torch.nn.init.dirac_(tensor, groups=1) 采用狄拉克函数进行权重初始化， 增益计算 torch.nn.init.calculate_gain(nonlinearity, param=None) 返回各激活函数对应的增益值，该值影响权重初始化的方差。 nonlinearity gain Linear / Identity 1 Conv{1,2,3}D 1 Sigmoid 1 Tanh 35 ReLU 2 Leaky Relu 1+negative_slope22 SELU 43 小结 本小节将torch.nn.init中包含的初始化方法进行了分类介绍，主要分为Xavier和Kaiming方法与其它常数方法，并且回顾了torchvision中如何对一个模型所有层进行权重初始化的流程，希望对大家有所帮助。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-5/":{"url":"chapter-5/","title":"第五章 PyTorch 优化模块","keywords":"","body":"第五章 PyTorch 优化模块 第五章 PyTorch 优化模块 5.1 二十一个损失函数 5.2 十三个优化器 5.3 十四个学习率调整器 第五章简介 本章开始介绍模型优化过程中涉及的三大概念：损失函数、优化器和学习率调整。 由于损失函数、优化器、学习率调整的方法有非常多，仅pytorch官方实现（V1.10）的就有二十一个损失函数，十三个优化器，十四个学习率调整方法。 这几十种方法不会对每一个进行详细介绍，主要通过几个核心的方法为案例，进行剖析各模块的机制，如损失函数的Module如何编写、pytorch是如何构建loss.py体系、优化器如何更新模型中的参数、优化器常用函数、学习率调整机制等内容。 相信了解上述机制，便可举一反三，掌握更为复杂的方法函数。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-5/5.1-loss-function.html":{"url":"chapter-5/5.1-loss-function.html","title":"5.1 二十一个损失函数","keywords":"","body":"5.1 二十一个损失函数 本节重点为pytorch损失函数实现方式及逻辑，而非具体某个损失函数的公式计算，核心为下图： 损失函数——Loss Function 损失函数（loss function）是用来衡量模型输出与真实标签之间的差异，当模型输出越接近标签，认为模型越好，反之亦然。因此，可以得到一个近乎等价的概念，loss越小，模型越好。这样就可以用数值优化的方法不断的让loss变小，即模型的训练。 针对不同的任务有不同的损失函数，例如回归任务常用MSE(Mean Square Error)，分类任务常用CE（Cross Entropy），这是根据标签的特征来决定的。而不同的任务还可以对基础损失函数进行各式各样的改进，如Focal Loss针对困难样本的设计，GIoU新增相交尺度的衡量方式，DIoU新增重叠面积与中心点距离衡量等等。 在pytorch中提供了二十一个损失函数，如下所示 nn.L1Loss nn.MSELoss nn.CrossEntropyLoss nn.CTCLoss nn.NLLLoss nn.PoissonNLLLoss nn.GaussianNLLLoss nn.KLDivLoss nn.BCELoss nn.BCEWithLogitsLoss nn.MarginRankingLoss nn.HingeEmbeddingLoss nn.MultiLabelMarginLoss nn.HuberLoss nn.SmoothL1Loss nn.SoftMarginLoss nn.MultiLabelSoftMarginLoss nn.CosineEmbeddingLoss nn.MultiMarginLoss nn.TripletMarginLoss nn.TripletMarginWithDistanceLoss 本小节讲解仅剖析nn.L1Loss和nn.CrossEntropyLoss这两个损失函数及其衍生函数。其余损失函数可以触类旁通。 核心知识在于损失函数的实现流程，不同的损失函数仅在于计算公式的不同，每个损失函数处理公式可在官方文档查阅。 以最简单的L1Loss出发，观察pytorch的损失函数是如何实现的 1. L1loss CLASS torch.nn.L1Loss(size_average=None, reduce=None, reduction='mean') 功能： 计算output和target之差的绝对值，可选返回同维度的tensor（reduction=none）或一个标量（reduction=mean/sum）。 计算公式： 参数： size_average (bool, optional) – 已舍弃使用的变量，功能已经由reduction代替实现，仍旧保留是为了旧版本代码可以正常运行。reduce (bool, optional) – 已舍弃使用的变量，功能已经由reduction代替实现，仍旧保留是为了旧版本代码可以正常运行。reduction (string, optional) – 是否需要对loss进行“降维”，这里的reduction指是否将loss值进行取平均（mean）、求和（sum）或是保持原尺寸（none），这一变量在pytorch绝大多数损失函数中都有在使用，需要重点理解。 示例：代码 流程剖析 通过示例代码可知，loss_func是一个类实例，使用方式是loss_func(output, target)。 而nn.L1Loss是一个什么类？提供怎么样的接口来实现loss_func(output, target)的？ 可跳转进入nn.L1Loss类定义，可以发现它继承_Loss，继续观察_Loss类，发现它继承nn.Module，既然是一个nn.Module，只需要在其内部实现一个forward()函数，就可以使类实例可以像函数一样被调用。 请看L1Loss类的实现： class L1Loss(_Loss): __constants__ = ['reduction'] def __init__(self, size_average=None, reduce=None, reduction: str = 'mean') -> None: super(L1Loss, self).__init__(size_average, reduce, reduction) def forward(self, input: Tensor, target: Tensor) -> Tensor: return F.l1_loss(input, target, reduction=self.reduction) L1Loss的forward函数正是接收两个变量，然后计算它们之差的绝对值。而具体的实现委托给F.l1_loss函数 继续进入F.l1_loss一探究竟： def l1_loss( input: Tensor, target: Tensor, size_average: Optional[bool] = None, reduce: Optional[bool] = None, reduction: str = \"mean\", ) -> Tensor: if has_torch_function_variadic(input, target): return handle_torch_function( l1_loss, (input, target), input, target, size_average=size_average, reduce=reduce, reduction=reduction ) if not (target.size() == input.size()): warnings.warn( \"Using a target size ({}) that is different to the input size ({}). \" \"This will likely lead to incorrect results due to broadcasting. \" \"Please ensure they have the same size.\".format(target.size(), input.size()), stacklevel=2, ) if size_average is not None or reduce is not None: reduction = _Reduction.legacy_get_string(size_average, reduce) expanded_input, expanded_target = torch.broadcast_tensors(input, target) return torch._C._nn.l1_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction)) F.l1_loss函数对输入参数相应的判断，例如传入的两个变量的维度必须一致，否则无法计算l1 loss。而具体公式的数值计算又委托给了torch._C._nn.l1_loss，torch._C._nn.l1_loss 就已经调用了python的C++拓展，底层代码是用C++语言编写，在python中就无法观察到，从这里大家可以知道pytorch大量的数值运算是借助了C++语言，毕竟python的底层运算比较慢。 关于C++底层代码，可依次观察： https://github.com/pytorch/pytorch/blob/master/torch/csrc/api/src/nn/modules/loss.cpp #include namespace F = torch::nn::functional; namespace torch { namespace nn { L1LossImpl::L1LossImpl(const L1LossOptions& options_) : options(options_) {} void L1LossImpl::reset() {} void L1LossImpl::pretty_print(std::ostream& stream) const { stream https://github.com/pytorch/pytorch/blob/master/aten/src/ATen/native/Loss.cpp Tensor& l1_loss_out(const Tensor& input, const Tensor& target, int64_t reduction, Tensor& result) { if (reduction != Reduction::None) { auto diff = at::sub(input, target); auto loss = diff.is_complex() ? diff.abs() : diff.abs_(); if (reduction == Reduction::Mean) { return at::mean_out(result, loss, IntArrayRef{}); } else { return at::sum_out(result, loss, IntArrayRef{}); } } else { auto diff = input.is_complex() ? at::sub(input, target) : at::sub_out(result, input, target); return at::abs_out(result, diff); } } 从上述代码中可以看到，实际的L1Loss公式的实现是 auto diff = at::sub(input, target); auto loss = diff.is_complex() ? diff.abs() : diff.abs_(); 总结一下，Loss的实现流程如下图所示： 首先，损失函数继承Module，并实现forward函数，forward函数中完成具体公式计算；其次，具体的公式运算委托给nn.functional下函数实现；最后，pytorch大多的数值运算借助C++代码实现，具体在ATen/native/Loss.cpp 2. CrossEntropyLoss CLASS torch.nn.CrossEntropyLoss(weight=None, size_average=None, ignore_index=- 100, reduce=None, reduction='mean', label_smoothing=0.0) 功能：先将输入经过softmax激活函数之后，再计算交叉熵损失。 在早期的pytorch中，是利用nn.LogSoftmax()和 nn.NLLLoss()实现的，现已经通过nn.CrossEntropyLoss()实现，不过官方文档中仍旧有提示：V1.11.0: \"Note that this case is equivalent to the combination of LogSoftmax and NLLLoss.\"V1.6.0: \"This criterion combines nn.LogSoftmax() and nn.NLLLoss() in one single class.\"\" 补充：小谈交叉熵损失函数交叉熵损失(cross-entropy Loss) 又称为对数似然损失(Log-likelihood Loss)、对数损失；二分类时还可称之为逻辑斯谛回归损失(Logistic Loss)。交叉熵损失函数表达式为 L = - sigama(y_i * log(x_i))。pytroch这里不是严格意义上的交叉熵损失函数，而是先将input经过softmax激活函数，将向量“归一化”成概率形式，然后再与target计算严格意义上交叉熵损失。 在多分类任务中，经常采用softmax激活函数+交叉熵损失函数，因为交叉熵描述了两个概率分布的差异，然而神经网络输出的是向量，并不是概率分布的形式。所以需要softmax激活函数将一个向量进行“归一化”成概率分布的形式，再采用交叉熵损失函数计算loss。 参数： weight (Tensor, optional) – 类别权重，用于调整各类别的损失重要程度，常用于类别不均衡的情况。 If given, has to be a Tensor of size Cignore_index (int, optional) – 忽略某些类别不进行loss计算。size_average (bool, optional) – 已舍弃使用的变量，功能已经由reduction代替实现，仍旧保留是为了旧版本代码可以正常运行。reduce (bool, optional) – 已舍弃使用的变量，功能已经由reduction代替实现，仍旧保留是为了旧版本代码可以正常运行。reduction (string, optional) – 是否需要对loss进行“降维”，这里的reduction指是否将loss值进行取平均（mean）、求和（sum）或是保持原尺寸（none），这一变量在pytorch绝大多数损失函数中都有在使用，需要重点理解。 label_smoothing (float, optional) – 标签平滑参数，一个用于减少方差，防止过拟合的技巧。详细请看论文《 Rethinking the Inception Architecture for Computer Vision》。通常设置为0.01-0.1之间，虽然理论值域为：A float in [0.0, 1.0]. 计算公式： 补图：https://pytorch.org/docs/1.11/generated/torch.nn.CrossEntropyLoss.html?highlight=crossentropyloss#torch.nn.CrossEntropyLoss C++底层代码实现： https://github.com/pytorch/pytorch/blob/master/aten/src/ATen/native/LossNLL.cpp Tensor cross_entropy_loss( const Tensor& self, const Tensor& target, const c10::optional& weight, int64_t reduction, int64_t ignore_index, double label_smoothing) { Tensor ret; if (self.sizes() == target.sizes()) { // Assume soft targets when input and target shapes are the same TORCH_CHECK(at::isFloatingType(target.scalar_type()), \"Expected floating point type for target with class probabilities, got \", target.scalar_type()); TORCH_CHECK(ignore_index weight_maybe_owned = at::borrow_from_optional_tensor(weight); const Tensor& weight_ = *weight_maybe_owned; ret = cross_entropy_loss_prob_target(self, target, weight_, reduction, label_smoothing); } else if (label_smoothing > 0.0) { TORCH_CHECK(label_smoothing weight_maybe_owned = at::borrow_from_optional_tensor(weight); const Tensor& weight_ = *weight_maybe_owned; ret = cross_entropy_loss_label_smoothing(self, target, weight_, reduction, ignore_index, label_smoothing); } else { auto class_dim = self.dim() == 1 ? 0 : 1; ret = at::nll_loss_nd( at::log_softmax(self, class_dim, self.scalar_type()), target, weight, reduction, ignore_index); } return ret; } Tensor & nll_loss_out(const Tensor & self, const Tensor & target, const c10::optional& weight_opt, int64_t reduction, int64_t ignore_index, Tensor & output) { // See [Note: hacky wrapper removal for optional tensor] c10::MaybeOwned weight_maybe_owned = at::borrow_from_optional_tensor(weight_opt); const Tensor& weight = *weight_maybe_owned; Tensor total_weight = at::empty({0}, self.options()); return std::get(at::nll_loss_forward_out(output, total_weight, self, target, weight, reduction, ignore_index)); } Tensor nll_loss(const Tensor & self, const Tensor & target, const c10::optional& weight_opt, int64_t reduction, int64_t ignore_index) { // See [Note: hacky wrapper removal for optional tensor] c10::MaybeOwned weight_maybe_owned = at::borrow_from_optional_tensor(weight_opt); const Tensor& weight = *weight_maybe_owned; return std::get(at::nll_loss_forward(self, target, weight, reduction, ignore_index)); } Tensor nll_loss_nd( const Tensor& self, const Tensor& target, const c10::optional& weight, int64_t reduction, int64_t ignore_index) { if (self.dim() 4 auto n = input_.sizes()[0]; auto c = input_.sizes()[1]; auto out_size = input_.sizes().slice(2).vec(); out_size.insert(out_size.begin(), n); if (target_.sizes().slice(1) != input_.sizes().slice(2)) { TORCH_CHECK( false, \"Expected target size \", IntArrayRef(out_size), \", got \", target_.sizes()); } input_ = input_.contiguous(); target_ = target_.contiguous(); // support empty batches, see #15870 if (input_.numel() > 0) { input_ = input_.view({n, c, 1, -1}); } else { input_ = input_.view({n, c, 0, 0}); } if (target_.numel() > 0) { target_ = target_.view({n, 1, -1}); } else { target_ = target_.view({n, 0, 0}); } if (reduction != Reduction::None) { ret = at::nll_loss2d(input_, target_, weight, reduction, ignore_index); } else { auto out = at::nll_loss2d(input_, target_, weight, reduction, ignore_index); ret = out.view(out_size); } } return ret; } 示例：代码 CrossEntropyLoss使用注意事项： target需要的是int类型，不需要one-hot向量形式； 类别需要从0开始计数，即10分类任务，类别index应当为0,1,2,3,4,5,6,7,8,9 小结 本小节重点剖析两个损失函数，学习pytorch损失函数的实现逻辑，请详细观察以下关系图，对后续编写其它千奇百怪的损失函数很有帮助。在深度学习中，损失函数还有很多，这里无法一一列举，感兴趣可以了解一下：https://github.com/JunMa11/SegLoss 以及目标检测中的IoU、GIoU、DIoU、CIoU等。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-5/5.2-Optimizer.html":{"url":"chapter-5/5.2-Optimizer.html","title":"5.2 十三个优化器","keywords":"","body":"5.2 十三个优化器 Optimizer 简介 有了数据、模型和损失函数，就要选择一个合适的优化器(Optimizer)对该模型进行优化，使loss不断降低，直到模型收敛。本节将介绍pytorch中优化器——Optimizer。 优化器的实现在torch.optim中，torch.optim is a package implementing various optimization algorithms. 在其中有一个核心类是Optimizer，Optimizer在pytorch提供的功能是所有具体优化器的基类，它对优化器进行了抽象与定义，约定了一个优化器应有的功能，Optimizer与十三个优化器的关系如下图所示： 通过上图可知道Optimizer定义了优化器应当具备的基础功能，如获取状态数据，加载状态数据，梯度清零，执行一步优化和添加参数组。 不同的优化方法会继承Optimizer，同时只需要实现不同的step()即可。这一点与损失函数类似，不同的损失函数只需要在forward()函数中定义好不同的公式计算即可。 本小节将以SGD为例，深入讲解优化器的以下函数，并具体地观察SGD算法的实现过程。 state_dict(self) load_state_dict(self, state_dict) zero_grad(self, set_to_none: bool = False) step(self, closure) add_param_group(self, param_group) 优化器工作方式 优化器如何工作，使得模型精度逐渐提高的？在此就不详细讲解，请大家自行补充机器学习基础概念。 众所周知，优化器是根据权重的梯度作为指导，定义权重更新的力度，对权重进行更新。 过程很简单，实现很复杂，上述过程涉及几个问题： 梯度哪里来？ 更新哪些权重？ 怎么执行权重更新？ 依次回答上述问题，便可熟悉优化器工作方式。 梯度哪里来？ 梯度通过loss值进行反向传播，得到每个权重的梯度，其中利用pytorch的autograd机制自动求导获得各权重的梯度。 （如果对autograd机制不熟悉，请查看第二章第六节） 更新哪些权重？通过loss的反向传播，模型(nn.Module)的权重（Parameter）上有了梯度(.grad)值，但是优化器对哪些权重进行操作呢？实际上优化器会对需要操作的权重进行管理，只有被管理的权重，优化器才会对其进行操作。在Optimizer基类中就定义了add_param_group()函数来实现参数的管理。通常在实例化的时候，第一个参数就是需要被管理的参数。 怎么执行权重更新？通过上述UML类图不难发现，step()函数是进行优化操作的，step()函数中实现了对所管理的参数进行更新的步骤。 总结一下：优化器在实例化时告诉它，需要对哪些参数进行管理，然后再每个iteration迭代时，借助loss.backward()得到梯度，接着优化器干活 optimizer.step()完成一步参数更新。 （此过程可以回顾第二章第二节的模型训练代码） 优化器基类 Optimizer Optimizer类是所有具体优化器的基类（Base class for all optimizers.） 下面分别介绍Optimizer的基础属性及方法。 属性： 参数组(param_groups)： 在finetune、某层定制学习率，某层学习率置零操作中，都会设计参数组的概念，因此首先了解参数组的概念非常有必要。 参数组是用于管理需要进行优化的那些参数，例如权值weight，偏置bias，BN的alpha/beta等。 注意，这里是参数组不是参数，表明可以将所有参数进行分组，区别对待。 例如在finetune过程中，通常让前面层的网络采用较小的学习率，后面几层全连接层采用较大的学习率， 这是我们就要把网络的参数划分为两组，每一组有它对应的学习率。正是因为这种针对不同参数需要不同的更新策略的需求，才有了参数组的概念。 参数组是一个list，其元素是一个dict，dict中包含，所管理的参数，对应的超参，例如学习率，momentum，weight_decay等等。 案例：chapter-5/02_optimizer.py state： 用于存储优化策略中需要保存的一些缓存值，例如在用momentum时，需要保存之前的梯度，这些数据保存在state中。 defaults: 优化方法默认的超参数； 方法： zero_grad() 功能：清零所管理参数的梯度。由于pytorch不会自动清零梯度，因此需要再optimizer中手动清零，然后再执行反向传播，得出当前iteration的loss对权值的梯度。 step() 功能：执行一步更新，依据当前的梯度进行更新参数 add_param_group(param_group) 功能：给optimizer管理的参数组中增加一组参数，可为该组参数定制lr,momentum,weight_decay等，在finetune中常用。 例如：optimizer_1.add_param_group({'params': w3, 'lr': 0.001, 'momentum': 0.8}) state_dict() 功能：获取当前state属性。 通常在保存模型时同时保存优化器状态，用于断点保存，下次继续从当前状态训练； load_state_dict(state_dict) 功能：加载所保存的state属性，恢复训练状态。 对优化器工作方式熟悉后，再看Optimizer的属性和方法就简单了，下面通过一个具体的优化算法来熟悉完整的优化器使用。 SGD概念 torch.optim.SGD详情请参照[官方文档]( https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD) SGD(stochastic gradient descent，随机梯度下降)是深度学习模型优化过程中最基础、最受欢迎、最稳定的一个，即使优化算法层出不穷，仅pytorch就提供了十三个，但目前绝大多数论文中仍旧采用SGD进行训练，因此SGD必须掌握。 SGD核心理论知识是梯度下降( gradient descent)，即沿着梯度的负方向，是变化最快的方向。 而随机则指的是一次更新中，采用了一部分样本进行计算，即一个batch的数据可以看作是整个训练样本的随机采样。更多关于SGD的理论知识请自行学习机器学习基础。 SGD更新公式可简化为 w新 = w旧 - w_grad，即参数减去梯度（学习率为1） 不过通常会加入学习率来调整更新的步伐：w_新 = w_旧 - (lr * w_grad) 对于加入L2正则（weight decay）时，变为：w_新 = w_旧 - (lr (w_grad + weight_decay w_旧)) L2正则称之为weight decay的原因，对比公式1发现W需要乘以一个小于1的系数，因此是衰减的：w_新 = w_旧 - (lr (w_grad + weight_decay w_旧)) = w_旧（1 - lrweight_decay) - (lr w_grad) 对于其它momentum 、dampening 和nesterov 的加入就不详细展开，可通过官方文档查阅： SGD使用 请结合代码观察SGD的使用 第一步：实例化：optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4) 第二步：loss.backward()之前进行梯度清零：optimizer.zero_grad() 第三步：loss.backward()之后执行一步更新：optimizer.step() 在代码中还有一处用到了optimizer，那就是学习率调整模块： scheduler = optim.lr_scheduler.StepLR(optimizer, gamma=0.1, step_size=50) 原理是将optimizer放到lr_scheduler进行管理，lr_scheduler会修改optimizer中的学习率 SGD代码实现 SGD类继承于Optimizer类，并重写step函数实现核心功能。 SGD类中step函数首先对各参数组、参数进行超参数的获取确定：for group in self.param_groups: 然后借助functional.sgd函数实现公式计算： F.sgd(params_with_grad, d_p_list, momentum_buffer_list, weight_decay=weight_decay, momentum=momentum, lr=lr, dampening=dampening, nesterov=nesterov, maximize=maximize,) 下面重点进入/torch/optim/_functional.py 的sgd()观察：这里为了讲解过程，省略了momentum的代码： d_p：是梯度 weight_decay：是权重衰减系数，如 0.0001 param：是具体的权重参数 lr:是学习率 依194行代码: param = param + (alpha)* d_p 依193行代码: param = param + (-lr) d_p = **param - lr \\ d_p** 依177行代码: param = param - lr (d_p + weight_decay param) = param(1 - lr * weight_decay) - lr*d_p 到这里，就可以与上述理论部分对应上了。 小结 其余十二个优化器可通过官方文档查阅，相信大家熟悉SGD以及优化器使用逻辑，其它的优化器都可轻松掌握。 Adadelta Implements Adadelta algorithm. Adagrad Implements Adagrad algorithm. Adam Implements Adam algorithm. AdamW Implements AdamW algorithm. SparseAdam Implements lazy version of Adam algorithm suitable for sparse tensors. Adamax Implements Adamax algorithm (a variant of Adam based on infinity norm). ASGD Implements Averaged Stochastic Gradient Descent. LBFGS Implements L-BFGS algorithm, heavily inspired by minFunc. NAdam Implements NAdam algorithm. RAdam Implements RAdam algorithm. RMSprop Implements RMSprop algorithm. Rprop Implements the resilient backpropagation algorithm. SGD Implements stochastic gradient descent (optionally with momentum). 下面梳理pytorch整个优化器实现的逻辑关系： Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-5/5.3-lr-scheduler.html":{"url":"chapter-5/5.3-lr-scheduler.html","title":"5.3 十四个学习率调整器","keywords":"","body":"5.3 学习率调整策略 深度学习模型训练中调整最频繁的就属学习率了，好的学习率可以使模型逐渐收敛并获得更好的精度。 本小节将介绍pytorch提供的十四种学习率调整方法，首先了解lr_scheduler整体结构设计，然后以StepLR为例，深度剖析一个学习率调整器的源代码实现细节，最后总结十四个学习率调整策略。 lr_scheduler 设计 lr_scheduler模块的设计与优化器一样，定义了一个核心基类_LRScheduler，在_LRScheduler中设计好学习率调整器的属性与方法。 核心属性有optimizer、base_lrs和last_epoch。 optimizer是调整器所管理的优化器，优化器中所管理的参数组有对应的学习率，调整器要调整的内容就在那里。 base_lrs是基础学习率，来自于optimizer一开始设定的那个值。self.base_lrs = [group['initial_lr'] for group in optimizer.param_groups] last_epoch是记录迭代次数，通常用于计算下一轮学习率。注意，默认初始值是-1，因为last_epoch的管理逻辑是执行一次，自加1。 核心方法有state_dict()、load_state_dict()、get_last_lr()、get_lr()、print_lr()、step()。 state_dict()和load_state_dict()分别是获取调整器的状态数据与加载状态数据。 get_last_lr()、get_lr() 分别为获取上一次和当前的学习率。 print_lr()是打印学习率。 step()为更新学习率的接口函数，使用者调用 scheduler.step()即完成一次更新。 lr_scheduler 使用流程 第一步：实例化。scheduler = optim.lr_scheduler.StepLR(optimizer, gamma=0.1, step_size=50) 第二步：合适的位置执行step()。大家要注意，不同的调整器的更新策略是不一样的，有的是基于epoch维度，有的是基于iteration维度，这个需要注意。 StepLR 源代码解读 StepLR是依据设定的step_size，以固定的间隔进行调整，调整规则为 lr_new = lr_old * gamma， 通常gamma设置为0.1，即一定次数训练后，学习率下降10倍。 下面观察代码，在代码104行与146行打断点进行调试，依次观察初始化过程、step更新过程。 初始化过程： StepLR类__init__()函数： self.step_size = step_size self.gamma = gamma super(StepLR, self).__init__(optimizer, last_epoch, verbose) 跳转到_LRScheduler类__init__()函数： 第一步：获取初始学习率：group.setdefault('initial_lr', group['lr']) 第二步：记录基础学习率：self.base_lrs = [group['initial_lr'] for group in optimizer.param_groups] self.last_epoch = last_epoch 第三步：执行首次step()，也就是在初始化的时候会自动执行一次step（），这也是为什么last_epoch的默认值是-1的原因。 step中会进行第0个epoch的学习率获取，具体过程如代码所示： torch/optim/lr_scheduler.py 151至168行 with _enable_get_lr_call(self): if epoch is None: self.last_epoch += 1 values = self.get_lr() else: warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning) self.last_epoch = epoch if hasattr(self, \"_get_closed_form_lr\"): values = self._get_closed_form_lr() else: values = self.get_lr() for i, data in enumerate(zip(self.optimizer.param_groups, values)): param_group, lr = data param_group['lr'] = lr self.print_lr(self.verbose, i, lr, epoch) self._last_lr = [group['lr'] for group in self.optimizer.param_groups] step更新过程 在初始化过程已经进行过一次step，这里再仔细分析一遍。 首先通过154行代码，获取新一轮学习率 values = self.get_lr() 然后通过165行代码，对优化器中的学习率进行更新param_group['lr'] = lr 可以发现step()函数由基类_LRScheduler实现，即所有学习率调整器均采用这个流程，具体的一步更新策略则委托给子类的.get_lr()函数，这样的架构设计值得学习。 此处，关注的是StepLR，下面深入 StepLR.get_lr()函数观察。 if (self.last_epoch == 0) or (self.last_epoch % self.step_size != 0): return [group['lr'] for group in self.optimizer.param_groups] return [group['lr'] * self.gamma for group in self.optimizer.param_groups] 可以看到，核心在两个return行。 第一个return表示未达到step_size，新学习率保持不变 第二个return表示达到step_size，学习率均需要乘以 gamma。 至此，整个学习率更新过程及逻辑讲解完毕，其余十三个学习率调整整体逻辑一样，均是step()与get_lr()的配合来实现学习率调整，请大家举一反三，自行深入研究其它调整器。 十四个调整器汇总 lr_scheduler.LambdaLR Sets the learning rate of each parameter group to the initial lr times a given function. lr_scheduler.MultiplicativeLR Multiply the learning rate of each parameter group by the factor given in the specified function. lr_scheduler.StepLR Decays the learning rate of each parameter group by gamma every step_size epochs. lr_scheduler.MultiStepLR Decays the learning rate of each parameter group by gamma once the number of epoch reaches one of the milestones. lr_scheduler.ConstantLR Decays the learning rate of each parameter group by a small constant factor until the number of epoch reaches a pre-defined milestone: total_iters. lr_scheduler.LinearLR Decays the learning rate of each parameter group by linearly changing small multiplicative factor until the number of epoch reaches a pre-defined milestone: total_iters. lr_scheduler.ExponentialLR Decays the learning rate of each parameter group by gamma every epoch. lr_scheduler.CosineAnnealingLR Set the learning rate of each parameter group using a cosine annealing schedule, where \\eta{max}ηmax is set to the initial lr and T{cur}Tcu**r is the number of epochs since the last restart in SGDR: lr_scheduler.ChainedScheduler Chains list of learning rate schedulers. lr_scheduler.SequentialLR Receives the list of schedulers that is expected to be called sequentially during optimization process and milestone points that provides exact intervals to reflect which scheduler is supposed to be called at a given epoch. lr_scheduler.ReduceLROnPlateau Reduce learning rate when a metric has stopped improving. lr_scheduler.CyclicLR Sets the learning rate of each parameter group according to cyclical learning rate policy (CLR). lr_scheduler.OneCycleLR Sets the learning rate of each parameter group according to the 1cycle learning rate policy. lr_scheduler.CosineAnnealingWarmRestarts Set the learning rate of each parameter group using a cosine annealing schedule, where \\eta{max}ηmax is set to the initial lr, T{cur}Tcu**r is the number of epochs since the last restart and T_{i}T**i is the number of epochs between two warm restarts in SGDR: 小结 本小节通过lr_scheduler结构设计出发，分析十四个优化器是如何组织实现的，并通过_LRScheduler基类与StepLR的代码讲解学习率调整的机制。 总结下来即：初始化时建立scheduler与optimizer的联系，scheduler在每次step()时修改optimizer中的lr，step()获取新lr的功能委托给get_lr()函数实现。 最后对六个学习率调整器进行了测试并绘图，绘图代码位于配套代码 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-6/":{"url":"chapter-6/","title":"第六章 PyTorch 可视化模块","keywords":"","body":"第六章 PyTorch 可视化模块 第六章 PyTorch 可视化模块 6.1 TensorBoard安装与使用 6.2 CNN卷积核与特征图可视化 6.3 混淆矩阵与训练曲线可视化 6.4 CAM可视化与hook函数使用 6.5 模型参数打印 第六章简介 本章介绍可视化工具，包括TensorBoard可视化工具，混淆矩阵，CNN卷积核与特征图可视化，分类模型注意力算法——Grad CAM，模型参数量可视化。 首先对强大的可视化工具TensorBoard进行讲解，介绍其提供的十多个数据可视化API。 然后借助Tensorboard的绘图功能，观察CNN卷积核与特征图的变化过程，同时对分类混淆矩阵进行分析。 接着介绍一个实用的分类模型注意力机制可视化算法——Grad CAM。 最后介绍一系列对模型参数量分析的工具。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-6/6.1-tensorboard.html":{"url":"chapter-6/6.1-tensorboard.html","title":"6.1 TensorBoard安装与使用","keywords":"","body":"6.1 Tensorboard 基础与使用 Tensorboard是TensorFlow中提供的可视化工具，它能可视化数据曲线、模型拓扑图、图像、统计分布曲线等。 在PyTorch中，早期是不支持Tensorboard，采用了TensorboardX作为替身，现在PyTorch已经支持Tensorboard的使用，本节就介绍Tensorboard工具的概念、原理以及使用方法。 tensorboard 安装 首先运行以下代码，观察报错，通过报错信息指引我们安装tensorboard。 import os BASE_DIR = os.path.dirname(os.path.abspath(__file__)) from torch.utils.tensorboard import SummaryWriter log_dir = BASE_DIR # 即test_tensorboard.py文件所在目录 writer = SummaryWriter(log_dir=log_dir, filename_suffix=\"_test_tensorboard\") # writer = SummaryWriter(comment=\"test01\", filename_suffix=\"_test_tensorboard\") x = range(100) for i in x: writer.add_scalar('y=2x', i * 2, i) writer.add_scalar('y=pow(2, x)', 2 ** i, i) writer.close() 直接运行代码,提示： import tensorboard ModuleNotFoundError: No module named 'tensorboard' 只需要在命令窗口中执行： pip install tensorboard 重新运行代码，获得event file文件，《events.out.tfevents.1654508983.dream.5756.0》 tensorboard 初体验 通过以上步骤得到了一个event file 文件，下面需要启动tensorboard软件对event file文件进行可视化。 tensorboard基本原理是这样的 python代码中将可视化的数据记录到event file中，保存至硬盘 采用tensorboard对event file文件进行读取，并在web端进行可视化 启动步骤如下： tensorboard --logdir=your path dir 在terminal中执行以下命令即可，注意必须是文件夹，不能是文件名，tensorboard会将文件夹下所有event file都可视化 得到TensorBoard 2.0.0 at http://localhost:6006/ (Press CTRL+C to quit)之类的提示 然后复制网址http://localhost:6006/ 到浏览器中进行打开，就得到如下界面 在tensorboard启动的过程中，可能发生的问题： 1. 6006端口被占用： port 6006 was already in use E0117 15:58:38.631224 MainThread program.py:260] TensorBoard attempted to bind to port 6006, but it was already in use TensorBoard attempted to bind to port 6006, but it was already in use 解决方法：修改端口为6007 tensorboard --logdir=your_dir --port=6007 到这里可以知道，tensorboard软件是一个web应用，它对指定目录下的event file进行可视化，可视化页面拥有一系列功能按钮，供开发者使用。 通过demo代码，我们绘制了两条曲线，除了绘制曲线，tensorboard还又许多强大可视化功能，下面就介绍如何进行其它数据类型的可视化。 SummaryWriter类介绍 tensorboard环境配置好了，下面要重点学习在python代码中如何把各类数据合理的写入event file，然后用tensorboard软件进行可视化。 在pytorch代码中，提供了SummaryWriter类来实现数据的写入，请阅读官方文档对SummaryWriter的描述： The SummaryWriter class provides a high-level API to create an event file in a given directory and add summaries and events to it. The class updates the file contents asynchronously. This allows a training program to call methods to add data to the file directly from the training loop, without slowing down training. 首先来学习SummaryWriter的参数设置，然后学习它提供的一些列写入方法，如add_scalars、add_histogram和add_image等等。 CLASS torch.utils.tensorboard.writer.SummaryWriter(log_dir=None, comment='', purge_step=None, max_queue=10, flush_secs=120, filename_suffix='') 属性： log_dir (string) – 文件保存目录设置，默认为 runs/current_datetime_hostname comment (string) – 当log_dir采用默认值时，comment字符串作为子目录 purge_step (int) – ？ max_queue (int) –？ flush_secs (int) – 磁盘刷新时间，默认值为120秒 filename_suffix (string) –文件名后缀 方法： add_scalar add_scalar(tag, scalar_value, global_step=None, walltime=None, new_style=False, double_precision=False) 功能：添加标量；tag的设置可以有个技巧是在同一栏下绘制多个图，如'Loss/train'， 'Loss/Valid'， 这就类似于matplotlib的subplot(121), subplot(122) tag (string) – Data identifier scalar_value (float or string/blobname) – Value to save global_step (int) – Global step value to record 代码实现： add_scalars add_scalars(main_tag, tag_scalar_dict, global_step=None, walltime=None) 功能：在一个坐标轴中绘制多条曲线。常用于曲线对比。 main_tag (string) – The parent name for the tags tag_scalar_dict (dict) – Key-value pair storing the tag and corresponding values global_step (int) – Global step value to record 核心在于tag_scalar_dict 字典中存放多条曲线的数值。 代码实现： add_histogram add_histogram(tag, values, global_step=None, bins='tensorflow', walltime=None, max_bins=None) 功能：绘制直方图。这里的global_step表明会得到多个直方图，详情请看图理解。 在tensorboard界面，需要进入HISTOGRAM中才能看到直方图可视化。 tag (string) – Data identifier values (torch.Tensor, numpy.array, or string/blobname) – Values to build histogram global_step (int) – Global step value to record bins (string) – One of {‘tensorflow’,’auto’, ‘fd’, …}. This determines how the bins are made. 代码实现： add_image add_image(tag, img_tensor, global_step=None, walltime=None, dataformats='CHW') 功能：绘制图像。 tag (string) – Data identifier img_tensor (torch.Tensor, numpy.array, or string/blobname) – Image data global_step (int) – Global step value to record dataformats- 数据通道顺序物理意义。默认为 CHW 代码实现： add_images add_images(tag, img_tensor, global_step=None, walltime=None, dataformats='NCHW') 功能：绘制图像序列，常用于数据清洗，卷积核，特征图的可视化。 Add batched image data to summary.Note that this requires the pillow package. tag (string) – Data identifier img_tensor (torch.Tensor, numpy.array, or string/blobname) – Image data global_step (int) – Global step value to record walltime (float) – Optional override default walltime (time.time()) seconds after epoch of event dataformats (string) – Image data format specification of the form NCHW, NHWC, CHW, HWC, HW, WH, etc. 代码实现： add_figure add_figure(tag, figure, global_step=None, close=True, walltime=None) 功能：将matplotlib的figure绘制到tensorboard中。 Render matplotlib figure into an image and add it to summary.Note that this requires the matplotlib package. tag (string) – Data identifier figure (matplotlib.pyplot.figure) – Figure or a list of figures global_step (int) – Global step value to record close (bool) – Flag to automatically close the figure walltime (float) – Optional override default walltime (time.time()) seconds after epoch of event 剩下一些高级函数，就不一一讲解，用法雷同，再次仅汇总，供需使用。 add_video：绘制视频 add_audio：绘制音频，可进行音频播放。 add_text：绘制文本 add_graph：绘制pytorch模型拓扑结构图。 add_embedding：绘制高维数据在低维的投影 add_pr_curve：绘制PR曲线，二分类任务中很实用。 add_mesh：绘制网格、3D点云图。 add_hparams：记录超参数组，可用于记录本次曲线所对应的超参数。 小结 pytorch中使用tensorboard非常简单，只需要将想要可视化的数据采用SummaryWriter类进行记录，存在硬盘中永久保存，然后借助tensorboard软件对event file进行可视化。 tensorboard是非常强大的可视化工具，可以很好帮助开发者分析模型开发过程中的各个状态，如监控loss曲线观察模型训练情况，绘制梯度分布直方图观察是否有梯度消失，绘制网络拓扑图观察网络结构等，请大家多留意SummaryWriter官方文档的介绍，了解最新SummaryWriter有什么方法可用。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-6/6.2-cnn-visualization.html":{"url":"chapter-6/6.2-cnn-visualization.html","title":"6.2 CNN卷积核与特征图可视化","keywords":"","body":"6.2 CNN卷积核与特征图可视化 众所周知，深度学习仍是一个黑盒子，模型内部的逻辑含义仍旧无法解释，越是未知的东西，越能激起人们的好奇心。 在卷积神经网络中，有时会对卷积核以及特征图进行可视化，以此观察卷积神经网络学习到了何种模式。 作为深度卷积神经网络的开山之作，AlexNet（2012年）就已经对卷积核的模式进行了分析，论文中发现卷积核的学习具有偏向性，一部分学习颜色特征，一部分学习边缘特征，详见下图： 紧接着AlexNet之后的2013年，ZFNet对CNN的特征图进行了可视化，进一步的探究卷积神经网络的奥秘。 AlexNet：《ImageNet Classification with Deep Convolutional Neural Networks》 ZFNet：《Visualizing and understanding convolutional networks》 本节就利用tensorboard以及pytorch的函数对AlexNet的卷积核与特征图进行可视化。 make_grid 函数 在图像任务中，往往需要人眼审核、观察大批量图像数据，如果一张一张的观察，效率会非常低。 通常会将一批数据绘制成网格图片，类似大排档的菜单一样，这样便于观察。 在pytorch的torchvision库中，提供了make_grid函数帮助大家完成网格图片制作。下面先学习make_grid函数，再用它绘制卷积核与特征图。 `torchvision.utils.make_grid(tensor: Union[torch.Tensor, List[torch.Tensor]], nrow: int = 8, padding: int = 2, normalize: bool = False, value_range: Optional[Tuple[int, int]] = None, scale_each: bool = False, pad_value: float = 0.0, **kwargs) 功能： 将一组图片拼接成一张网格图片，便于可视化。 参数： tensor(Tensor or list)- 需可视化的数据，shape:(B x C x H x W) ,B表示batch数，即几张图片 nrow(int)- 一行显示几张图，默认值为8。 padding(int)- 每张图片之间的间隔，默认值为2。 normalize(bool)- 是否进行归一化至(0,1)。 value_range(tuple)- 设置归一化的min和max，若不设置，默认从tensor中找min和max。 scale_each(bool)- 每张图片是否单独进行归一化，还是min和max的一个选择。 pad_value(float)- 填充部分的像素值，默认为0，即黑色。 关于输入：make_grid的输入可以分为两种： 一种是4D张量，函数自动将第一维度作为图片数量进行拆解。 一种是list，元素必须是张量形式，并且张量的shape必须一致。 这两种输入分别对应两种常用场景： 4D张量：卷积核大小与特征图张量都适合用这种形式。 list：对普通图片进行可视化观察，一次加载一张图片时使用。 另外，对于像素的转换也需要注意相应策略，对于float类型的数据，需要设置归一化的策略，策略由value_range和scale_each构成，请自行调整观察变化。 请看代码使用效果: Alexnet卷积核可视化 要对卷积核进行可视化，就需要对pytorch的nn.Module类非常熟悉，要了解卷积核以怎样的形式？存储在哪里？ 2D卷积的卷积核权重是一个4D张量，包含输入通道，输出通道，高，宽。 注意：除了第一层可以将 输入通道 *高*宽作为 RGB图像进行可视化之外，其余网络层只能将高*宽作为灰度图像（2D）进行可视化。 卷积核存储在nn.Conv2D的weight变量中，下面就可以通过如下代码获得。 for sub_module in alexnet.modules(): # 非卷积层则跳过 if isinstance(sub_module, nn.Conv2d): # 获取conv2d层的权重，即卷积核权重 kernels = sub_module.weight 有了4D张量，剩下就按部就班的绘制到grid中可视化即可，完整代码生成的可视化图像如下所示： 可以看到，alexnet模型的第一层的卷积核确实学习到了不同模式，有边缘模式，有色彩模式。 Alexnet特征图可视化 特征图可视化与卷积核可视化类似，需要知道特征图以怎样的形式？从哪里获得？ 常规任务中，特征图是4D张量（BCHW）。 但是获得就没有那么简单，因为特征图是中间数据，通常不会保留，在前向运算过程中，不再使用的特征图会被舍弃。 因此需要特殊方法获得特征图，本节介绍一种笨办法，但容易理解，就是将对应层（仍旧是一个nn.Module）拿出来，然后把图片仍给网络层（仍旧是一个nn.Module），其输出的就是特征图了。 更高级的方法是利用hook函数机制完成中间特征图的获取，这个在本章的后半部分会介绍。 请看核心代码 alexnet = models.alexnet(pretrained=True) # forward convlayer1 = alexnet.features[0] fmap_1 = convlayer1(img_tensor) 这样就获得了(1, 64, 55, 55)的4D张量（fmap_1），然后将其转换成能可视化的形式，再利用tensorboard绘制。 完整代码生成的可视化图像如下所示： 小结 本节介绍了tensorboard对卷积核与特征图的绘制，其中涉及非常实用的函数make_grid，make_grid可以帮助开发人员高效的审核图片，人眼看图是算法工程师最重要的一步，因为模型是没办法知道哪张图片的标签搞错了！ 下一小节将介绍在模型训练过程中，如何基于tensorboard进行监控模型状态。 最后留一个思考题，将卷积核与特征图放到一起去比较，大家能否找到什么规律？ 边缘模式的卷积核似乎能过滤掉大部分细节，仅留下边缘；还能看到清晰原图信息的特征图所对应的卷积核，都是颜色卷积核。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-6/6.3-conf_matrix.html":{"url":"chapter-6/6.3-conf_matrix.html","title":"6.3 混淆矩阵与训练曲线可视化","keywords":"","body":"6.3 混淆矩阵与训练曲线可视化 在分类任务中，通过混淆矩阵可以看出模型的偏好，而且对每一个类别的分类情况都了如指掌，为模型的优化提供很大帮助。本节将介绍混淆矩阵概念及其可视化。 为了演示混淆矩阵与训练曲线，本节代码采用cifar10数据集进行训练，模型采用resnet系列。 数据cifar-10-python.tar.gz 可从 \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\" 下载，放到指定文件夹节课，无需解压，代码会自动解压。 混淆矩阵概念 混淆矩阵(Confusion Matrix)常用来观察分类结果，其是一个N*N的方阵，N表示类别数。 混淆矩阵的行表示真实类别，列表示预测类别。例如，猫狗的二分类问题，有猫的图像10张，狗的图像30张，模型对这40张图片进行预测，得到的混淆矩阵为 阿猫 阿狗 阿猫 7 3 阿狗 10 20 从第一行中可知道，10张猫的图像中，7张预测为猫，3张预测为狗，猫的召回率(Recall)为7/10 = 70%， 从第二行中可知道，30张狗的图像中，8张预测为猫，22张预测为狗，狗的召回率为20/30 = 66.7%， 从第一列中可知道，预测为猫的17张图像中，有7张是真正的猫，猫的精确度(Precision)为7 / 17 = 41.17% 从第二列中可知道，预测为狗的23张图像中，有20张是真正的狗，狗的精确度(Precision)为20 / 23 = 86.96% 模型的准确率(Accuracy)为 7+20 / 40 = 67.5% 可以发现通过混淆矩阵可以清晰的看出网络模型的分类情况，若再结合上颜色可视化，可方便的看出模型的分类偏好。 本小节将介绍，混淆矩阵的统计及其可视化。 混淆矩阵的统计 混淆矩阵的绘制将借助matplotlib的imshow功能，在imshow中可对矩阵进行上色，colorbar可自行调整，如本例中采用的黑白调，也可以选择其他的colorbar。 在模型训练中，通常以一个epoch为单位，进行混淆矩阵的统计，然后绘制，代码思路如下： 第一步：创建混淆矩阵 获取类别数，创建N*N的零矩阵 conf_mat = np.zeros([cls_num, cls_num]) 第二步：获取真实标签和预测标签 labels 为真实标签，通常为一个batch的标签 predicted为预测类别，与labels同长度 第三步：依据标签为混淆矩阵计数 for j in range(len(labels)): cate_i = labels[j].cpu().numpy() pre_i = predicted[j].cpu().numpy() conf_mat[cate_i, pre_i] += 1. 混淆矩阵可视化 混淆矩阵可视化已经封装成一个函数show_conf_mat，函数位于 配套代码 show_conf_mat(confusion_mat, classes, set_name, out_dir, epoch=999, verbose=False, perc=False) 参数： \"\"\" 混淆矩阵绘制并保存图片 :param confusion_mat: nd.array :param classes: list or tuple, 类别名称 :param set_name: str, 数据集名称 train or valid or test? :param out_dir: str, 图片要保存的文件夹 :param epoch: int, 第几个epoch :param verbose: bool, 是否打印精度信息 :param perc: bool, 是否采用百分比，图像分割时用，因分类数目过大 :return: \"\"\" show_conf_mat函数内部原理就不再详细展开，都是matplotlib的基础知识。下图为最终效果图: show_conf_mat函数提供png的保存，不便于观察整个训练过程的变化，这里借助tensorboard的add_figure功能，将每个epoch的混淆矩阵保存到tensorboard中，然后可拖拽的形式观察模型精度的变化情况。 效果如下图： 从上述变化可以发现模型在迭代过程中的偏好，前后对比图可很好的帮助工程师分析模型的偏好。 当global_step比较多的时候，toolbar无法展示每一个step，这需要在启动tensorboard的时候设置一下参数即可 tensorboard --logdir=./Result --samples_per_plugin images=200 除了手动绘制之外，sklearn库也提供了混淆矩阵绘制（from sklearn.metrics import confusion_matrix），这里不再拓展。 训练曲线绘制 除了混淆矩阵，在模型训练过程中最重要的是观察loss曲线的变化，loss曲线变化趋势直接决定训练是否需要停止，并指引我们进行参数的调整。 loss曲线是需要将训练与验证放在一起看的，单独看一条曲线是不够的，这一点需要大家了解模型评估中的方差与偏差的概念。 通过训练loss看偏差，通过训练loss与验证loss看方差。 偏差看的是模型拟合能力是否足够，方差是看模型泛化性能是否足够，是否存在过拟合。 将两条曲线绘制到一个坐标系里，可以借助tensorboard的add_scalars函数，具体请看代码 在训练集的迭代之后记录训练集的loss writer.add_scalars('Loss_group', {'train_loss': loss_avg}, epoch) 在验证集的迭代之后记录训练集的loss writer.add_scalars('Loss_group', {'valid_loss': loss_avg}, epoch) 在这里可以发现，SummaryWriter类的函数是以tag变量进行区分不同的坐标系，以上例子看出，虽然在两个地方执行代码，但是通过tag=\"Loss_group\"，仍旧可以把它们绘制在一个坐标系里。 小结 以上就是在训练过程中记录必要的训练信息，用于监控模型训练状态。 下一节将介绍有趣的CAM可视化实现，以及nn.Module模块中的系列hook函数使用。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-6/6.4-cam-vis.html":{"url":"chapter-6/6.4-cam-vis.html","title":"6.4 CAM可视化与hook函数使用","keywords":"","body":"6.4 CAM可视化与hook函数使用 前文说到，在本章第二节介绍CNN的可视化时我们知道，深度学习模型仍是一个黑箱，大家想尽办法对其进行可视化，本节就介绍一个实用的分析方法CAM(Class activation mapping，类激活图)，如下图所示： 以上图为例，CAM方法是探究模型将图片分为“Dog”的依据是什么，即图片中哪些区域支撑了模型将图片判别为\"Dog\"。 其背后的原理是将网络中间的特征图进行加权并可视化，而权重的得来就有多种方法，不同的方法就有了不同的CAM算法，如CAM、Grad CAM和Grad CAM++。 CAM：《2016-CAM-Learning Deep Features for Discriminative Localization》 Grad-CAM：《2017-Grad-CAM Visual Explanations from Deep Networks via Gradient-based Localization》 Grad-CAM++：《2018-Grad-CAM++ Generalized Gradient-based Visual Explanations for Deep Convolutional Networks》 本文将介绍其演变过程，并用手写代码实现Grad CAM，同时借助强大的github仓库，实现多种热力图对比，如下图所示： CAM 论文名称：《Learning Deep Features for Discriminative Localization》 原理解释：CAM方法需要将CNN模型修改后重新训练，修改的目的就是为了获得加权权重，具体方式如下图所示： 将最后一层特征图之后的层移除，并接入一个全连接层用于分类，全连接层的输入是特征图的全局池化后的特征向量。 最终热力图通过分类类别神经元所对应的权重w，乘以最后一层特征图，再求和即可。 背后逻辑有两个： 1、最后一层特征图是原图经过一系列卷积后保留下来的特征，其与原图的空间关系一一对应，空间关系指左上角对应左上角，右下角对应原图右下角，等等。 2、特征图对于分类类别（如上图的AustralianTerrier）的贡献程度与全连接层权重密切相关 因此，只需要利用全连接层的权重乘以对应通道，即可得到热力图。 Grad CAM 论文名称：《Grad-CAM Visual Explanations from Deep Networks via Gradient-based Localization》 CAM的思路非常巧妙，但缺点很明显，它需要对模型进行修改，并且重新训练，不适用于大多数场景。 为此，研究者提出额Grad CAM，可以对模型直接进行观察，无需改动模型。 Grad CAM的思路也非常巧妙，在CAM思路中有两个要素： 1、特征图 2、特征图对应指定类别的权重 特征图很容易获得，但特征图的重要性（加权权重）应该如何寻找？ Grad CAM给出了不一样的答案，Grad CAM利用梯度求导获得特征图的重要性权重。 原理分析： 假设最后一层feature maps有10个，那么如何寻找10个权值用来指示这些feature maps对某一类别的重要性呢？ CAM是通过对feature maps进行GAP，然后采用该类别与这个10个GAP后的神经元的连接权值作为权值； 而Grad-CAM采用的则是梯度，是该类别对于这10个feature maps的求取梯度。 注意：最终求取的梯度是一个110的向量，即每个feature map对应一个标量，而对feature maps求取梯度是一个矩阵，作者是通过对*矩阵求均值得到的标量。 对于类别c，特征图的权值 a_k^c 计算公式如下: c表示第c类，k表示第k个特征图，Z表示特征图像素点总数，i表示行，j表示列，A表示特征图。 公式可以分两部分看，最右边 gradients via backprop，即对类别c求得特征图的梯度，是一个二维的矩阵； 再通过左边的global average pooling，对二维的梯度矩阵求平均值，得到第k个特征图对于第c类的权值。 示意图如下： 最终的热力图通过以下公式进行求取： 与CAM不同的是，Grad-CAM在加权求和后还加上了ReLU函数，计算公式如下： 之所以加上ReLU，是因为在这里只关注正的梯度值，而不关注负的。 最后将Discriminative Localization Map直接resize至原图大小即可，如最后一层feature maps是14*14的，原图是224*224，则将14*14的图缩放到224*224即可。 Grad-CAM++ 论文名称：《Grad-CAM++ Generalized Gradient-based Visual Explanations for Deep Convolutional Networks》 事物总是在不断的发展，Grad CAM还存在以下缺点： 当图片出现多个同类物体时，无法定位；（1-3列） 单物体图片中，定位错误。（4-6列） 并且， Grad-CAM中一个特征图对应的权重是对特征图的梯度求平均，即认为特征图的梯度（2维数据）上的每个元素同等重要。 而Grad-CAM++则认为特征图的梯度上的每个元素重要程度应当不一样，因此对Grad CAM进行了改进。 Grad-CAM++ 热力图的权重计算通过以下公式： CAM系列对比 CAM、Grad-CAM和Grad-CAM++的区别如下图所示： 关于CAM还有很多迭代改进，可参考这个repo repo中对数十个CAM进行了实现，建议使用。 本节将用代码手动的实现Grad CAM，并通过算法的实现来学习nn.module中的hook函数使用。 nn.module中的hook函数 在CAM系列算法中知道，需要利用中间层的特征图，可nn.module并不会返回、保留中间层的特征图。这时，就要用到nn.module中的hook函数，把中间层特征图给拿出来。 什么是hook函数? pytorch中的hook是一个非常有意思的概念，hook意为钩、挂钩、鱼钩。 引用知乎用户“马索萌”对hook的解释：“(hook)相当于插件。可以实现一些额外的功能，而又不用修改主体代码。把这些额外功能实现了挂在主代码上，所以叫钩子，很形象。” 简单讲，就是不修改主体，而实现额外功能。对应到在pytorch中，主体就是forward和backward，而额外的功能就是对模型的变量进行操作 pytorch提供的hook 1. torch.Tensor.register_hook 功能：注册一个反向传播hook函数，这个函数是Tensor类里的，当计算tensor的梯度时自动执行。 形式： hook(grad) -> Tensor or None ，其中grad就是这个tensor的梯度。 返回值：a handle that can be used to remove the added hook by calling handle.remove() 案例请看配套代码 2. torch.nn.Module.register_forward_hook 功能：Module前向传播中的hook,module在前向传播后，自动调用hook函数。 形式：hook(module, input, output) -> None。注意不能修改input和output 返回值 其中，module是当前网络层，input是网络层的输入数据, output是网络层的输出数据 应用场景：如用于提取特征图 案例请看配套代码 3. torch.nn.Module.register_forward_pre_hook 功能：执行forward()之前调用hook函数。 形式：hook(module, input) -> None or modified input 应用场景举例：暂时没碰到过，希望读者朋友补充register_forward_pre_hook相关应用场景。 registerforwardprehook与forwardhook一样，是在module.__call中注册的，与forward_hook不同的是，其在module执行forward之前就运行了，具体可看module.__call中的代码，第一行就是执行forward_pre_hook的相关操作。 4. torch.nn.Module.register_full_backward_hook 功能：Module反向传播中的hook,每次计算module的梯度后，自动调用hook函数。 形式：hook(module, grad_input, grad_output) -> tuple(Tensor) or None 注意事项：当module有多个输入或输出时，grad_input和grad_output是一个tuple。 返回值：a handle that can be used to remove the added hook by calling handle.remove() 应用场景举例：例如提取特征图的梯度 Grad CAM 手动实现 下面就利用 register_forward_hook 和 register_full_backward_hook 来实现Grad CAM 详情请看配套代码 整体思路如下： 对模型最后一个卷积层进行hook函数注册，两个hook分别记录特征图于梯度 def backward_hook(module, grad_in, grad_out): grad_block.append(grad_out[0].detach()) def farward_hook(module, input, output): fmap_block.append(output) ------------------------------------------------------------ # 注册hook resnet_50.layer4[-1].register_forward_hook(farward_hook) resnet_50.layer4[-1].register_full_backward_hook(backward_hook) 获取类别loss，类别loss为分类类别最大的那个神经元的值，具体由comp_class_vec函数实现 if not index: index = np.argmax(ouput_vec.cpu().data.numpy()) else: index = np.array(index) index = index[np.newaxis, np.newaxis] index = torch.from_numpy(index) one_hot = torch.zeros(1, 1000).scatter_(1, index, 1) one_hot.requires_grad = True class_vec = torch.sum(one_hot * ouput_vec) # one_hot = 11.8605 执行backward，得到梯度 通过gen_cam()函数得到CAM图 将CAM与原图进行融合可视化，如下图所示 CAM 系列算法统一实现 CAM自2016年提出以来，已经有多种改进，并可运用于图像分割和目标检测，详细的CAM算法参见仓库。 pytorch-grad-cam提供了丰富的算法及简单的接口应用，下面就以resnet50为例，绘制6种CAM算法的热力图，效果如下图所示。 代码就不剖析了，grad-cam的接口已经非常清晰。请运行代码，查看结果如下图所示： 小结 CAM系列算法对理解深度卷积神经网络非常有帮助，建议仔细学习本节内容并进行拓展。 通过CAM分析： 可诊断模型是否学到真正特征 可通过热力图信息做对应的数据增强（如对非激活区域进行随机擦除和Cutout处理），类似YOLOv4中的CutMix数据增强方法。 还可以将热力图作为语义分割的弱监督标签进行训练分割模型，可参考《Tell Me Where to Look: Guided Attention Inference Network》 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-6/6.5-model-print.html":{"url":"chapter-6/6.5-model-print.html","title":"6.5 模型参数打印","keywords":"","body":"6.5 模型参数可视化 随着神经网络越来越深，越来越复杂，手动计算模型中间的数据的shape变得困难。 本节将介绍torchinfo，可用一键实现模型参数量计算、各层特征图形状计算和计算量计算等功能。 torchinfo的功能最早来自于TensorFlow和Kearas的summary()函数，torchinfo是学习借鉴而来。而在torchinfo之前还有torchsummary工具，不过torchsummary已经停止更新，并且推荐使用torchinfo。 torchsummay：https://github.com/sksq96/pytorch-summary torchinfo：https://github.com/TylerYep/torchinfo torchinfo 主要提供了一个函数，即 def summary( model: nn.Module, input_size: Optional[INPUT_SIZE_TYPE] = None, input_data: Optional[INPUT_DATA_TYPE] = None, batch_dim: Optional[int] = None, cache_forward_pass: Optional[bool] = None, col_names: Optional[Iterable[str]] = None, col_width: int = 25, depth: int = 3, device: Optional[torch.device] = None, dtypes: Optional[List[torch.dtype]] = None, mode: str | None = None, row_settings: Optional[Iterable[str]] = None, verbose: int = 1, **kwargs: Any, ) -> ModelStatistics: torchinfo 演示 运行代码 resnet_50 = models.resnet50(pretrained=False) batch_size = 1 summary(resnet_50, input_size=(batch_size, 3, 224, 224)) 可看到resnet50的以下信息 ========================================================================================== Layer (type:depth-idx) Output Shape Param # ========================================================================================== ResNet [1, 1000] -- ├─Conv2d: 1-1 [1, 64, 112, 112] 9,408 ├─BatchNorm2d: 1-2 [1, 64, 112, 112] 128 ├─ReLU: 1-3 [1, 64, 112, 112] -- ├─MaxPool2d: 1-4 [1, 64, 56, 56] -- ├─Sequential: 1-5 [1, 256, 56, 56] -- │ └─Bottleneck: 2-1 [1, 256, 56, 56] -- │ │ └─Conv2d: 3-1 [1, 64, 56, 56] 4,096 │ │ └─BatchNorm2d: 3-2 [1, 64, 56, 56] 128 │ │ └─ReLU: 3-3 [1, 64, 56, 56] -- │ │ └─Conv2d: 3-4 [1, 64, 56, 56] 36,864 │ │ └─BatchNorm2d: 3-5 [1, 64, 56, 56] 128 │ │ └─ReLU: 3-6 [1, 64, 56, 56] -- │ │ └─Conv2d: 3-7 [1, 256, 56, 56] 16,384 │ │ └─BatchNorm2d: 3-8 [1, 256, 56, 56] 512 │ │ └─Sequential: 3-9 [1, 256, 56, 56] 16,896 │ │ └─ReLU: 3-10 [1, 256, 56, 56] -- ...... │ └─Bottleneck: 2-16 [1, 2048, 7, 7] -- │ │ └─Conv2d: 3-140 [1, 512, 7, 7] 1,048,576 │ │ └─BatchNorm2d: 3-141 [1, 512, 7, 7] 1,024 │ │ └─ReLU: 3-142 [1, 512, 7, 7] -- │ │ └─Conv2d: 3-143 [1, 512, 7, 7] 2,359,296 │ │ └─BatchNorm2d: 3-144 [1, 512, 7, 7] 1,024 │ │ └─ReLU: 3-145 [1, 512, 7, 7] -- │ │ └─Conv2d: 3-146 [1, 2048, 7, 7] 1,048,576 │ │ └─BatchNorm2d: 3-147 [1, 2048, 7, 7] 4,096 │ │ └─ReLU: 3-148 [1, 2048, 7, 7] -- ├─AdaptiveAvgPool2d: 1-9 [1, 2048, 1, 1] -- ├─Linear: 1-10 [1, 1000] 2,049,000 ========================================================================================== Total params: 25,557,032 Trainable params: 25,557,032 Non-trainable params: 0 Total mult-adds (G): 4.09 ========================================================================================== Input size (MB): 0.60 Forward/backward pass size (MB): 177.83 Params size (MB): 102.23 Estimated Total Size (MB): 280.66 ========================================================================================== 其中包括各网络层名称，以及层级关系，各网络层输出形状以及参数量。在最后还有模型的总结，包括总的参数量有25,557,032个，总的乘加（Mult-Adds）操作有4.09G（4.09*10^9次方 浮点运算），输入大小为0.60MB，参数占102.23MB。 计算量：1G表示10^9 次浮点运算 （Giga Floating-point Operations Per Second），关于乘加运算，可参考知乎问题 存储量：这里的Input size (MB): 0.60，是通过数据精度计算得到，默认情况下采用float32位存储一个数，因此输入为：3*224*224*32b = 4816896b = 602112B = 602.112 KB = 0.6 MB 同理，Params size (MB): 25557032 * 32b = 817,825,024 b = 102,228,128 B = 102.23 MB 接口详解 summary提供了很多参数可以配置打印信息，这里介绍几个常用参数。 col_names：可选择打印的信息内容，如 (\"input_size\",\"output_size\",\"num_params\",\"kernel_size\",\"mult_adds\",\"trainable\",) dtypes：可以设置数据类型，默认的为float32，单精度。 mode：可设置模型在训练还是测试状态。 verbose: 可设置打印信息的详细程度。0是不打印，1是默认，2是将weight和bias也打出来。 小结 本节介绍torchinfo的使用，并分析其参数的计算过程，这里需要了解训练参数数量、特征图参数数量和计算量。其中计算量还有一个好用的工具库进行计算，这里作为额外资料供大家学习——PyTorch-OpCounter Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-7/":{"url":"chapter-7/","title":"第七章 PyTorch 小技巧汇总","keywords":"","body":"第七章 PyTorch 小技巧汇总 第七章 PyTorch 小技巧汇总 7.1 模型保存与加载 7.2 Finetune 模型微调 7.3 GPU使用 7.4 模型训练代码模板 7.5 TorchMetrics 模型评估指标库 7.6 Albumentations 数据增强库 7.7 TorchEnsemble 模型集成库 第七章简介 本章介绍开发过程中常用的代码段、工具模块和技巧等，初步设计有模型保存与加载、模型Finetune技巧、GPU使用技巧、训练代码框架等。 本章小结会续更新，将工作中遇到的小技巧分享出来。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-7/7.1-serialization.html":{"url":"chapter-7/7.1-serialization.html","title":"7.1 模型保存与加载","keywords":"","body":"7.1 模型保存与加载 保存与加载的概念（序列化与反序列化） 模型训练完毕之后，肯定想要把它保存下来，供以后使用，不需要再次去训练。 那么在pytorch中如何把训练好的模型，保存，保存之后又如何加载呢？ 这就用需要序列化与反序列化，序列化与反序列化的概念如下图所示： 因为在内存中的数据，运行结束会进行释放，所以我们需要将数据保存到硬盘中，以二进制序列的形式进行长久存储，便于日后使用。 序列化即把对象转换为字节序列的过程，反序列化则把字节序列恢复为对象。 在pytorch中，对象就是模型，所以我们常常听到序列化和反序列化，就是将训练好的模型从内存中保存到硬盘里，当要使用的时候，再从硬盘中加载。 torch.save / torch.load pytorch提供的序列化与反序列化函数分别是 1. torch.save(obj, f, pickle_module=pickle, pickle_protocol=DEFAULT_PROTOCOL, _use_new_zipfile_serialization=True) 功能：保存对象到硬盘中 主要参数： obj- 对象 f - 文件路径 2. torch.load(f, map_location=None, pickle_module=pickle, **pickle_load_args) 功能：加载硬盘中对象 主要参数： f - 文件路径 map_location - 指定存储位置，如map_location='cpu'， map_location={'cuda:1':'cuda:0'} 这里的map_location大有文章，经常需要手动设置，否者会报错。具体可参考以下形式： GPU->CPU：torch.load(model_path, map_location='cpu') CPU->GPU：torch.load(model_path, map_location=lambda storage, loc: storage) 两种保存方式 pytorch保存模型有两种方式 保存整个模型 保存模型参数 我们通过示意图来区分两者之间的差异 从上图左边知道法1保存整个nn.Module， 而法2只保存模型的参数信息。 我们知道一个module当中包含了很多信息，不仅仅是模型的参数 parameters，还包含了buffers, hooks和modules等一系列信息。 对于模型应用，最重要的是模型的parameters，其余的信息是可以通过model 类再去构建的，所以模型保存就有两种方式 所有内容都保存； 仅保存模型的parameters。 通常，我们只需要保存模型的参数，在使用的时候再通过load_state_dict方法加载参数。 由于第一种方法不常用，并且在加载过程中还需要指定的类方法，因此不做演示也不推荐。 对于第二种方法的代码十分简单，请看示例： net_state_dict = net.state_dict() torch.save(net_state_dict, \"my_model.pth\") 常用的代码段 在模型开发过程中，往往不是一次就能训练好模型，经常需要反复训练，因此需要保存训练的“状态信息”，以便于基于某个状态继续训练，这就是常说的resume，可以理解为断点续训练。 在整个训练阶段，除了模型参数需要保存，还有优化器的参数、学习率调整器的参数和迭代次数等信息也需要保存，因此推荐在训练时，采用以下代码段进行模型保存。以下代码来自torchvision的训练脚本。 checkpoint = { \"model\": model_without_ddp.state_dict(), \"optimizer\": optimizer.state_dict(), \"lr_scheduler\": lr_scheduler.state_dict(), \"epoch\": epoch, } path_save = \"model_{}.pth\".format(epoch) torch.save(checkpoint, path_save # =================== resume =============== # resume checkpoint = torch.load(path_save, map_location=\"cpu\") model.load_state_dict(checkpoint[\"model\"]) optimizer.load_state_dict(checkpoint[\"optimizer\"]) lr_scheduler.load_state_dict(checkpoint[\"lr_scheduler\"]) start_epoch = checkpoint[\"epoch\"] + 1 小结 模型保存与加载比较简单，需要注意的有两点： torch.load的时候注意map_location的设置； 理解checkpoint resume的概念，以及训练过程是需要模型、优化器、学习率调整器和已迭代次数的共同配合。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-7/7.2-finetune.html":{"url":"chapter-7/7.2-finetune.html","title":"7.2 Finetune 模型微调","keywords":"","body":"7.2 Finetune 模型微调 Finetune（微调）是深度学习模型训练中常用的方法。Finetune的理论可从迁移学习（Transfer Learning）中学习。 迁移学习 Transfer Learning是机器学习的分支，主要研究源域(source domain)所学到的知识，如何迁移到目标域(target domain)中 如《A Survey on Transfer Learning》中的图所示： 为什么要这样做呢？这是因为在target domain中，数据量较少，可学习提取的知识不足以完成任务，所以需要进行迁移学习，这样在target domain中可以学得快，学得好。 例如一个人学会了骑自行车，再去学骑电动车就很快，又比如一个人学会了C语言，再去学python就会比较快。 transfer learning是一个较大的领域，这里只讨论神经网络的finetune，如何理解模型的finetune它也是迁移学习呢？ 我们知道，神经网络中最重要的东西就是权值参数，训练模型就是在更新参数，这些参数就是模型学习到知识。 之前对alexnet的卷积核进行了可视化，可以理解卷积核学习到的图像边缘，色彩信息就是alexnet所学习到的知识。 在图像任务中，这些知识是可以共享，可以迁移到其它任务中去，因此，大家常常采用在imagenet上训练好的模型进行finetune，进行transfer learning。 Finetune常用的两种方法 通常，会将模型划分为两个部分 feature extractor: 将fc层之前的部分认为是一个feature extractor classifier: fc层认为是classifier 基于此，finetune大体有两种方法： 将 feature extractor部分的参数固定，冻结，不进行训练，仅训练classifier 将 feature extractor设置较小的学习率，classifier设置较大的学习率 下面通过一个实例讲解两种方法 方法一：冻结 feature extractor。 原理是通过设置paramters的requires_grad为False，让它们不进行权重更新即可。 for param in resnet18_ft.parameters(): param.requires_grad = True 在完整代码中，每个epoch都打印了第一个卷积层权重，观察它们是否有变化。 经过25个epoch训练，性能指标如下图所示。 方法二：不同层不同学习率 原理是通过优化器的参数组管理，不同参数组可以设置不同的学习率。 因此第一步需要将不同的参数从模型中识别、提取出来，分别定义为不同参数组，这里通过内存地址进行区分。 # 返回的是该层所有参数的内存地址 fc_params_id = list(map(id, resnet18_ft.fc.parameters())) #遍历model的参数，只要不是需要ignore的，就保留，返回filter对象，在optimizer.py中的add_param_group中有 base_params = filter(lambda p: id(p) not in fc_params_id, resnet18_ft.parameters()) optimizer = optim.SGD([ {'params': base_params, 'lr': LR}, # 0 {'params': resnet18_ft.fc.parameters(), 'lr': LR*2}], momentum=0.9) 通过代码看到最后的全连接层学习率比前面的特征提取部分大10倍，如果对optimizer的参数组概念不了解，请回看第五章 小结 Finetune的代码实现非常简单，不过需要大家对nn.Module和optimizer的基础概念熟悉，建议回顾第四章与第五章的基础知识。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-7/7.3-gpu.html":{"url":"chapter-7/7.3-gpu.html","title":"7.3 GPU使用","keywords":"","body":"7.3 GPU使用 深度学习之所以可以发展迅猛，得益于强大的计算力。在PyTorch中，自然加持GPU加速运算，本节将介绍PyTorch中GPU的使用原理与多GPU使用的DataParallel原理，还有一些针对GPU的实用代码段。 gpu与cpu 在处理器家族中，有两大阵营，分别是CPU和GPU，它们分工协作，共同完成计算机复杂功能。 但它们两者主要差别在哪里？下面一探究竟。 CPU(central processing unit, 中央处理器)cpu主要包括两个部分，即控制器、运算器，除此之外还包括高速缓存等 GPU(Graphics Processing Unit, 图形处理器)是为处理类型统一并且相互无依赖的大规模数据运算，以及不需要被打断的纯净的计算环境为设计的处理器，因早期仅有图形图像任务中设计大规模统一无依赖的运算，因此该处理器称为图像处理器，俗称显卡。 那么它们之间主要区别在哪里呢，来看一张示意图 绿色的是计算单元，橙红色的是存储单元，橙黄色的是控制单元，从示意图中看出，gpu的重点在计算，cpu的重点在控制，这就是两者之间的主要差异。 在pytorch中，可以将训练数据以及模型参数迁移到gpu上，这样就可以加速模型的运算 在这里，需要了解的是，在pytorch中，两个数据运算必须在同一个设备上。 PyTorch的设备——torch.device 前面提到，PyTorch的运算需要将运算数据放到同一个设备上，因此，需要了解PyTorch中设备有哪些？ 目前，PyTorch支持两种设备，cpu与cuda，为什么是cuda而不是gpu？因为早期，只有Nvidia的GPU能用于模型训练加速，因此称之为cuda。 即使现在支持了AMD显卡进行加速，仍旧使用cuda来代替gpu。 PyTorch中表示设备通常用torch.device)这个函数进行设置，例如: >>> torch.device('cuda:0') device(type='cuda', index=0) >>> torch.device('cpu') device(type='cpu') >>> torch.device('cuda') # current cuda device device(type='cuda') 补充资料： ROCm平台及HIP介绍 https://pytorch.org/docs/stable/notes/hip.html 把数据放到GPU——to函数 在pytorch中，只需要将要进行运算的数据放到gpu上，即可使用gpu加速运算 在模型运算过程中，需要放到GPU的主要是两个： 输入数据——形式为tensor 网络模型——形式为module pytorch中针对这两种数据都有相应的函数把它们放到gpu上，我们来认识一下这个函数，就是to函数 tensor的to函数: to(*args, \\kwargs) → Tensor** 功能：转换张量的数据类型或者设备 注意事项：to函数不是inplace操作，所以需要重新赋值，这与module的to函数不同 使用： 转换数据类型 x = torch.ones((3, 3)) x = x.to(torch.float64) 转换设备 x = torch.ones((3, 3)) x = x.to(\"cuda\") module的to函数：to(*args, \\kwargs)** 功能：move and/or cast the parameters and buffers，转换模型中的参数和缓存 注意事项：实行的是inplace操作 使用： 转换数据类型 linear = nn.Linear(2, 2) print(linear.weight) linear.to(torch.double) print(linear.weight) 迁移至gpu gpu1 = torch.device(\"cuda:1\") linear.to(gpu1) print(linear.weight) 将torch.device 与 to函数联合使用，就是第六章混淆矩阵代码中使用过的方式 device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") model.to(device) inputs, labels = inputs.to(device), labels.to(device) 通常，会采用torch.cuda.is_available()函数来自适应当前设备，若没有gpu可用，自动设置device为cpu，不会影响代码的运行。 除了torch.cuda.is_available()，torch库中还有一些关于cuda的实用函数，下面一起看看。 torch.cuda 在torch.cuda中有几十个关于guda的函数，详细请查阅官方文档) 下面介绍几个常用的函数。 torch.cuda.device_count()： 查看可用GPU数量 torch.cuda.current_device()：查看当前使用的设备的序号 torch.cuda.get_device_name()：获取设备的名称 torch.cuda.get_device_capability(device=None)：查看设备的计算力 torch.cuda.is_available()：查看cuda是否可用 torch.cuda.get_device_properties()：查看GPU属性 torch.cuda.set_device(device)：设置可用设备，已不推荐使用，建议通过CUDA_VISIBLE_DEVICES来设置，下文会讲解CUDA_VISIBLE_DEVICES的使用。 torch.cuda.mem_get_info(device=None)：查询gpu空余显存以及总显存。 torch.cuda.memory_summary(device=None, abbreviated=False)：类似模型的summary，它将GPU的详细信息进行输出。 torch.cuda.empty_cache()：清空缓存，释放显存碎片。 torch.backends.cudnn.benchmark = True : 提升运行效率，仅适用于输入数据较固定的，如卷积 会让程序在开始时花费一点额外时间，为整个网络的每个卷积层搜索最适合它的卷积实现算法，进而实现网络的加速让内置的 cuDNN 的 auto-tuner 自动寻找最适合当前配置的高效算法，来达到优化运行效率的问题 torch.backends.cudnn.deterministic: 用以保证实验的可重复性. 由于cnDNN 每次都会去寻找一遍最优配置，会产生随机性，为了模型可复现，可设置torch.backends.cudnn.deterministic = True 运行代码，可看到如下信息： device_count: 1 current_device: 0 (8, 6) NVIDIA GeForce RTX 3060 Laptop GPU True ['sm_37', 'sm_50', 'sm_60', 'sm_61', 'sm_70', 'sm_75', 'sm_80', 'sm_86', 'compute_37'] _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060 Laptop GPU', major=8, minor=6, total_memory=6144MB, multi_processor_count=30) (5407899648, 6442450944) |===========================================================================| | PyTorch CUDA memory summary, device ID 0 | |---------------------------------------------------------------------------| | CUDA OOMs: 0 | cudaMalloc retries: 0 | |===========================================================================| | Metric | Cur Usage | Peak Usage | Tot Alloc | Tot Freed | |---------------------------------------------------------------------------| | Allocated memory | 0 B | 0 B | 0 B | 0 B | | from large pool | 0 B | 0 B | 0 B | 0 B | | from small pool | 0 B | 0 B | 0 B | 0 B | |---------------------------------------------------------------------------| | Active memory | 0 B | 0 B | 0 B | 0 B | | from large pool | 0 B | 0 B | 0 B | 0 B | | from small pool | 0 B | 0 B | 0 B | 0 B | |---------------------------------------------------------------------------| | GPU reserved memory | 0 B | 0 B | 0 B | 0 B | | from large pool | 0 B | 0 B | 0 B | 0 B | | from small pool | 0 B | 0 B | 0 B | 0 B | |---------------------------------------------------------------------------| | Non-releasable memory | 0 B | 0 B | 0 B | 0 B | | from large pool | 0 B | 0 B | 0 B | 0 B | | from small pool | 0 B | 0 B | 0 B | 0 B | |---------------------------------------------------------------------------| | Allocations | 0 | 0 | 0 | 0 | | from large pool | 0 | 0 | 0 | 0 | | from small pool | 0 | 0 | 0 | 0 | |---------------------------------------------------------------------------| | Active allocs | 0 | 0 | 0 | 0 | | from large pool | 0 | 0 | 0 | 0 | | from small pool | 0 | 0 | 0 | 0 | |---------------------------------------------------------------------------| | GPU reserved segments | 0 | 0 | 0 | 0 | | from large pool | 0 | 0 | 0 | 0 | | from small pool | 0 | 0 | 0 | 0 | |---------------------------------------------------------------------------| | Non-releasable allocs | 0 | 0 | 0 | 0 | | from large pool | 0 | 0 | 0 | 0 | | from small pool | 0 | 0 | 0 | 0 | |---------------------------------------------------------------------------| | Oversize allocations | 0 | 0 | 0 | 0 | |---------------------------------------------------------------------------| | Oversize GPU segments | 0 | 0 | 0 | 0 | |===========================================================================| None 多gpu训练——nn.DataParallel 人多力量大的道理在PyTorch的训练中也是适用的，PyTorch支持多个GPU共同训练，加快训练速度。 多GPU可分为单机多卡和多机多卡，这里仅介绍单机多卡的方式。 单机多卡的实现非常简单，只需要增加一行代码： net = nn.DataParallel(net) 代码的意思是将一个nn.Module变为一个特殊的nn.Module，这个Module的forward函数实现多GPU调用。 如果对nn.Module的概念以及forward函数不理解的话，请回到第四章进行学习。 首先看一幅示意图，理解多GPU是如何工作的 整体有四个步骤： 数据平均划为N份 模型参数复制N份 在N个GPU上同时运算 回收N个GPU上的运算结果 了解了多gpu运行机制，下面看看DataParallel是如何实现的。 torch.nn.DataParallel(module, device_ids=None, output_device=None, dim=0) 功能：实现模型的数据并行运算 主要参数： module - 需要并行的module device_ids: (list of python:int or torch.device) – CUDA devices (default: all devices), eg: [2, 3] 默认采用所有可见gpu，这里强调了可见gpu，就是说可以设置部分gpu对当前python脚本不可见，这个可以通过系统环境变量设置 output_device: int or torch.device , 设置输出结果所在设备，默认为 device_ids[0]，通常以第1个逻辑gpu为主gpu 源代码分析： DataParallel仍旧是一个nn.Module类，所以首要关注它的forward函数。 来到/torch/nn/parallel/data_parallel.py的147行： def forward(self, *inputs, **kwargs): with torch.autograd.profiler.record_function(\"DataParallel.forward\"): if not self.device_ids: return self.module(*inputs, **kwargs) for t in chain(self.module.parameters(), self.module.buffers()): if t.device != self.src_device_obj: raise RuntimeError(\"module must have its parameters and buffers \" \"on device {} (device_ids[0]) but found one of \" \"them on device: {}\".format(self.src_device_obj, t.device)) inputs, kwargs = self.scatter(inputs, kwargs, self.device_ids) # for forward function without any inputs, empty list and dict will be created # so the module can be executed on one device which is the first one in device_ids if not inputs and not kwargs: inputs = ((),) kwargs = ({},) if len(self.device_ids) == 1: return self.module(*inputs[0], **kwargs[0]) replicas = self.replicate(self.module, self.device_ids[:len(inputs)]) outputs = self.parallel_apply(replicas, inputs, kwargs) return self.gather(outputs, self.output_device) 核心点有4行代码，分别是： inputs, kwargs = self.scatter(inputs, kwargs, self.device_ids) replicas = self.replicate(self.module, self.device_ids[:len(inputs)]) outputs = self.parallel_apply(replicas, inputs, kwargs) return self.gather(outputs, self.output_device) 一、数据切分 inputs, kwargs = self.scatter(inputs, kwargs, self.device_ids)：利用scatter函数，将数据切分为多块，为各GPU需要的数据做准备。 scatter函数在torch\\nn\\parallel\\scatter_gather.py第11行。 def scatter(inputs, target_gpus, dim=0): r\"\"\" Slices tensors into approximately equal chunks and distributes them across given GPUs. Duplicates references to objects that are not tensors. \"\"\" 二、模型分发至GPU replicas = self.replicate(self.module, self.device_ids[:len(inputs)])：利用replicate函数将模型复制N份，用于多GPU上。 replicate函数在 torch\\nn\\parallel\\replicate.py第78行。 三、执行并行推理 outputs = self.parallel_apply(replicas, inputs, kwargs)：多GPU同时进行运算。 四、结果回收 return self.gather(outputs, self.output_device) 为了理解分发过程，请使用具备多GPU的环境，运行配套代码，可看到如下信息： batch size in forward: 4 batch size in forward: 4 batch size in forward: 4 batch size in forward: 4 model outputs.size: torch.Size([16, 3]) CUDA_VISIBLE_DEVICES :0,1,3,2 device_count :4 batchsize设置为16，将16个样本平均分发给4个GPU，因此在forward函数当中，看到的数据是4个样本。 多GPU训练模型的保存与加载 当模型变为了Dataparallel时，其参数名称会多一个module.字段，这导致在保存的时候state_dict也会多了module.字段。 从而，在加载的时候经常出现以下报错。 RuntimeError: Error(s) in loading state_dict for FooNet: ​ Missing key(s) in state_dict: \"linears.0.weight\", \"linears.1.weight\", \"linears.2.weight\". ​ Unexpected key(s) in state_dict: \"module.linears.0.weight\", \"module.linears.1.weight\", \"module.linears.2.weight\". 解决方法是，移除key中的module.： from collections import OrderedDict new_state_dict = OrderedDict() for k, v in state_dict_load.items(): namekey = k[7:] if k.startswith('module.') else k new_state_dict[namekey] = v 请结合代码运行，观察其使用，并看到如下结果： state_dict_load: OrderedDict([('module.linears.0.weight', tensor([[ 0.3337, 0.0317, -0.1331], [ 0.0431, 0.0454, 0.1235], [ 0.0575, -0.2903, -0.2634]])), ('module.linears.1.weight', tensor([[ 0.1235, 0.1520, -0.1611], [ 0.4511, -0.1460, -0.1098], [ 0.0653, -0.5025, -0.1693]])), ('module.linears.2.weight', tensor([[ 0.3657, -0.1107, -0.2341], [ 0.0657, -0.0194, -0.3119], [-0.0477, -0.1008, 0.2462]]))]) new_state_dict: OrderedDict([('linears.0.weight', tensor([[ 0.3337, 0.0317, -0.1331], [ 0.0431, 0.0454, 0.1235], [ 0.0575, -0.2903, -0.2634]])), ('linears.1.weight', tensor([[ 0.1235, 0.1520, -0.1611], [ 0.4511, -0.1460, -0.1098], [ 0.0653, -0.5025, -0.1693]])), ('linears.2.weight', tensor([[ 0.3657, -0.1107, -0.2341], [ 0.0657, -0.0194, -0.3119], [-0.0477, -0.1008, 0.2462]]))]) Process finished with exit code 0 使用指定编号的gpu 通常，一台服务器上有多个用户，或者是会进行多个任务，此时，对gpu合理的安排使用就尤为重要 在实践中，通常会设置当前python脚本可见的gpu，然后直接使用nn.dataparallel使用所有gpu即可，不需要手动去设置使用哪些gpu 设置python脚本可见gpu的方法为设置系统环境变量中的CUDA_VISIBLE_DEVICES 设置方法为： os.environ.setdefault(\"CUDA_VISIBLE_DEVICES\", \"2, 3\") 当时之后，即物理设备的2,3号GPU，在程序中分别是0号、1号GPU，这里需要理解逻辑编号与物理编号的对应关系。 注意事项： CUDA_VISIBLE_DEVICES的设置一定要在 device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") 之前！ 否则已经调用cuda，python脚本已经获取当前可见gpu了，再设置就无效了 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-7/7.4-training-script.html":{"url":"chapter-7/7.4-training-script.html","title":"7.4 模型训练代码模板","keywords":"","body":"7.4 模型训练代码模板 一个良好的训练代码，可以有助于分析和超参调优，本节将以torchvision提供的分类模型训练代码为基础，编写适合自己的训练代码框架。 torchvision还提供了分割、检测、相似性学习和视频分类的 训练脚本，可以参考https://pytorch.org/vision/stable/training_references.html。 在分类的train.py中，共计501行代码，下面我们提炼出核心内容，在cifar10数据集上完成resnet-8的训练。 提炼后，代码核心内容包括： 参数设置部分采用argparse模块进行配置，便于服务器上训练，以及超参数记录； 日志模块，包括logging模块记录文本信息.log文件，以及tensorboard部分的可视化内容； 训练模块封装为通用类——ModelTrainer 模型保存部分 一、参数设置 在服务器上进行训练时，通常采用命令行启动，或时采用sh脚本批量训练，这时候就需要从命令行传入一些参数，用来调整模型超参。 例如学习率想从0.1改为0.01，按以往代码，需要进入.py文件，修改代码，保存代码，运行代码。 这样操作明显欠妥，因此通常会采用argparse模块，将经常需要调整的参数，可以从命令行中接收。 在代码中，采用了函数get_args_parser()实现，有了args，还可以将它记录到日志中，便于复现以及查看模型的超参数设置，便于跟踪。 二、日志模块 模型训练的日志很重要，它用于指导下一次实验的超参数如何调整。 代码中采用借助logging模块构建一个logger，并且以时间戳（年月日-时分秒）的形式创建文件夹，便于日志管理。 在logger中使用logger.info函数代替print函数，可以实现在终端展示信息，还可以将其保存到日志文件夹下的log.log文件，便于溯源。 三、训练模块 训练过程比较固定，因此会将其封装成 train_one_epoch和evaluate的两个函数，从这两个函数中需要返回我们关心的指标，如loss，accuracy，混淆矩阵等。 四、指标统计模块 之前的代码中，loss和accuracy需要手动记录每个值，然后取平均，除了它们两个，深度学习训练中还有许多指标都需要类似的操作。 因此，可以抽象出一个AverageMeter类，用于记录需要求取平均值的那些指标。 AverageMeter类的使用，使得代码更简洁，下面一同分析一下。 运行代码当训练完成后，可在输出目录下得到以时间戳为文件夹的日志目录，里面包括loss、accuracy、混淆矩阵可视化图，最优模型checkpoint。 小结 训练模型的代码结构可以千变万化，每个人结合自己的风格进行编写，本节代码也是吸取了多个代码的精华，当然还有不足之处，后续会慢慢补上，这里提供一个整体思路，知道代码中需要什么。 建议参考以下训练代码结构： PyTorch ImageNet example (https://github.com/pytorch/examples/tree/master/imagenet) NVIDIA CUDA specific speedups adopted from NVIDIA Apex examples (https://github.com/NVIDIA/apex/tree/master/examples/imagenet) TIMM: https://github.com/rwightman/pytorch-image-models/blob/master/train.py Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-7/7.5-torchmetrics.html":{"url":"chapter-7/7.5-torchmetrics.html","title":"7.5 TorchMetrics 模型评估指标库","keywords":"","body":"7.5 torchmetrics 模型评估指标库 模型训练时是通过loss进行好坏的评估，因为我们采用的是loss进行方向传播。对于人类评判好坏，往往不是通过loss值，而是采用某种评判指标。 在图像分类任务中常用的有Accuracy（准确率）、Recall（召回率）和Precision（精确度），图像分割中常用mIoU和Dice系数，目标检测中常用mAP，由此可见不同任务的评价指标大多不一样。 常用的指标多达几十种，本节将介绍torchmetrics工具，它目前提供超过80种评价指标的函数，并且使用起来非常方便，值得学习。 TorchMetrics简介与安装 TorchMetrics： Github TorchMetrics is a collection of 80+ PyTorch metrics implementations and an easy-to-use API to create custom metrics. It offers: A standardized interface to increase reproducibility Reduces Boilerplate Distributed-training compatible Rigorously tested Automatic accumulation over batches Automatic synchronization between multiple devices 安装： pip install torchmetrics conda install -c conda-forge torchmetrics TorchMetrics 快速上手 torchmetrics 的使用与本章第四节课中介绍的AverageMeter类似，它能够记录每一次的信息，并通过.compute()函数进行汇总计算。 下面通过一个accuracy的例子，剖析torchmetrics的体系结构。 from my_utils import setup_seed setup_seed(40) import torch import torchmetrics metric = torchmetrics.Accuracy() n_batches = 3 for i in range(n_batches): preds = torch.randn(10, 5).softmax(dim=-1) target = torch.randint(5, (10,)) acc = metric(preds, target) # 单次计算，并记录本次信息。通过维护tp, tn, fp, fn来记录所有数据 print(f\"Accuracy on batch {i}: {acc}\") acc_avg = metric.compute() print(f\"Accuracy on all data: {acc_avg}\") tp, tn, fp, fn = metric.tp, metric.tn, metric.fp, metric.fn print(tp, tn, fp, fn, sum([tp, tn, fp, fn])) metric.reset() Accuracy on batch 0: 0.30000001192092896 Accuracy on batch 1: 0.10000000149011612 Accuracy on batch 2: 0.20000000298023224 Accuracy on all data: 0.20000000298023224 tensor(6) tensor(96) tensor(24) tensor(24) tensor(150) torchmetrics的使用可以分以下三步： ​ 1.创建指标评价器 ​ 2.迭代中进行\"update\"或forward，update和forward均可记录每次数据信息 ​ 3.计算所有数据指标 TorchMetrics代码结构 这里提到forward，正是第四章中nn.Module的forward。 TorchMetrics所有指标均继承了nn.Module，因此可以看到这样的用法。 acc = metric(preds, target) 下面进入 torchmetrics\\classification\\accuracy.py 中观察 Accuracy到底是什么。 可以看到Accuracy类只有3个函数，分别是__init__, update, compute，其作用就如上文所述。 再看继承关系，Accuracy --> StatScores --> Metric --> nn.Module + ABC。 Metric类正如文档所说“The base Metric class is an abstract base class that are used as the building block for all other Module metrics.”，是torchmetrics所有类的基类，它实现forward函数，因此才有像这样的调用： acc = metric(preds, target) Accuracy 更新逻辑 torchmetrics的使用与上一节课中的AverageMeter+Accuracy函数类似，不过在数据更新维护方面略有不同，并且torchmetrics还有点难理解。 AverageMeter+Accuracy时，是通过self.val, self.sum, self.count, self.avg进行维护。 在torchmetrics.Accuracy中，并没有这些属性，而是通过tp, tn, fp, fn进行维护。 但是有个问题来了，请仔细观察代码，iteration循环是3次，每一次batch的数量是10，按道理tp+tn+fp+fn= 30，总共30个样本，为什么会是150？ 因为，这是多类别分类的统计，不是二分类。因此需要为每一个类，单独计算tp, tn, fp, fn。又因为有5个类别，因此是30*5=150。 关于多类别的tp, tn, fp, fn，可参考stackoverflow 还有个好例子，请看混淆矩阵： 真实\\预测 0 1 2 0 2 0 0 1 1 0 1 2 0 2 0 对于类别0的 FP=1 TP=2 FN=0 TN=3 对于类别1的 FP=2 TP=0 FN=2 TN=2 对于类别2的 FP=1 TP=0 FN=2 TN=3 自定义metrics 了解了Accuracy使用逻辑，就可以触类旁通，使用其它80多个Metrics。 但总有不满足业务需求的时候，这时候就需要自定义metrics。 自定义metrics非常简单，它就像自定义Module一样，提供必备的函数即可。 自定义metrics只需要继承Metric，然后实现以下三个函数即可： init(): Each state variable should be called using self.add_state(...). update(): Any code needed to update the state given any inputs to the metric. compute(): Computes a final value from the state of the metric. 举例： class MyAccuracy(Metric): full_state_update: bool = False def __init__(self): super().__init__() self.add_state(\"correct\", default=torch.tensor(0), dist_reduce_fx=\"sum\") self.add_state(\"total\", default=torch.tensor(0), dist_reduce_fx=\"sum\") def update(self, preds: torch.Tensor, target: torch.Tensor): batch_size = target.size(0) _, pred = preds.topk(1, 1, True, True) pred = pred.t() correct = pred.eq(target.reshape(1, -1).expand_as(pred)) self.correct += torch.sum(correct) self.total += batch_size def compute(self): return self.correct.float() / self.total 这里需要注意的是： 在init函数中需要通过add_state进行属性初始化； 在update中需要处理接收的数据，并可自定义管理机制，如这里采用correct与total来管理总的数据 在compute中需清晰知道返回的是总数据的Accuracy 小结 torchmetrics是一个简单易用的指标评估库，里面提供了80多种指标，建议采用torchmetrics进行指标评估，避免重复造轮子。 下面请看支持的指标： Auido 任务指标 Perceptual Evaluation of Speech Quality (PESQ) Permutation Invariant Training (PIT) Scale-Invariant Signal-to-Distortion Ratio (SI-SDR) Scale-Invariant Signal-to-Noise Ratio (SI-SNR) Short-Time Objective Intelligibility (STOI) Signal to Distortion Ratio (SDR) Signal-to-Noise Ratio (SNR) 分类 任务指标 Accuracy AUC AUROC Average Precision Binned Average Precision Binned Precision Recall Curve Binned Recall At Fixed Precision Calibration Error Cohen Kappa Confusion Matrix Coverage Error Dice Score F1 Score FBeta Score Hamming Distance Hinge Loss Jaccard Index KL Divergence Label Ranking Average Precision Label Ranking Loss Matthews Corr. Coef. Precision Precision Recall Precision Recall Curve Recall ROC Specificity Stat Scores 图像 任务指标 Error Relative Global Dim. Synthesis (ERGAS) Frechet Inception Distance (FID) Image Gradients Inception Score Kernel Inception Distance Learned Perceptual Image Patch Similarity (LPIPS) Multi-Scale SSIM Peak Signal-to-Noise Ratio (PSNR) Spectral Angle Mapper Spectral Distortion Index Structural Similarity Index Measure (SSIM) Universal Image Quality Index 检测 任务指标 Mean-Average-Precision (mAP) Pairwise 任务指标 Cosine Similarity Euclidean Distance Linear Similarity Manhattan Distance Regression 任务指标 Cosine Similarity Explained Variance Mean Absolute Error (MAE) Mean Absolute Percentage Error (MAPE) Mean Squared Error (MSE) Mean Squared Log Error (MSLE) Pearson Corr. Coef. R2 Score Spearman Corr. Coef. Symmetric Mean Absolute Percentage Error (SMAPE) Tweedie Deviance Score Weighted MAPE Retrieval 任务指标 Retrieval Fall-Out Retrieval Hit Rate Retrieval Mean Average Precision (MAP) Retrieval Mean Reciprocal Rank (MRR) Retrieval Normalized DCG Retrieval Precision Retrieval R-Precision Retrieval Recall Text 任务指标 BERT Score BLEU Score Char Error Rate ChrF Score Extended Edit Distance Match Error Rate ROUGE Score Sacre BLEU Score SQuAD Translation Edit Rate (TER) Word Error Rate Word Info. LostWord Info. Preserved Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-7/7.6-albumentations.html":{"url":"chapter-7/7.6-albumentations.html","title":"7.6 Albumentations 数据增强库","keywords":"","body":"7.6 albumentations 数据增强库 本节介绍albumentations库，albumentations是强大的数据增强库，原计划在第三章中进行介绍，后因篇幅过大，放到了本章作为进阶技巧。 为什么要用albumentations？ pytorch的transforms有什么不足么？ 当然有不足了， pytorch的transforms在处理图像分割与目标检测这一类需要图像与标签同时变换的时候不方便，而albumentations提供了图像分割、目标检测等复杂任务的数据增强方法。 为什么要用albumentations？ 从github中译过来： 支持多种任务：支持分类、语义分割、实例分割、目标检测和姿态估计等； 提供简洁的API：针对分割、边界框回归、关键点任务及多种数据形态（RBG-images, grayscale images, multispectral images）均可采用统一的函数完成数据增强。 数据增强方法多：提供超70种变换方法。 速度快效率高：相比其它常见数据增强库，多数方法速度都为最优 支持主流框架：albumentations已是pytorch生态系统的一员，可很好适配pytorch，同时支持TensorFlow中使用。 专家背书：albumentations的作者大多数来自工业界大牛 市场验证：albumentations已经被广泛应用于工业界和学术界，以及各种竞赛，并且获得了优异成绩。 albumentations有那么多优点，还不赶快来学习它。 安装 pip install -U albumentations 上手demo demo代码请查看配套代码，通过代码可以看到，使用步骤有： 定义一个Compose，内部包括多个变换方法（同transforms一样） 将compose放到dataset中，在getitem函数中实现调用 getitem中注意各变换方法的输入，由于albumentations支持多种数据同时处理，因此输入时需要指定变量。如image、mask、bboxes和keypoints之类。 经过Compose返回的数据是一个字典形式，需要根据key获取对应信息，如image、mask、bboxes和keypoints。 可以任意调整以下变换方法，以及参数设置，观察图像变化。 train_transform = A.Compose( [ A.Resize(512, 512), A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=55, p=0.5), ] ) 图像-标签对的数据增强 图像分割、目标检测和关键点任务中的数据增强，需要同时对图像和标签一起变换，这也是albumentations与pytorch的transforms最大的区别。 请运行代码观察结果，这里介绍使用步骤 dataset的getitem中将image与mask同时传入self.transfoms()中； 在DataLoader返回的数据中，采用key-value的形式获取image与mask/bboes/keypoints； data_augmented = data_transform(image=image_rgb, mask=mask) albumentations 代码结构 albumentations采用BasicTransform作为基类，再根据是否需要对标签进行变换，划分为nlyTransform 和 DualTransform 顾名思义，ImageOnlyTransform就是仅针对原图进行操作，DualTransform就是同时对原图和标签进行操作。 两种类型的变换常见的方如下： ImageOnlyTransform： Blur，RGBShift，RandomBrightnessContrast等 DualTransform： Resize, Flip， Crop， Rotate，ElasticTransform等 为了分析albumentations代码结构，特地绘制了一副简略版的UML类图，再结合Resize与Blur的函数，分析albumentations代码运行结构。 在代码中通过Resize类的调试，可看到实现图像模糊的功能在apply()函数中，接下来就需要理清代码结构，寻找BasicTransform是如何调用apply()的。 通过代码单步调试，发现依次进行以下步骤： BasicTransform的__call__()：在89行，return时调用self.apply_with_params(params, **kwargs) BasicTransform的self.apply_with_params()：在100行，通过target_function = self._get_target_function(key)获得具体需要变换的函数 BasicTransform的self._get_target_function()：在123行，通过self.targets.get()获得具体的target_function DualTransform的targets：是一个字典，其中定义了key与具体变换函数的映射，其中self.apply即上文提到的Resize类下的self.apply。 到这里一个具体的变换实现过程才算走完，其中BasicTransform定义了基础逻辑，例如概率选择、参数获取等，DualTransform则是定义mask,masks，bboxes，keypoints的变换函数接口，最终的实现由Resize类来完成。同理，ImageOnlyTransform 一样。 @property def targets(self): return { \"image\": self.apply, \"mask\": self.apply_to_mask, \"masks\": self.apply_to_masks, \"bboxes\": self.apply_to_bboxes, \"keypoints\": self.apply_to_keypoints, } 小结 本节介绍了albumentations的优点，基本使用以及代码结构，关于albumentations的70多种方法请查看附录，或者阅读文档查看API，使用方法非常简单，也可到代码中查看编写的批量数据增强代码段，实现了68个数据增强可视化 附录 albumentations提供70多种API，这里将不再一一介绍各API的参数，请查看文档即可。 整体分为两种，Pixel-Level和Spatial-Level： AdvancedBlur Blur CLAHE ChannelDropout ChannelShuffle ColorJitter Downscale Emboss Equalize FDA FancyPCA FromFloat GaussNoise GaussianBlur GlassBlur HistogramMatching HueSaturationValue ISONoise ImageCompression InvertImg MedianBlur MotionBlur MultiplicativeNoise Normalize PixelDistributionAdaptation Posterize RGBShift RandomBrightnessContrast RandomFog RandomGamma RandomRain RandomShadow RandomSnow RandomSunFlare RandomToneCurve RingingOvershoot Sharpen Solarize Superpixels TemplateTransform ToFloat ToGray ToSepia UnsharpMask Transform Image Masks BBoxes Keypoints Affine ✓ ✓ ✓ ✓ CenterCrop ✓ ✓ ✓ ✓ CoarseDropout ✓ ✓ ✓ Crop ✓ ✓ ✓ ✓ CropAndPad ✓ ✓ ✓ ✓ CropNonEmptyMaskIfExists ✓ ✓ ✓ ✓ ElasticTransform ✓ ✓ Flip ✓ ✓ ✓ ✓ GridDistortion ✓ ✓ GridDropout ✓ ✓ HorizontalFlip ✓ ✓ ✓ ✓ Lambda ✓ ✓ ✓ ✓ LongestMaxSize ✓ ✓ ✓ ✓ MaskDropout ✓ ✓ NoOp ✓ ✓ ✓ ✓ OpticalDistortion ✓ ✓ PadIfNeeded ✓ ✓ ✓ ✓ Perspective ✓ ✓ ✓ ✓ PiecewiseAffine ✓ ✓ ✓ ✓ PixelDropout ✓ ✓ ✓ ✓ RandomCrop ✓ ✓ ✓ ✓ RandomCropNearBBox ✓ ✓ ✓ ✓ RandomGridShuffle ✓ ✓ ✓ RandomResizedCrop ✓ ✓ ✓ ✓ RandomRotate90 ✓ ✓ ✓ ✓ RandomScale ✓ ✓ ✓ ✓ RandomSizedBBoxSafeCrop ✓ ✓ ✓ RandomSizedCrop ✓ ✓ ✓ ✓ Resize ✓ ✓ ✓ ✓ Rotate ✓ ✓ ✓ ✓ SafeRotate ✓ ✓ ✓ ✓ ShiftScaleRotate ✓ ✓ ✓ ✓ SmallestMaxSize ✓ ✓ ✓ ✓ Transpose ✓ ✓ ✓ ✓ VerticalFlip ✓ ✓ ✓ ✓ Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-7/7.7-torchensemble.html":{"url":"chapter-7/7.7-torchensemble.html","title":"7.7 TorchEnsemble 模型集成库","keywords":"","body":"7.7 TorchEnsemble 模型集成库 俗话说，三个臭皮匠顶个诸葛亮，机器学习模型亦是如此。Model Ensemble（模型集成）是机器学习领域重要的研究方向，在传统机器学习以及各种数据科学竞赛中，Model Ensemble成了标配， 因此，本节就介绍工业生产中实用的模型集成技术。 pytorch的生态系统中已经有ensemble的库，本节将介绍torchensemble的使用，各种集成方法的逻辑，torchensemble的代码结构以及如何改造自己的代码。 ensemble-pytorch 简介 TorchEnsemble是pytorch生态的一员，提供了统一的集成模块供pytorch使用。目前支持的方法有 Fusion Mixed fusion.py Classification / Regression Voting[1] Parallel voting.py Classification / Regression Neural Forest Parallel voting.py Classification / Regression Bagging[2] Parallel bagging.py Classification / Regression Gradient Boosting[3] Sequential gradient_boosting.py Classification / Regression Snapshot Ensemble[4] Sequential snapshot_ensemble.py Classification / Regression Adversarial Training[5] Parallel adversarial_training.py Classification / Regression Fast Geometric Ensemble[6] Sequential fast_geometric.py Classification / Regression Soft Gradient Boosting[7] Parallel soft_gradient_boosting.py Classification / Regression 各方法的理论简介可查阅文档 （关于模型集成的理论概念，请自行通过机器学习基础了解） 原理分析介绍 torchensemble提供了训练示例,本节对示例进行了整理及注释，可参见配套代码。 通过代码段可知道，torchensemble提供了集成类，集成类中的基学习器都是同一个结构（如LeNet-5），然后通过集成类的fit()函数完成训练，通过evaluate()来评估。 本部分最核心的问题在于理解不同的集成方法，它是如何使用多个基学习器的输出结果，下面通过源代码中的forward函数观察不同方法的集成方式。 fusion 原理：先平均，后概率。 通过FusionClassifier类的 forward函数可看到，它是对基学习器的输出进行逐元素的平均，然后再进行softmax进行输出分类概率向量。 class FusionClassifier(BaseClassifier): def _forward(self, *x): \"\"\" Implementation on the internal data forwarding in FusionClassifier. \"\"\" # Average outputs = [estimator(*x) for estimator in self.estimators_] output = op.average(outputs) return output @torchensemble_model_doc( \"\"\"Implementation on the data forwarding in FusionClassifier.\"\"\", \"classifier_forward\", ) def forward(self, *x): output = self._forward(*x) proba = F.softmax(output, dim=1) return proba voting voting：先概率，后平均。 voting先对基学习器进行softmax，然后把多个概率向量进行平均。 关于投票法，在sklearn中还有多种选择，vote模式有soft与hard，在torchensemble采用的是soft方式，及返回的是各分类器分类概率的平均。 If voting='soft' and flatten_transform=True: returns ndarray of shape (n_samples, n_classifiers * n_classes), being class probabilities calculated by each classifier. If voting='soft' and `flatten_transform=False: ndarray of shape (n_classifiers, n_samples, n_classes) If voting='hard': ndarray of shape (n_samples, n_classifiers), being class labels predicted by each classifier. class VotingClassifier(BaseClassifier): @torchensemble_model_doc( \"\"\"Implementation on the data forwarding in VotingClassifier.\"\"\", \"classifier_forward\", ) def forward(self, *x): # Average over class distributions from all base estimators. outputs = [ F.softmax(estimator(*x), dim=1) for estimator in self.estimators_ ] proba = op.average(outputs) return proba bagging bagging：先概率，后平均。这与voting一样。 bagging的主要原理在于基模型的训练数据不一样，因此可得到不同的基模型，而torchensemble文档里提到，深度学习中数据越多，模型越好，因此就没有采用K-Flod的方法划分数据了。 \"bagging further uses sampling with replacement on each batch of data. Notice that sub-sampling is not typically used when training neural networks, because the neural networks typically achieve better performance with more training data.\" class BaggingClassifier(BaseClassifier): @torchensemble_model_doc( \"\"\"Implementation on the data forwarding in BaggingClassifier.\"\"\", \"classifier_forward\", ) def forward(self, *x): # Average over class distributions from all base estimators. outputs = [F.softmax(estimator(*x), dim=1) for estimator in self.estimators_] proba = op.average(outputs) return proba GradientBoostingClassifier GradientBoostingClassifier：先求和，再概率。 这里先求和是因为Gradient Boosting算法原理就是“加法模型”，最终的结果是利用N个学习器的结果之和得到。为什么呢？因为第二个学习器学习的是第一个学习器与目标检测的差距，第三个学习器学习的是第一个+第二个学习器结果之和与结果之间的差距，以此类推。因此才有了sum_with_multiplicative这个函数中的代码逻辑。 如果不了解集成学习的基础概念，是无法理解上面这段话的，因为上面这段话是对梯度提升（GradientBoosting）算法的简述，而梯度提升（GradientBoosting）算法相对于bagging方法而言，不是那么容易理解，还请自行补足机器学习基础概念。 def forward(self, *x): output = [estimator(*x) for estimator in self.estimators_] output = op.sum_with_multiplicative(output, self.shrinkage_rate) proba = F.softmax(output, dim=1) return proba def sum_with_multiplicative(outputs, factor): \"\"\" Compuate the summation on a list of tensors, and the result is multiplied by a multiplicative factor. \"\"\" return factor * sum(outputs) SnapshotEnsembleClassifier SnapshotEnsembleClassifier：先平均，后概率。 SnapshotEnsembleClassifier是深度学习模型提出后才发明的集成方法，这与深度学习模型训练过程有关。其思路是保存多个局部最后的模型，然后将它们的结果进行集成输出。 这个思路非常新奇，集成学习的核心点之一是如何寻找多个基学习器，通常方法是从数据、参数、模型类型出发，获得多个性能不同的基学习器。而SnapShotEnsemble是通过一次训练过程中，保存多个局部最优的状态为基学习器，这样做的好处是高效，且各基学习器的错误样本通常不会重复，因此模型是基于上一次错误样本进行训练的。 [Huang Gao, Sharon Yixuan Li, Geoff Pleisset, et al., “Snapshot Ensembles: Train 1, Get M for Free.” ICLR, 2017.] def _forward(self, *x): \"\"\" Implementation on the internal data forwarding in snapshot ensemble. \"\"\" # Average results = [estimator(*x) for estimator in self.estimators_] output = op.average(results) return output Average results = [estimator(*x) for estimator in self.estimators_] output = op.average(results) 更多方法请关注官方文档的介绍。 官方demo提供了一些对比实验，这里进行汇总，供参考 代码结构 torchensemble库将模型训练、推理、集成过程都进行了高度封装，并且提供统一的接口，如何将复杂的、多种多样的模型编写为统一的API接口？ 这里就绘制简略版的UML类图，梳理代码结构。 通过类图，可以看到所有的继承类都是nn.Module类，由此可见第四章的nn.Module有多重要。 从代码结构可以学习了解到，一个复杂的模块都可以提炼、抽象出最基础的BaseClass，BaseClass中定义最核心的、最通用的属性和方法，如这里的基学习器、基学习器数量、学习器容器，forward(), fit(), predict()等。 手动实现模型集成 虽然torchensemble提供了丰富的集成方法，但是有的时候并不适用于手动训练的多个模型，下面记录两个手动实现模型集成（投票法）的代码方案。 一、借助nn.ModuleList() class Ensemble(nn.Module): def __init__(self, device): super(Ensemble,self).__init__() # you should use nn.ModuleList. Optimizer doesn't detect python list as parameters self.models = nn.ModuleList(models) def forward(self, x): # it is super simple. just forward num_ models and concat it. output = torch.zeros([x.size(0), len(training.classes)]).to(device) for model in self.models: output += model(x) return output 原文链接：https://www.kaggle.com/code/georgiisirotenko/pytorch-fruits-transferlearing-ensemble-test99-18/notebook 二、借助list，并Counter for img, label in tqdm(testloader): img, label = img.to(device), label.to(device) for i, mlp in enumerate(mlps): mlp.eval() out = mlp(img) _, prediction = torch.max(out, 1) # 按行取最大值 pre_num = prediction.cpu().numpy() mlps_correct[i] += (pre_num == label.cpu().numpy()).sum() pre.append(pre_num) arr = np.array(pre) pre.clear() result = [Counter(arr[:, i]).most_common(1)[0][0] for i in range(BATCHSIZE)] vote_correct += (result == label.cpu().numpy()).sum() print(\"epoch:\" + str(ep) + \"集成模型的正确率\" + str(vote_correct / valid_data_size)) 原文链接：https://blog.csdn.net/weixin_42237113/article/details/108970920 ResNet在Cifar-10上的实验效果 为了观察模型融合的效果，特地编写了代码，实现ResNet在Cifar10上的训练，并对每个基学习器的性能进行对比，直观的看出模型集成的作用是立竿见影的，请看效果图。 本实验采用3个学习器进行投票式集成，因此绘制了7条曲线，其中各学习器在训练和验证各有2条曲线，集成模型的结果通过 valid_acc输出（蓝色），通过上图可发现，集成模型与三个基学习器相比，分类准确率都能提高3个多百分点左右，是非常高的提升了。 为了能绘制出这幅图，特地构思了代码，代码主要是自定义了class MyEnsemble(VotingClassifier)，并重写fit函数，使得训练过程的信息可以被记录下来。 小结 本节简单介绍了pytorch中使用模型集成的方法库——torchensemble，详细内容还请查看官方文档，同时可以关注kaggle的方案，集成学习是竞赛的必备方案，也是工业项目中常用的方法，请重点学习。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-8/":{"url":"chapter-8/","title":"第八章 图像项目案例","keywords":"","body":"第八章 图像项目案例 第八章 图像项目案例 8.1 图像分类——胸部X光肺炎分类 8.2 图像分割——脑MRI胶质瘤分割 8.3 目标检测——无人机检测 8.4 目标跟踪（上）——DeepSORT原理 8.4 目标跟踪（下）——虎门大桥车流量统计 8.5 生成对抗网络——CycleGAN 第八章简介 本章介绍图像领域的相关案例，包括图像分类、图像分割、目标检测、目标跟踪、GAN、扩散模型等相关任务，这里将以一个完整的项目为一节，代码也将是独立的，希望通过一个个完整的案例，梳理在实际任务中所涉及的各个知识点、环节。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-8/8.1-classification.html":{"url":"chapter-8/8.1-classification.html","title":"8.1 图像分类——胸部X光肺炎分类","keywords":"","body":"8.1 图像分类案例——胸部X光肺炎分类 前言 前言：时隔7个月，终于能有时间继续撰写本书，在这期间，生活发生了重大变化、工作内容与岗位也有不小调整，整理而言还是未来可期，接下来一段时间将开始撰写中篇，案例应用。 本案例以胸部X光片二分类任务为案例，完整的介绍图像分类任务的训练过程。其中，涉及的知识点有： 图片的读取与dataset的编写 数据增强策略消融实验：手动设置数据增强，AutoAug实验 基于torchvision的预训练模型使用与替换：调用resnet、convnext模型 完整的训练日志分析 模型推理代码及推理速度、吞吐量计算对比 案例的讲解不再拘泥于代码细节，而是从任务分解出发，将该案例任务划分为多个模块，并对每个模块涉及的知识点及核心代码进行讲解。 图像分类的主代码采用第七章第四节中的训练脚本实现。 数据模块 首先来看数据部分，数据通过mendeley下载，得到的是ChestXRay2017.zip压缩包，图片已经划分好训练集与验证集。 获取数据后，需要对数据基础情况进行了解，首先看目录组织形式，便于dataset的编写，目录组织形式如下： ├─test │ ├─NORMAL │ └─PNEUMONIA └─train ​ ├─NORMAL ​ └─PNEUMONIA 数据为jpeg格式，类型为灰度图像，长宽在600-1000像素左右。 接下来即可编写dataset，这里仍旧需要dataset的基础知识，可以快速回顾第三章 PyTorch 数据模块。 dataset配套代码。 数据加载完成后，需要做数据增强，这里可以手动根据任务背景知识进行手动设计，或者使用AutoAug中的数据增强策略。 手动设计 对于手动设计，这里给出了基于torchvision的案例与albumentations的案例，分别位于train_main.py与train_aug.py 这里要重点介绍的是albumentations的使用，需要注意的是数据normalize与totensor的地方有些不同，详情看 A.Normalize(normMean, normStd, max_pixel_value=255.), # mean, std， 基于0-1，像素值要求0-255，并通过max_pixel_value=255，来实现整体数据变换为0-1 ToTensorV2(), # 仅数据转换，不会除以255 对于pytorch，totensor是会除以255的，而albumentations是在normalize中实现除以255的操作。 AutoAug 一些任务可以套用AutoAug的策略，关于自动数据增强可以回顾第三章，在代码实现时候也需要注意将变换后的数据进行衔接，这里主要是把数据的size变换到模型接收的大小。从代码上看，autoaug可以理解为一个打包好的transform.compose，插入自定义的compose中即可。 auto_aug_list = torchvision.transforms.AutoAugment(transforms.AutoAugmentPolicy.IMAGENET) train_transform = transforms.Compose([ auto_aug_list, transforms.Resize(256), transforms.RandomCrop(input_size, padding=4), transforms.ToTensor(), transforms.Normalize(normMean, normStd), ]) 模型模块 关于模型的创建就很简单了，基于CNN的模型，可以通过torchvision直接创建，并且加载imagenet的预训练参数。 主要注意如何修改模型最后的FC层，来适应自定义任务的分类类别数。 对于提供的模型（如resnet, convnext），需要加载进来之后，debug形式的去观察模型的结构，看看最后一个FC层的定义是什么，然后针对性的修改。 例如：resnet50的是model.fc， convnext的是model.classifier[2]，这里就需要大家对第四章module的概念有较深入的理解。 训练指令 resnet50 nohup python train_aug.py --data-path ./data/chest_xray --batch-size 64 --workers 16 --lr 0.01 --lr-step-size 20 --epochs 50 --model resnet50 > ./log.log 2>&1 & nohup python train_main.py --data-path ./data/chest_xray --batch-size 64--workers 16 --lr 0.01 --lr-step-size 20 --epochs 50 --model resnet50 > ./log.log 2>&1 & nohup python train_aug.py --data-path ./data/chest_xray --batch-size 64 --workers 16 --lr 0.01 --lr-step-size 20 --epochs 50 --model resnet50 --autoaug > ./log.log 2>&1 & convnext nohup python train_aug.py --data-path ./data/chest_xray --batch-size 32 --workers 16 --lr 0.01 --lr-step-size 20 --epochs 50 --print-freq 20 --model convnext > ./log.log 2>&1 & nohup python train_main.py --data-path ./data/chest_xray --batch-size 32 --workers 16 --lr 0.01 --lr-step-size 20 --epochs 50 --print-freq 20 --model convnext > ./log.log 2>&1 & convnext-tiny nohup python train_aug.py --data-path ./data/chest_xray --batch-size 32 --workers 16 --lr 0.01 --lr-step-size 20 --epochs 50 --print-freq 20 --model convnext-tiny > ./log.log 2>&1 & nohup python train_main.py --data-path ./data/chest_xray --batch-size 64 --workers 16 --lr 0.01 --lr-step-size 20 --epochs 50 --print-freq 20 --model convnext-tiny > ./log.log 2>&1 & 训练实验记录 其它模块代码都是先前脚本中有的，就不再赘述，在本案例中，做了一些对比实验。 对比实验一：resnet50与convnext-base/tiny的比较 对比实验二：手动设计数据增强与AutoAug数据增强的比较 结论一：简单场景下，resnet50适用性更好；convnext-base与convnext-tiny在本任务差别不大； 结论二：AutoAug数据增强方法稍差些，非自然图像场景，手动设计数据增强策略效果更好； 模型名称 日志文件夹 acc convnext-tiny 2023-02-09_09-50-07 92.5 convnext-base 2023-02-08_20-28-44 92.3 resnet50 2023-02-08_16-37-24 93.8 resnet50 + albumentation 2023-02-08_17-45-29 94.87 resnet50 + autoaug 2023-02-09_13-45-08 93.3 模型推理与时间测试 模型训练好之后是以将模型的权重参数存储为字典形式，放在了pt文件中，在未来使用时候需要创建模型（nn.module），然后把参数加载进去，同时需要注意在推理阶段的数据前处理。 在配套代码中，实现了一张图片的推理，同时对resnet50的推理速度进行了评估，推理速度效率如下： 设备 推理速度（bs=128） 吞吐量（bs=128） GTX 1080 Ti 5.23 ms/例0.67s ÷ 128 = 5.23 ms 191 帧 / 秒 1 ÷ 5.23 * 1000 = 191 RTX 3060 Laptop 2.18 ms/例0.28s ÷ 128 = 2.18 ms 459 帧 / 秒 1 ÷ 2.18 * 1000 = 459 Inte i7-11800H @ 2.30GHz 八核 41.2 ms/例 5.27s ÷ 128 = 41.2 ms 24.3 帧 / 秒1 ÷ 41.2 * 1000 = 24.3 i7-7700 @ 3.60GHz 101.8 ms/例 13.03s ÷ 128 = 101.8 ms 9.8 帧 / 秒1 ÷ 101.8 * 1000 = 9.8 综合来看，一般的cpu可以实现实时推理，gpu推理速度是cpu的10-50倍。 PS：本次推理时间测试并不充分，不可代表实际生产下的推理效率，因此需要额外注意几个点： 时间测算需考虑数据前处理、后处理时间； 数据组batch后，可充分利用gpu资源，单位时间内推理的图片数更多，但也需要考虑组batch的时间消耗 小结 本小节通过胸部X光片的二分类场景，详细描述了从数据集读取、数据增强策略、模型finetune修改、实验对比、模型推理的各个步骤，包含代码与理论介绍。 通过本小节，应能独立实现图像分类任务。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-8/8.2-segmentation.html":{"url":"chapter-8/8.2-segmentation.html","title":"8.2 图像分割——脑MRI胶质瘤分割","keywords":"","body":"8.2 图像分割案例——脑MRI胶质瘤分割 前言 本案例以脑部MRI肿瘤数据为例，介绍图像分割（本节特指语义分割）的训练、推理过程。其中，涉及的知识点有： 基于csv的数据集维护管理，及其dataset编写； smp库的介绍与使用：segmentation_models_pytorch库，是语义分割的高级API库，提供9种分割架构、数百个encoder的backbone及预训练权重，以及分割的loss和衡量指标计算函数，是语义分割的好帮手，使用它可以快速实现各语义分割功能； 对smp中9中网络架构对比实验，网络架构分别是：'Unet', 'UnetPlusPlus', 'MAnet', 'Linknet', 'FPN', 'PSPNet', 'DeepLabV3', 'DeepLabV3Plus', 'PAN'; 语义分割iou计算时，image-wise与整体计算的差异，当纯阴性片时，iou统计应当采用image-wise更合理。 探究不同backbone对于语义分割的效果差异； 探究不同loss对语义分割的效果差异； 探究encoder采用较小学习率时，模型的精度变化。 本案例将从数据介绍、训练代码、smp库使用、对比实验和模型推理，五个模块进行讲解。 数据模块 数据集来自Kaggle，包含110位脑胶质瘤患者的MRI数据，总共3929张图片，其中有肿瘤区域的图片为2556张，阴性图片1373张。 下图为每个患者图片数量，以及阴、阳图片的比例汇总，从图中可知，一个MRI序列包含20-40张图片，其中出现肿瘤的图片有60%左右。（不过这里需要注意，肿瘤区域的像素点还还是远小于阴性像素点区域的） 下图为数据集示意，第一行为MRI图像，第二行为人工标注的脑胶质瘤mask。 数据集划分 首先下载数据集，解压得到kaggle_3m文件夹，然后设置数据根目录data_dir = args.data_path，运行下面代码，即可得到对应csv python 01_parse_data.py --data-path /mnt/chapter-8/data/kaggle_3m 数据集为110个文件夹形式，这里需要进行数据集划分，本案例采用csv对数据集进行维护，这里将会通过01_parse_data.py对数据集进行解析，获得以下三个csv data_info.csv：包含文件夹id、图片路径、标签路径； data_train.csv：根据文件夹id分组划分的训练集，比例为80%，有88位患者的3151张图片； data_val.csv：根据文件夹id分组划分的验证集，比例为20%， 有22位患者的778张图片； 知识点：数据划分需要按患者维度划分，不能基于图片维度随机划分，基于图片维度随机划分会使得模型存在作弊行为，导致模型在真实应用场景下效果很差。 为什么不能基于图片维度划分数据？因为这样做的话，以为患者的40张图片，有32张用于训练，另外8张用于测试，这8张与那32张是非常接近的，因为是同一个人的连续影像。这样划分的数据集是带有偏差的，理所当然的效果很好，模型不容易出现过拟合。后续的实验也证明了这一点，基于图片维度划分的精度要高出10个百分点。 Dataset编写 dataset编写就相当容易了，因为数据的路径信息已经获得，因此只需要注意数据读取进来之后，如何转换称为标签的格式即可。 这里要注意，对于语义分割，若采用的是交叉熵损失函数，Dice损失函数，它们要求标签是一个long类型数据，不需要手动转为one-hot向量，因此对于本实验，mask要变成一个[256,256]的矩阵，其中每个元素是0或者1。对应的实现代码如下： mask = cv_imread(self.df.iloc[idx, 2]) mask[mask == 255] = 1 # 转换为0, 1 二分类标签 mask.long() 训练代码 训练代码整体结构仍旧沿用第七章第四节中的训练脚本实现。 在此处需要做的修改主要是，语义分割模型的创建、分割模型的Loss创建、分割模型指标评价，以下四行代码分别是对应的实现 model = smp.Unet(encoder_name=args.encoder, encoder_weights=\"imagenet\", in_channels=3, classes=1) criterion = smp.losses.DiceLoss(mode='binary') tp, fp, fn, tn = smp.metrics.get_stats(outputs.long(), labels, mode=\"binary\") iou_score = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"macro\") 可以发现，这里面无一例外都用到了smp库，下面简单介绍smp库的优点，以及使用方法。 smp库介绍 segmentation-models-pytorch是pytorch的语义分割工具库，提供9个分割框架，数百个encoder，常用的loss，指标计算函数，非常方便开发者进行语义分割开发。 这是smp库的github链接与官方文档 github: https://github.com/qubvel/segmentation_models.pytorch docs:https://smp.readthedocs.io/en/latest/ 它安装很方便，只需要pip即可， pip install segmentation-models-pytorch。 掌握pytorch基础知识的话，smp库只需要10分钟即可掌握上手，更系统应用建议配合smp库的两个案例进行学习。 下面将从模型创建、loss创建、指标计算三个部分介绍smp使用。 模型创建 语义分割模型发展至今，主要还是采用encoder-decoder的形式，通常会采用主流的CNN作为encoder，decoder部分则进行随机初始化去训练。 而encoder与decoder之间如何信息交互、以及decoder由哪些组件构成等等一系列问题，就引出了不同的语义分割架构。 在smp中，提供了9种常用的语义分割模型架构，分别是'Unet', 'UnetPlusPlus', 'MAnet', 'Linknet', 'FPN', 'PSPNet', 'DeepLabV3', 'DeepLabV3Plus', 'PAN'。 在语义分割中，除了架构、encoder，输入和输出的维度也非常重要，这关系到可接收的数据形式是什么，以及可以预测的类别有多少个。 因此，一个语义分割模型的创建，需要确定架构、选择encoder、再确定输入通道数、输出通道数。 下面介绍unet的创建 import segmentation_models_pytorch as smp model = smp.Unet( encoder_name=\"resnet34\", # choose encoder, e.g. mobilenet_v2 or efficientnet-b7 encoder_weights=\"imagenet\", # use `imagenet` pre-trained weights for encoder initialization in_channels=1, # model input channels (1 for gray-scale images, 3 for RGB, etc.) classes=3, # model output channels (number of classes in your dataset) ) 对于初学者来说，那么多模型或许是个头痛的问题，后续也进行了对比实验，采用相同的encoder（resnet-18），分别训练9个语义分割架构，观察精度变化。 从经验来说，凡是有系列的模型都是应用广泛、相对可靠的模型，例如net系列，deeplab系列，yolo系列等等。 如何用代码来实现类属性的调用，这里是一个值得学习的代码段，这里主要通过getattr()方法获取module的属性，然后对其进行实例化即可。 archs = ['Unet', 'UnetPlusPlus', 'MAnet', 'Linknet', 'FPN', 'PSPNet', 'DeepLabV3', 'DeepLabV3Plus', 'PAN'] for arch_str in archs: model_class = getattr(smp, arch_str) model = model_class(encoder_name=args.encoder, encoder_weights=\"imagenet\", in_channels=3, classes=1) 更多关于分割模型的介绍，可以参见：https://smp.readthedocs.io/en/latest/ 损失函数创建 smp提供了8个损失函数，分别是JaccardLoss、DiceLoss、TverskyLoss、FocalLoss、LovaszLoss、SoftBCEWithLogitsLoss、SoftCrossEntropyLoss、MCCLoss。具体差异参见官方文档，这里要讲讲损失函数创建时，需要设置的模式。 损失函数创建时需要设置mode，smp库提供了3种mode，分别是二分类、多分类、多标签分类。 二分类：'binary'， 用于一个类的分割（阴性不算一个类，例如本案例），对于二分类，标签需要是(N, H, W)的形式，元素为0或1，,它不需要通道维度，而模型输出是跟着pytorch走的，因此仍旧是4D张量，形状是(N, 1, H, W). 多分类：'multiclass'，多分类是更为常见的场景，例如VOC、COCO数据集，这时标签元素为0, 1, ..., C-1，类似交叉熵损失函数（可以把语义分割看成是逐像素分割），模型的输出自然是(N, C, H, W)了，因为一个像素点，需要用C维的分类概率向量来做分类。 多标签：'multilabel'，多标签语义分割指一个像素即是A类又是B类，因此它的标签需要借助C个通道来标注，对应类别设置为1，其它设置为0。所以标签形式为(N, C, H, W)，模型输出仍旧是(N, C, H, W)，多标签需要注意模型输出时就不再做softmax，而是对每个神经元做sigmoid，以此判断该类是否存在。 对于loss的选择，一般是交叉熵损失函数、Dice这两个系列，其它的可以自行选择，它就像模型架构一样，学术界有几十上百个选择，但在工程领域，仁者见仁智者见智，更多的语义分割损失函数可参考SegLoss 指标计算 语义分割可以理解为逐像素的图像分类，因此图像分类的各指标也可用于衡量分割模型，但分割与分类不同的是，它注重空间结构信息，关注集合与集合之间的关系，因此更常用的是IoU或Dice系数来评估模型。 IoU（Intersection over Union，交并比）是用来衡量两个集合重叠的情况，公式计算为：交集/并集，而dice系数（Dice similarity coefficient，又名dsc）也用于评估两个集合重叠情况，但是计算公式不一样，而且根据文章阐述, \"Dice倾向于衡量平均性能，而 IoU 倾向于衡量最坏的表现。\" 具体计算时，通常先获得tn, tp, fn, fp，然后计算指标。蓝色部分为TP(True Positives)，红色部分为FN(False Negatives)，黄色部分为(False Positives) smp工具库中也是这么做的，首先根据smp.metrics.get_stats函数，获得tp, fp, fn, tn。随后通过各指标计算函数获得相应指标， 可计算的指标有fbeta_score、f1_score、iou_score、accuracy、precision、recal1、sensitivity、specificity、balanced_accuracy、positive_predictive_value、negative_predictive_value、false_negative_rate、false_positive_rate、false_discovery_rate、false_omission_rate、positive_likelihood_ratio、negative_likelihood_ratio。 来看一段使用示例： import segmentation_models_pytorch as smp # lets assume we have multilabel prediction for 3 classes output = torch.rand([10, 3, 256, 256]) target = torch.rand([10, 3, 256, 256]).round().long() # first compute statistics for true positives, false positives, false negative and # true negative \"pixels\" tp, fp, fn, tn = smp.metrics.get_stats(output, target, mode='multilabel', threshold=0.5) # then compute metrics with required reduction (see metric docs) iou_score = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\") f1_score = smp.metrics.f1_score(tp, fp, fn, tn, reduction=\"micro\") f2_score = smp.metrics.fbeta_score(tp, fp, fn, tn, beta=2, reduction=\"micro\") accuracy = smp.metrics.accuracy(tp, fp, fn, tn, reduction=\"macro\") recall = smp.metrics.recall(tp, fp, fn, tn, reduction=\"micro-imagewise\") 在使用时，需要注意的有2个地方， 计算tp, fp, fn, tn时，模型输出要转换为类别标签，而不是概率向量。 对batch数据统计时，是否需要考虑样本不平衡问题，进行加权平均，是否需要基于图像维度进行计算后再平均。 对于问题1，get_stats函数提供了二分类、多标签时的处理方法，只需要在model下设置'binary' 或 'multiclass'之后，设置threshold即可。从此可看出需要手动进行sigmoid()； 对于问题2，较为复杂一些，smp提供了6个模式，这些在sklearn中有的，分别是，'micro' ， 'macro' ， 'weighted' ， 'micro-imagewise' ， 'macro-imagewise' ， 'weighted-imagewise'。 'micro’ 用于计算总体的指标，不对每个类别进行计算， 'macro'计算每个类别的指标，然后求和平均，不加权。 ’weighted’ 计算每个类别的指标，然后根据每类样本数，进行加权求平均 可参考（https://blog.csdn.net/qq_27668313/article/details/125570210） 对于x-imagewise，表示根据图片维度进行计算，然后将指标求取平均。 因此，可知道，前缀micro、macro、weighted是决定如何对类别进行求取平均，后缀-imagewise表示如何对图片之间进行求平均。 所以，对于binary来说，'micro' = 'macro' = 'weighted' ，并且 'micro-imagewise' = 'macro-imagewise' = 'weighted-imagewise'。 在这里重点讲一下，本案例采用的是macro来统计，因此iou比较低，如果是手写iou统计，一般会基于图片维度计算，然后再平均，也就是macro-imagewise。 本案例中，由于大量阴性图片的存在，所以若不采用-imagewise的话，阴性片虽然预测正确，但实际上是tn很大，而tn缺不计入iou计算中。若采用imagewise，阴性预测正确时，iou为1，从而可以大幅度提高iou值。 下面可以通过代码观察，对于阴性片，模型预测完全正确，tp, fp, fn值都是0的情况下，iou也是会被计算为1的。 tp, fp, fn, tn = smp.metrics.get_stats(c, b, mode=\"binary\") tp Out[12]: tensor([[0]], device='cuda:0') fp Out[13]: tensor([[0]], device='cuda:0') fn Out[14]: tensor([[0]], device='cuda:0') tn Out[15]: tensor([[65536]], device='cuda:0') smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"macro\") Out[16]: tensor(1., device='cuda:0') 对比实验 此部分实验没有进过严格微调，只用于横向比对，主要观察不同架构、不同backbone、不同学习率策略之间的差异，可以大体上观察出一定的趋势，供大家参考，以便后续选择模型。 在这里主要做了4次实验，分别是： 实验一：不同backbone的实验，猜想为越复杂的backbone，精度越高，这里采用uent-resnet18/34/50来观察。 实验二：不同网络架构之间的实验，猜想是有系列的模型，鲁棒性更高，适用性更广，如unet、deeplab系列。这里backbone均采用resnet-18，训练了九个模型。 实验三：encoder采用小10倍学习率，让decoder学习率高一些，猜想是要比相同学习率的效果更好，这里就需要与实验二中的九个模型精度对比。 实验四：根据图片随机划分与病人维度划分的差异，猜想是根据图片随机划分，精度要比病人高的，毕竟用到了极其类似的图片进行训练。 实验完整代码在github 实验一：不同backbone的差异 python 02_train_seg.py --batch-size 16 --workers 8 --lr 0.01 --epochs 100 --useplateau --model unet --encoder resnet18 python 02_train_seg.py --batch-size 16 --workers 8 --lr 0.01 --epochs 100 --useplateau --model unet --encoder resnet34 python 02_train_seg.py --batch-size 16 --workers 8 --lr 0.01 --epochs 100 --useplateau --model unet --encoder resnet50 unet-resnet18 unet-resnet34 unet-resnet50 miou 0.82 0.79 0.84 结论：可证实猜想基本正确，越复杂的backbone，精度越高。但resnet34的精度反而比resnet18要差，这个需要仔细研究，在此不做讨论。 实验二：对比不同模型架构差异 python 03_train_architecture.py --batch-size 16 --workers 4 --lr 0.01 --epochs 100 --useplateau --encoder resnet18 这里可以看到unet++和deeplabv3+精度较高，过它们的训练速度也是最慢的，侧面反映出它的模型复杂，理所应当获得最高精度。 'Unet' 'UnetPlusPlus' 'MAnet' 'Linknet' 'FPN' 'PSPNet' 'DeepLabV3' 'DeepLabV3Plus' PAN miou 0.81 0.85 0.73 0.83 0.83 0.78 0.81 0.84 0.62 实验三：encoder采用更小学习率差异 # encoder采用小10倍学习率 python 03_train_architecture.py --batch-size 16 --workers 4 --lr 0.01 --epochs 100 --useplateau --encoder resnet18 --lowlr 要想获得好的精度，往往需要各种trick来微调，对于语义分割模型中encoder部分，可以采用较小学习率，因为encoder提取的是共性的语义特征，对于decoder才需要特有的特征，因此可以对它们两个进行差异化设置学习率。为此，对encoder学习率乘以0.1，观察模型精度变化。 从实验结果来看，简单粗暴的调整大都未获得精度提升，反而都存在3-4个点的掉点，deeplabv3, MAnet， PAN缺有提升，由此可见训练的trick还是难以适应各个场景的。 综合实验二、实验三，可以观察到unet系列和deeplab系列都是比较稳定的，这也是它们一直被工业界认可、使用至今的原因，因此推荐首选Unet系列或deepalabv3+进行任务的初步验证。 'Unet' 'UnetPlusPlus' 'MAnet' 'Linknet' 'FPN' 'PSPNet' 'DeepLabV3' 'DeepLabV3Plus' PAN lowlr 0.79 0.81 0.82 0.81 0.81 0.76 0.83 0.80 0.80 base 0.81 0.85 0.73 0.83 0.83 0.78 0.81 0.84 0.62 实验四：根据图片随机划分数据集 此实验需要在01_parse_data.py 代码中的data_split()函数下修改groupby的对象，需要改为 grouped = dff.groupby('image_path') # bad method 并且将csv文件名做相应修改。 miou 细节 unet-resnet18 0.82 基于patient维度划分 unet-resent18 0.88 基于imgs维度划分 很明显，基于imgs维度划分存在很明显的性能提升，约6个点，但是这个提升是假性的，会迷惑工程师，误以为模型很好。 这是实际业务场景中常碰到的问题，一定要注意业务数据的维度划分问题。 模型推理 模型推理与图像分类类似，没有什么特殊的地方，在这里想重点讲一下模型输出的数据如何转换为要用的类别mask。 由于是二分类，并且输出是一通道的矩阵，因此会采用sigmoid将它变为分类概率的形式，然后再通过阈值（一般设为0.5）转换为0/1的mask矩阵。如下代码所示： outputs = model(img_tensor_batch) outputs_prob = (outputs.sigmoid() > 0.5).float() outputs_prob = outputs_prob.squeeze().cpu().numpy().astype('uint8') 接着通过opencv寻找轮廓函数可以得到边界，最后进行可视化。 最后通过imageio实现gif图的生成，可参见05-gen-gif.py。 即可得到下图 小结 通过本案例，可以掌握： 语义分割模型的训练与推理流程 smp工具库中的模型创建、损失函数创建、评价指标计算使用 评价指标中，micro、macro、weighted， x-imagewise的差别 dice与iou评价指标的定义与差异 9个语义分割架构实验比对，为后续选择模型提供参考 医学数据处理划分维度，需要基于患者维度，不可基于图片维度 基于本案例需要进一步学习的内容： 采用多类分割任务进行实验，了解softmax与sigmoid的处理差异； 进一步了解unet系列、deeplab系列适合的场景 语义分割后处理：图像处理的形态学操作 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-8/8.3-detection.html":{"url":"chapter-8/8.3-detection.html","title":"8.3 目标检测——无人机检测","keywords":"","body":"8.3 目标检测——无人机检测 前言 目标检测在工业界应用广泛，例如工业生产线上的质量检测、监控工业场景中的安全问题、机器人的自主导航等，可以提高生产效率和产品质量，降低生产成本，也可以提高工作环境的安全性，减少事故发生，由此可见目标检测意义重大。 本小节，将介绍工业界中的热宠YOLOv5，并通过无人机场景检测任务进行实现。 本小节内容丰富，包括： VisDrone数据集介绍 目标检测常见数据格式介绍：VoC, COCO， YOLO YOLOv1-YOLOv8 概述：了解YOLO发展历史，各版本模型优点，缺点 YOLOv5 源代码结构剖析及使用步骤：了解优秀的项目代码结构，设计 YOLOv5在VisDrone数据集上的多组实验，了解不同容量的YOLOv5能力 数据模块 VisDrone数据集介绍 VisDrone数据集是一个大规模的用于视觉目标检测、跟踪和计数等任务的数据集，由天津大学整理于2018年发布，论文为Vision Meets Drones: A Challenge，可通过github下载。 其中包含多个任务，这里采用VisDrone-DET数据集，进行目标检测案例学习，VisDrone-DET也就是VisDrone2018。 VisDrone-DET中，总共包含10209张，划分为了4个数据集，额外给出了一个1610张模拟的测试集-dev，训练集6471张，验证集548张，测试集-dev1610张，测试集-challenge 1580张。 数据特点：图片分辨率较大、目标小、目标存在一定程度遮挡，部分是严重遮挡（例如汽车）。 下面介绍数据集目录组织形式与标签含义。 数据包含annotations和images两个文件夹，分别存储标注信息txt文件，图片jpg文件，文件名保持一致。 标签txt文件中，一行表示一个标注框，一行有8个信息，例如 495,473,120,46,1,4,0,1 507,447,107,38,1,4,0,1 分别表示： ,,,,,,, bbox：前四个为bbox信息； score：表示标注框的置信度，取值为0或1，0表示忽略，1表示可用。 object_category： 目标类别，0-11，分别是，gnored regions(0), pedestrian(1), people(2), bicycle(3), car(4), van(5), truck(6), tricycle(7), awning-tricycle(8), bus(9), motor(10), others(11) truncation：截断程度，取值为0,1。0表示无截断，1表示目标有1%~50%的区域再当前帧(图像)之外。 occlusion：遮挡程度，0-2。0表示无遮挡，1表示1%-50%遮挡，2表示50%-100%遮挡。 对于本案例使用，仅需要剔除score=0的bbox。 目标检测数据集格式 了解数据之后，需要把数据集转换为代码可以接收的形式。与分类分割任务不同，目标检测领域的数据格式相对固定，一般不需要自己重写数据加载模块，而是跟随代码框架的要求来适配。 目标检测目前主流的有三种格式，VOC格式、COCO格式、YOLO格式，下面分别介绍。 VOC数据集格式如下： 图像位于JPEGImages文件夹。 标注文件位于Annotations文件夹中，标注文件与图像文件文件名应当相同，并且XML格式描述目标的位置和类别等信息，bbox形式为xmin、xmax、ymin、ymax。 COCO数据集格式如下： 图像位于images文件夹中。 标注文件位于annotations文件夹下的instances_train2017.json，所有标注均存储在一个json中，并通过特定字段获取图片对应的标签信息。bbox形式为xmin, ymin, w, h。 YOLO数据格式如下： 图像位于images文件夹下。 标注文件位于labels文件夹下，标注文件与图像文件文件名应当相同，并且以txt文件存储标签信息。txt中一行是一个标注框，一行的格式为： class x_center y_center width height，其中bbox的数值需要除以长/宽，使得值为0-1之间。 在这里侧面证明了YOLO模型的强大，以往算法开发要适应数据集的格式，而现在yolo系列模型被广泛使用，使得大家愿意接受YOLO数据格式。 标签数据转换代码 在目标检测任务开发过程中，无法避免数据集之间的转换，这里推荐repo，可以实现三种数据格式之间的互相转换。 在本案例中，适合自行编写脚本进行转换，这里yolov5官方也给出了代码，因此直接复用即可。 推荐yolov5中使用的几个小函数： 文件夹的创建， Path对象可直接.mkdir()，并且可设置递归及判断存在与否。 from pathlib import Path (dir / 'labels').mkdir(parents=True, exist_ok=True) # make labels directory pbar显示进度， 将可迭代对象用tqdm包一下，并且设置打印的字符串信息格式desc pbar = tqdm((dir / 'annotations').glob('*.txt'), desc=f'Converting {dir}') 使用配套代码，运行即可得到与images文件夹在同级目录下的labels文件夹 python visdrone2yolo.py --data-path /mnt/chapter-8/data/visdrone 到这里yolo格式数据集已经准备好，如何在代码中使用及配置，这部分放到模型模块中的yolo框架讲解部分。 模型模块 在数据模块，讲解了目标检测中数据集常见的格式，并且已经转换称为yolo格式，等待使用。 若是在分类或分割中，我们会手写代码进行实验，然而在目标检测，绝大多数是不需要的，原因有 目标检测中涉及多个模块，重新造轮子的时间成本高，容易出bug； 目标检测可用成熟的“框架”（可用的repo）很多，如ultralytics的yolov3/yolov5/yolov8，mmdetection，paddledetction等，感谢前人的工作！ 成熟的\"框架\"指，功能齐全，满足绝大多数场景，受众多，经得起时间的考验，可以放心使用。 在图像分割的实验中就指出，凡是有系列的，优先考虑，因此，这里选择ultralytics的yolov5，它是目前为止（2023年3月10日07:07:25）star最高的目标检测开源代码仓库，已经36K，足以证明yolov5的稳定性与可靠性。 yolo系列简介 YOLOv1 YOLOv2 YOLOv3 YOLOv4 YOLOv5 YOLOv6 YOLOv7 YOLOv8 时间 2015.6.8 2016.12.25 2018.4.8 2020.4.23 2020.6.10 2022.6.23 2022.7.7 2023.1 作者 Joseph Redmon Joseph Redmon Joseph Redmon Alexey Bochkovskiy Ultralytics 美团 Alexey Bochkovskiy Ultralytics 深度学习目标检测框架发展快10年时间，只有yolo（You Only Look Once）系列久经不衰，截至目前公认的版本已经到了v8，很难有人能将v1-v8的细节全部吃透。 在校有时间的同学十分建议从v1-v8认真学习，这样可以理解目标检测的发展，锻炼科研意识，掌握代码能力。 对于工作繁忙的工程师来说，它们只是解决问题的工具，了解工具的优点与缺点，有的放矢的应用在各个项目场景也是不错的选择。 为此，特地总结yolov1-v8的特点，为后续使用工具打下基础。 参考deephub的文章，可以看到yolo系列主流的模型发展历程。 yolov1：2015年提出的one-stage目标检测算法，与当时的Fater RCNN（two-stage）共同称为当时最受欢迎的检测模型。特点为anchor-free：没有anchor的概念，每个cell直接输出bbox。每个cell仅输出2个bbox，每个cell输出向量为（20+ (4+1)*2），20为20个类，1为bbox概率，4为bbox信息，一张图片最终变为7×7的特征图，一个cell只能预测1个类，因此定位粗糙，小目标不友好，对重叠物体检测能力差。 yolov2：针对yolov1定位不精准问题，借鉴faster rcnn的anchor-base的概念，并且引入k-means实现anchor的自动配置。 yolov3：划时代意义的目标检测算法，也奠定了目标检测之后的范式，backone+neck+多尺度。yolov3网路结构简单，并且采用多尺度特征图实现不同尺寸目标的检测，速度与精度在当时都是优于其他模型。yolov3采用的是手动配置的33=9种anchor，anchor的参数设置是通过k-means对标签进行聚类发现的，*3种尺寸，3种长宽比。 yolov4：yolov4发布前有个小插曲，那就是YOLO之父Jeseph Redmon，由于“无法忽视工作带来的负面影响”，公开宣布隐退。好在有大神接了他的大旗，在yolov3推出快2年的时间，yolov3的改进版v4终于在2020年来了，yolov4开始，可以认为是一个分割点，更准确地说yolov3是后续模型的分割点。借助paperswithcode的一个精度图，可以看到yolov3在coco的map是30-40之间，而往后v4-v8已经来到50-60的区间，已经不在一个档次。 对于yolov4，它对当时深度学习的多种tricks进行了实验，集成到yolov3上进行改进，精度和速度都得到大幅度提升。它使用了大量tricks，包括WRC、CSP、CmBN、SAT、 Mish activation、Mosaic data augmentation、CutMix、CmBN、DropBlock regularization 和 CIoU loss、GIoU loss。 yolov5：在yolov4发布后短短2个月，yolov5横空出世，并且带来了多种大小的模型, nano/s/m/l/x等尺寸，可适用于多种场景，同时配备高质量的开源代码仓库，短时间内就受到了广泛关注。yolov5数据增强上使用了Mosaic数据增强、自适应锚框计算、自适应图片缩放（推理时采用最小填充原则，加速推理）、融合新网络模块Focus、CSP结、FPN+PAN，GIOU_Loss，以及预测框筛选的DIOU_nms、 yolov6：2022年由美团提出的速度更快的检测模型，主打是速度，因此模型特点是backbone与neck的设计都为了适应硬件的运算，使用了Rep-Pan和EfficientRep块，head部分用了解耦的形式，在训练策略方面采用了anchor-free、SimOTA标记策略、SIoU盒回归的损失。 yolov7：在yolov6推出不到半个月，yolov7也发布了，yolov7团队与yolov4团队一致，属于官方YOLO团队（yolov4团队接过yolo之父Jeseph Redmon的大旗）。yolov7同样从速度方面做了许多优化，例如内存访问成本、I / O比率、element-wise、激活函数等，以及模型重参数化（re-parameterization）。 yolov8：yolov5的团队——ultralytics打造的集成图像分类、图像分割、目标检测于一体的结构，目前github地址并为采用yolov8而是采用ultralytics。发布2个多月后，论文仍旧未发布，具体优化内容请关注官方github，从代码中观察吧。 yolov5 代码结构讲解 根据广大工程师“用脚投票”的结果，本案例采用ultralytics的yolov5来实现目标检测，并学习代码中优秀的设计思想，同时剖析用户如何使用yolov5仓库代码。 后续建议跟进yolov8! 学习yolov5之前，推荐阅读yolov5的readme，其中包含了许多学习资料。 下图为yolov5(2023.03版)的代码结构，逻辑相当清晰，可分三个模块，三个模块是图像分类、图像分割和目标检测。 目标检测分为data、models、utils和运行脚本部分。 data：存放的主要是数据超参数配置yaml文件。 models：存放的是各模型的yaml配置文件，即模型创建依赖于yaml文件。 utils：存放各功能模块，如，数据增强augmentations.py， 自动计算anchor功能autoanchor.py，激活函数activations.py， fastapi接口等等。 检测模型的训练、验证、推理分别在：train.py, val.py, detect.py中。下面将重点讲解train.py的运行机制。 yolov5 训练机制讲解 train.py有600多行，并且调用了许多函数，一开始接触会感到困难。 不过不用担心，它还是pytorch框架，仍旧逃离不了基础核心模块， dataloader， module，loss， scheduler，迭代训练。 下面依次简要的说明train.py中是如何训练的。 参数配置模块 使用parse_opt()进行参数包装，训练时可指定模型、数据集配置yaml路径，超参数配置yaml路径等内容。 数据模块 man() --> train()-->create_dataloader(): 第188行，调用了create_dataloader()函数，并且传入了数据集配置yaml文件中的训练集路径。 utils/dataloders.py-->LoadImagesAndLabels(): 在函数内部采用LoadImagesAndLabels()类实现pytorch的dataset的生成，class LoadImagesAndLabels(Dataset), 代码有483行，里面实现了许多数据检测、数据加载功能，但是核心与pytorch的dataset是一致的，重点关注init中做了哪些初始化，以及getitem如何从磁盘加载图片并且做数据预处理、数据增强的即可。 模型模块 第125行实现模型创建，可以看到是通过配置信息进行创建的，这里的配置信息来自参数配置模块中--cfg或者指定预训练模型--weights， model = Model(cfg or ckpt['model'].yaml, ch=3, nc=nc, anchors=hyp.get('anchors')).to(device) # create 再看往里看 DetectionModel继承自BaseModel，BaseModel集成nn.Module，里边细节就可通过nn.Module的基础知识一步一步剖析。 迭代训练模块 核心功能在，262行 262行：主循环 for epoch in range(start_epoch, epochs): # epoch ------------------------------------------------------------------ 284行：batch循环 for i, (imgs, targets, paths, _) in pbar: # batch ------------------------------------------------------------- 310行：前向推理，计算loss，反向传播 pred = model(imgs) # forward loss, loss_items = compute_loss(pred, targets.to(device)) # loss scaled by batch_size scaler.scale(loss).backward() 344行：epoch维度变更学习率，因此在batch的循环之外 lr = [x['lr'] for x in optimizer.param_groups] # for loggers scheduler.step() 日志输出模块 在runs文件夹下会有train文件夹，每一次实验会以exp{实验次序}创建文件夹，在下面会保存训练过程中的一系列有价值内容。 如下图所示，会有这些文件 weights：训练好的模型权重，包括last.pt, best.pt hyp.yaml：训练时的超参数，便于复现 results.png：训练曲线，便于分析训练情况，调整超参数 results.csv：训练指标记录表格 train_batch2.jpg：训练数据集，bbox绘制情况，十分有用，可用于检测数据标签是否处理正确！ val_batch0_labels.jpg：验证数据集，bbox验证情况 val_batch2_pred.jpg：模型预测出的bbox在验证集上的情况。 混淆矩阵：针对标签的预测的情况进行混淆矩阵观察，这个混淆矩阵是转置了的，行是预测，列才是真实标签，以下图为例，汽车这个类别中，有78%的汽车框被预测为了汽车，有19%的汽车框没有被检测到，剩下2%的汽车框被检测出来了，但是分类时分为了van（箱式货柜车）。 PR_curve：PR曲线是各类别的AP情况 P_curve和R_curve：是观察模型对各类别分类情况，可用于挑选分类概率阈值， 横轴表示选择的阈值，纵轴是对应的值。可以看到阈值越小召回率越高，反之，精确度越低。 labels_correlogram.jpg：是借助seaborn的pairplot，绘制的多变量的二维分析相关性统计分析图。以列为基础，第一列是x与其它数据的关系，第一列，第一行，表示x的整体分布，可以看到是相对于中心点0.5对称的，表明矩形框在宽这个维度，左边有的数量与右边有的数量是一致的，并且呈现中间多，两边少的情况。 第一列，第二行，表示x与y的分布情况，同labels.jpg中第三幅图一样，观察矩形框整体情况是宽度偏中间，高度偏中间与中下部。 第一列，第三行，表示x与w的分布情况，呈现一个梯形，这个很合理，因为当x靠近图片的最左边的时候，即物体在图像的边界时，这个物体一般不会很大，否则根据拍照的基础原理，肯定会将镜头朝向主要物体，并放置在镜头中央，不至于在边界处。 第一列，第四行，表示x与h的分布情况。 第二列，第二行，是y的整体分布，可以看到是偏向0-0.5之间。 第三列，第三行，是w的整体分布。 第四列，第四行，是h的整体分布。 yolov5 训练VisDrone步骤 第一步：设置数据集配置yaml文件，首先到detection\\yolov5-master\\data\\下复制一份yaml，命名为mydrone.yaml，设置好路径即可，这里yolo数据格式只需要images路径就能通过相对路径寻找到labels。同时设置好检测类别数量与名称 path: G:\\deep_learning_data\\VisDrone # dataset root dir train: VisDrone2019-DET-train\\\\images # train images (relative to 'path') 128 images val: VisDrone2019-DET-val\\\\images # val images (relative to 'path') 128 images test: # test images (optional) nc: 10 # number of classes names: ['pedestrian', 'people', 'bicycle', 'car', 'van', 'truck', 'tricycle', 'awning-tricycle', 'bus', 'motor'] 第二步：将预训练模型下载到code/chapter-8/03_detection/yolov5-master下，下载方式为github。 第三步：在终端，运行训练指令，即可在runs/train下面看到对应日志. python train.py --imgsz 640 --batch 16 --epochs 100 --data mydrone.yaml --weights yolov5s.pt --workers 8 对比实验 实验一：visdrone数据集特点是分辨率大，一般的640,1000的尺寸无法满足要求，为此，进行了5种尺寸的训练，用于观察不同分辨率对精度的影响 实验二：yolov5提供多种尺寸的模型，这里观察s/m/l三种尺寸的模型对精度的影响。 实验三：同时观察yolov5自带的三种不同强度的数据增强带来怎样的精度变化。 更新：所有实验权重、实验文件已经上传云盘：链接：https://pan.baidu.com/s/11kQJcCka2VyR5ToF-N0BOQ 提取码：op4x 实验一/二：不同输入尺寸对模型精度的变化 python train.py --imgsz 640 --batch 24 --epochs 100 --data mydrone.yaml --weights yolov5s.pt --workers 8 --hyp data/hyps/hyp.scratch-low.yaml python train.py --imgsz 960 --batch 16 --epochs 100 --data mydrone.yaml --weights yolov5s.pt --workers 8 --hyp data/hyps/hyp.scratch-low.yaml python train.py --imgsz 1280 --batch 12 --epochs 100 --data mydrone.yaml --weights yolov5s.pt --workers 8 --hyp data/hyps/hyp.scratch-low.yaml python train.py --imgsz 1600 --batch 8 --epochs 100 --data mydrone.yaml --weights yolov5s.pt --workers 8 --hyp data/hyps/hyp.scratch-low.yaml python train.py --imgsz 1920 --batch 6 --epochs 100 --data mydrone.yaml --weights yolov5s.pt --workers 8 --hyp data/hyps/hyp.scratch-low.yaml map50/map50:95 640 960 1280 1600 1920 yolov5s 0.33/0.18 0.44/0.26 0.50/0.30 0.54/0.33 0.55/0.34 exp0-4 yolov5m 0.38/0.21 0.48/0.30 0.53/0.33 0.57/0.36 0.59/0.38 exp11-15 yolov5l 0.40/0.23 0.50/0.31 0.55/0.35 0.57/0.37 0.60/0.39 exp16-20 从上图可以看出： 随着尺寸增大，精度得到提高，且1920仍未达到瓶颈，可继续增加图片尺寸来获得精度提高。 随着模型容量增大，精度得到提高；可根据任务难以程度选择合适容量的模型。 在size和模型容量两者间可以选择更适合的方式来涨点，即size也可以涨点，换大模型也可以涨点，如果不能同时采用，则根据上下游条件进行取舍。 实验三：不同数据增强方法的变化 这里套用yolov5提供的三种强度的数据增强方法，观察精度变化。 python train.py --imgsz 960 --batch 16 --epochs 100 --data mydrone.yaml --weights yolov5s.pt --workers 8 --hyp data/hyps/hyp.scratch-low.yaml python train.py --imgsz 960 --batch 16 --epochs 100 --data mydrone.yaml --weights yolov5s.pt --workers 8 --hyp data/hyps/hyp.scratch-med.yaml python train.py --imgsz 960 --batch 16 --epochs 100 --data mydrone.yaml --weights yolov5s.pt --workers 8 --hyp data/hyps/hyp.scratch-high.yaml scratch-low scratch-med scratch-high map50/map50:95 0.44/0.26 0.44/0.26 0.43/0.26 exp5-7 从结果可知，yolov5中自带的low, med, high在本案例中效果都一样，并无差别。 模型推理 训练好模型后，可通过detect.py进行推理并观察结果，detect.py提供了多个参数接口 weights：训练好的.pt文件，.pt文件中存储了模型结构，因此无需额外指定模型结构的yaml文件 source：需要检测的数据来源，支持图片、视频、摄像头、网络视频url等 data：数据集yaml文件，关联检测的类别名称 imgsz：图像输入大小 conf-thres：检测框置信度阈值 iou-thres：非极大值抑制时的iou阈值设置 half：采用半精度(Float 16)进行推理，可提升推理速度，但有一定精度损失 其它配置参数可看代码注释，这面介绍detect.py中的核心代码结构，观察其是如何实现推理的。 第一部分，数据加载读取，对于数据的加载与读取，采用utils/dataloders.py中实现的3个类来实现包装，并进行迭代。如LoadStreams、LoadScreenshots、LoadImages，对于三个类的实例，在使用时，采用for循环进行依次取出数据 dataset = LoadStreams(source, img_size=imgsz, stride=stride, auto=pt, vid_stride=vid_stride) dataset = LoadScreenshots(source, img_size=imgsz, stride=stride, auto=pt) dataset = LoadImages(source, img_size=imgsz, stride=stride, auto=pt, vid_stride=vid_stride) for path, im, im0s, vid_cap, s in dataset: 第二部分，模型加载，使用models/common.py中的DetectMultiBackend类实现，该类支持多种计算后端如pytorch\\onnx\\tensorrt\\jit\\dnn等等。其中，pytorch模型是通过models/experimental.py中的attempt_load()函数实现加载。attempt_load()需要的一个核心参数就是.pt文件路径。然后根据.pt内信息完成模型创建、权重加载等工作。 model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=half) model = attempt_load(weights if isinstance(weights, list) else w, device=device, inplace=True, fuse=fuse) 第三部分，推理与保存，推理主要两个步骤，模型前向传播，经过NMS后得到最终输出矩形框。对于结果可视化，这里采用Annotator类实现绘制，首先将图像传入Annottor，进行实例化，后续通过annotator.box_label()进行bbox与labels的绘制。 pred = model(im, augment=augment, visualize=visualize) pred = non_max_suppression(pred, conf_thres, iou_thres, classes, agnostic_nms, max_det=max_det) # ------------------------------------------------------------------------------------------------ annotator = Annotator(im0, line_width=line_thickness, example=str(names)) annotator.box_label(xyxy, label, color=colors(c, True)) 运行以下推理指令，即可在.runs/detect/exp*下获得结果，下图为航拍视频推理示例 python detect.py --weights ./runs/train/exp2/best.pt --source G:\\DJI_0690.MP4 --data data/mydrone.yaml --imgsz 1280 --half python detect.py --weights best.pt --source G:\\DJI_0690.MP4 --data data/mydrone.yaml --imgsz 1280 到这里，yolov5代码就讲解完毕，yolov5代码库还有许多值得学习的地方，这里由于篇幅关系，作为拓展阅读推荐给大家： 模型导出为TFLite, ONNX, CoreML, TensorRT：https://github.com/ultralytics/yolov5/issues/251 TTA(test time augmentation): https://github.com/ultralytics/yolov5/issues/303 模型剪枝：https://github.com/ultralytics/yolov5/issues/304 yolov5训练技巧总结：https://github.com/ultralytics/yolov5/wiki/Tips-for-Best-Training-Results yolov5模型集成：https://github.com/ultralytics/yolov5/issues/318 小结 本案例介绍了yolov5实现无人机视角的目标检测，主要涉及以下知识点： Visdrone数据集介绍与标签含义解析，会有模糊程度与遮挡程度的两个额外标注信息。 目标检测常见数据形式：voc，coco，yolo形式，三者的bbox形式均不一样，使用时需要注意转换。xmin,ymin,xmax,ymax； xmin, ymin, w, h； x_center, y_center, w, h yolov1-v8模型简介：简要介绍v1-v8的模型特点，便于后续有的放矢的选择使用。 yolov5代码结构介绍：剖析yolov5项目代码结构，并分析如何进行训练、推理。 自定义数据集训练过程：详细介绍自己的数据集要如何使用yolov5进行训练的过程，核心在于了解yolov5的数据加载形式与模型加载形式都通过yaml文件进行管理。 对比实验：分析分辨率、模型容量、数据增强方法带来的精度变化，对后续重要超参数设置具有指导性意义。 本案例已近万字，可以快速用代码实现目标检测，但是对于目标检测的学习来说，还远不够，案例初衷还是通过具体的项目，来巩固pytorch基础知识。 最后，可以发现，即使是采用yaml来管理数据和模型，在实现的时候还会继承dataset和dataloader，以及nn.Module，由此可见第三章和第四章的概念有多么重要。 对于想要深入了解目标检测的朋友，推荐学习： 非深度学习目标检测时期的检测方法； faster rcnn + yolov3的详细理论过程与代码实现 yolov3后时代下的，anchor-free, one-stage的检测模型 特定问题目标检测：小目标检测， 旋转目标检测，密集场景目标检测，超大分辨率图像目标检测、遮挡场景目标检测等等 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-8/8.4-tracking-1.html":{"url":"chapter-8/8.4-tracking-1.html","title":"8.4 目标跟踪（上）——DeepSORT原理","keywords":"","body":"8.4 目标跟踪（上）——DeepSORT原理 前言 目标跟踪技术可以用于人流量计数和车流量计数等，能够帮助人们更好地了解和掌握一个地区的交通状况和人流状况。这些计数功能有以下几个价值和意义： 交通规划：通过了解车流量，可以更好地规划交通路线和疏导车流，提高交通效率，减少拥堵，从而减少交通事故的发生。 商业决策：通过了解人流量，可以更好地了解商业活动的热点区域，从而制定更加有效的营销策略和经营计划，提高商业效益。 目标跟踪（object tracking）定义是，在视频序列中识别目标并赋予唯一标识，同时跟踪目标在视频序列中的位置。在自动驾驶、监控、人机交互等领域都有应用。 目标跟踪常用的策略是TBD（Tracking-by-Detecton），又称DBT（Detection-Based-Tracking）。即在每一帧进行目标检测，再利用目标检测的结果来进行目标跟踪，这一步称为数据关联（Data Assoiation）。与之相对的，是DFT（Detection-Free Tracking）， DFT使用较少。 根据目标的数量，目标跟踪可分为单目标跟踪（Sing-Object Tracking）与多目标跟踪（Multi-Object Tracking），目前MOT研究较多，并且MOT可覆盖SOT。 根据处理时效性，又可分为在线跟踪（Online）与离线跟踪（Offline），离线跟踪是指可以使用后续帧的信息来预测当前帧，在视频分析中可用。在线跟踪是只能采用前序帧信息与当前帧信息，这是目前主流方案。 本案例中的目标跟踪属于多目标跟踪、在线跟踪、TBD。 通过简单定义，可以知道，目标跟踪分两步 检测：找出当前帧中的目标，即目标检测 关联匹配：将当前目标与历史帧中的目标进行关联与匹配 检测可以采用各类目标检测算法，关联匹配可以采用deepsort算法。 本案例将详细介绍DeepSORT算法原理，并基于yolov5实现车流量统计代码。 DeepSORT算法流程 DeepSORT算法发表于2017年，其是SORT的改进版。SORT(Simple Online and Realtime Tracking)于2016年发表，主要基于卡尔曼滤波和匈牙利算法实现。 DeepSORT算法则是对SORT加入了Deep Association Metric进行特征提取与匹配，是目前精度与速度都不错的跟踪算法。 SORT论文速读：提出了基于卡尔曼滤波和匈牙利算法的目标跟踪策略，同时发现好的目标检测器，可以大幅度提升MOT精度，高达18.9个百分点。SORT实现分为4个步骤，分别对应3.1-3.4，目标检测模型得到目标框；采用卡尔曼滤波进行轨迹框的预测；采用匈牙利算法对目标框与轨迹框进行匹配；最后基于匹配结果，删除旧轨迹框，添加新轨迹框。（论文只有5页，核心内容第三章仅半页纸，但不妨碍它是优秀的工作） DeepSORT论文速读：基于SORT，DeepSORT最大特点是引入了deep association metric，即采用CNN提取目标框中图像特征，来进行匹配。同时，涉及了级联匹配策略，有了更好的准入、准出机制，对目标的跟踪更精细、合理。 目标跟踪的过程相当复杂，为了能了解全过程，这里通过具体案例，一步一步发现问题，然后学习DeepSORT的解决方案，最后汇总。 为了将复杂的问题描述清楚，有必要对名词进行一些解释。 检测框（dets）：由目标检测模型输出的框，包含框的位置信息，物体类别信息，是该物体的概率信息 跟踪框（tracks）：跟踪模块认为是有价值的检测框。跟踪框中有两种，一个是正式框，一个是预备框。论文中称为confirmed, unconfirmed， 这里借鉴正式党员、预备党员的叫法，应该好理解一些。 预备框（unconfirmed）：潜在的跟踪框，只在算法内部记录，当达到一定条件，转为正式跟踪框，才能被算法输出，在屏幕上绘制出来。 正式框（confirmed）：目标跟踪算法的输出，回顾定义，目标跟踪需要在视频序列中识别目标并赋予唯一标识，即输出框应当包含检测框信息、唯一标识。 假设世界上没有目标跟踪算法，需要我们自己构思，需求是在在连续帧中将检测到的物体关联起来，实现目标跟踪。 现在有个行人跟踪任务，如图所示 第一帧：检测器只有一个检测框，因此赋予它唯一标识，再采用卡尔曼滤波算法进行跟踪框坐标的输出。 第二帧：检测器输出两个框，如何将2个检测框与1个跟踪框进行匹配，获得行人1在第二帧当中的跟踪框。这时可以借助匈牙利算法，它是求解任务分配问题的组合优化算法。 匈牙利算法可以很好的将检测框1与前序跟踪框1匹配上，然后对前序跟踪框1进行更新(采用卡尔曼滤波)，获得当前跟踪框1。 对于检测框2，没有找到与其匹配的前序跟踪框，所以认为它是新进入的，给它创建一个新跟踪框即可。因此，当前跟踪框应有两个。 第三帧：又来了一个人，检测到了3个框，因此重复第二帧的任务，采用检测框更新采用卡尔曼滤波)跟踪框的信息，同时为王五注册新的身份ID——行人3。 第四帧：张三离开了图像，检测器只检测到2个框，2个检测框去匹配3个跟踪框，自然会有一个跟踪框匹配不上，这里显然是行人1，因此没有匹配上的跟踪框需要被删除，最终输出两个跟踪框。 以此类推，新来检测框匹配已有跟踪框，匹配不上，则增加跟踪框，同理，已有跟踪框没有匹配到新的检测框，认为它离开了，需要删除跟踪框。 到这里，一个基础的目标跟踪框架出来了，有了新增跟踪框机制、删除跟踪框机制。这就是大名鼎鼎的SORT算法的流程，对于匹配细节和跟踪框的坐标更新 SORT很好的解决检测框如何与跟踪框对上号，同时有了新增、删除跟踪框机制，但是对于常见的问题没有得到很好的解决，例如： 检测器漏检：检测器在某一帧漏检是很常见的现象，假设第二帧中，张三漏检了，第二帧会将张三的身份ID——行人1给删除。第三帧中的张三将会被认为是新来的，无法匹配到他是行人1。 检测器误检：检测器在某一帧错误的将背景检测为了行人，根据SORT算法，会被背景赋予一个跟踪框，这是很不合理的。 为了让目标跟踪算法输出的跟踪框更稳定，DeepSORT引入了预备框、正式框机制，可以很好的解决漏检、误检带来的不稳定。 对于新增，要考察一下框是否是真的，通常用3帧的时间来考察，当发现框连续3帧都存在，那么认为它是一个好的框，算法批准框称为正式框。这样可以很好的过滤掉一些”没有耐心“的框。这样对于某一帧，某两帧的误检，是很好的过滤方法。 对于删除，要考察一下框是否真的离开，毕竟框也是经过了准入审查的，通常不会一瞬间就离开，此时给它连续30次机会，连续30帧里边发现它都不在了，将它永久开除。 综合上述理解，DeepSORT流程解释如下： DeepSORT核心——匹配过程 匹配过程指的是，如何将检测框与跟踪框匹配上，让每一个检测框都能找到与之对应的跟踪框。若没有找到，则认为是新进入的物体，会创建新跟踪框。 deepsort的匹配过程分两部分。 首先，基于外观特征和马氏距离，为正式框进行匹配，方法是级联匹配（matching cascade），用到的优化方法是匈牙利算法。 然后，基于bbox坐标和IoU，为预备框进行匹配，采用剩余检测框与剩余跟踪框（未匹配和预备框）匹配，用到的优化方法是匈牙利算法。 外观特征与bbox坐标对应：表示的是对于一个物体，要用什么特征表示TA，是1128的向量？还是14的向量？ 马氏距离与IoU对应：表示两个特征之间\"相近\"程度的衡量，只有衡量了两个特征之间的距离，后续才能用优化算法优化距离最短的匹配方案 匈牙利算法作用：将N个A与M个B，采用特征向量描述以及距离度量方法，可以得到N*M的距离代价矩阵，即A中每一个元素与B中每一个元素之间的距离。随后用匈牙利算法找到最优匹配。 级联匹配 级联匹配的思想是分70级进行匹配，级的概念指距离当前帧的远近，第一级（level）采用所有检测框， 和仅被记录了一次的正式框（if tracks[k].time_since_update == 1 + level），以此循环70次。 因为越新的目标，越有可能与检测框匹配上，存在太久的目标可能离开了。级联匹配可以解决一部分身份交换问题。 级联匹配中，传入了： distance_metric：基于外观特征（CNN提取出来的512维特征向量）的举例度量函数 max_distance：当距离大于max_distance时，认为是不匹配的 tracks：跟踪框 detections：检测框 track_indices_l：本轮需要匹配的跟踪框的index unmatched_detections：本轮需要匹配的检测框的index # code/chapter-8/tracking/deep_sort/deep_sort/sort/linear_assignment.py 的matching_cascade函数 for level in range(cascade_depth): if len(unmatched_detections) == 0: # No detections left break track_indices_l = [ k for k in track_indices if tracks[k].time_since_update == 1 + level # 为每个跟踪框记录它被更新的次数，优先选择新跟踪框进行匹配， 1+0 ] if len(track_indices_l) == 0: # Nothing to match at this level continue # ============================ 核心部分：匹配 ================================ matches_l, _, unmatched_detections = \\ min_cost_matching( distance_metric, max_distance, tracks, detections, track_indices_l, unmatched_detections) matches += matches_l 级联匹配中采用的是跟踪框的历史特征列表与检测框进行匹配，如跟踪框已经检测到了18次，会得到18个特征向量，新的检测框有30个，则会得到18*30的矩阵。 然后在第0维选择最小值，得到1*30的距离矩阵，最终判断是否有匹配上的检测框。 Tracker --> _match() --> gated_metric() 下的： cost_matrix = self.metric.distance(features, targets) 跳转到：deep_sort/sort/nn_matching.py 的 NearestNeighborDistanceMetric.distance() cost_matrix = np.zeros((len(targets), len(features))) for i, target in enumerate(targets): cost_matrix[i, :] = self._metric(self.samples[target], features) 跳转到： def _nn_cosine_distance(): distances = _cosine_distance(x, y) # 18*30的矩阵 return distances.min(axis=0) # 选择距离最小的特征； 如18*1，选择18个跟踪框中与第一个检测框距离最近的；以此类推得到1*30. # 由此可见，检测框与目标的所有历史特征向量进行距离计算，挑选最近那个特征的距离作为评判距离。 级联匹配之后，会有未匹配的检测框，未匹配的正式框（如果被记录70次以上，是无法进行匹配的），以及预备框。 接下来用IoU测量检测框与跟踪框之间的相似性，很好理解，IoU越大，它俩越有可能是一个物体。 IoU匹配 IoU匹配的代码位于：code/chapter-8/tracking/deep_sort/deep_sort/sort/tracker.py 的_match()函数， 同理采用的min_cost_matching进行匹配，传入的有iou_cost度量函数，max_iou_distance用于过滤，跟踪框，检测框，需要匹配的跟踪框的index，需要匹配的检测框的index。 # Associate remaining tracks together with unconfirmed tracks using IOU. iou_track_candidates = unconfirmed_tracks + [ k for k in unmatched_tracks_a if self.tracks[k].time_since_update == 1] unmatched_tracks_a = [ k for k in unmatched_tracks_a if self.tracks[k].time_since_update != 1] matches_b, unmatched_tracks_b, unmatched_detections = \\ linear_assignment.min_cost_matching( iou_matching.iou_cost, self.max_iou_distance, self.tracks, detections, iou_track_candidates, unmatched_detections) 匈牙利算法 无论是级联匹配还是IoU匹配，最后都会用到min_cost_matching函数，其中匹配的核心代码是： # code/chapter-8/tracking/deep_sort/deep_sort/sort/linear_assignment.py min_cost_matching() row_indices, col_indices = linear_assignment(cost_matrix) # 匈牙利算法求解，得到配对的（raw, col） 这里使用了scipy库的linear_sum_assignment实现，可返回最优匹配的坐标，到底匈牙利算法是如何解决分配问题，下面进行介绍。 匈牙利算法是1955年美国数学家哈罗德·库恩（(W.W.Kuhn)），基于匈牙利数学家康尼格(D.Kőnig)提出的康尼格定理，提出求解二分图最大匹配的一种方法。 二分图（ Bipartite graph，二部图）是图论中一种模型，指的是有A，B两个节点集合，存在一系列边，边的两端不能再同一个集合，简单说就是A只能和B相连，反之亦然。 为了求解分配问题，需要对二分图中每种可能进行代价描述，称之为代价矩阵（系数矩阵、变换矩阵等等）。 下面借鉴视频中的内容，简要介绍匈牙利解决二分图最大匹配问题。 假设有一本说明书，需要翻译成4种语言，现在有4个人，他们对每个语言的熟悉程度不同，因此如何分配任务，就是一个典型的二分图最大匹配问题。 首先，可以根据任务进行量化，得到目标函数min Z。 然后，设置约束条件，一个人选一个语言，一个语言只能被一个人选择。 最后，得到右下角的方程式。 匈牙利算法实现步骤是： 画圈，划0：对代价矩阵每行减去最小值，使得其出现0；然后对列进行同样操作，使得其出现0； 试指派寻找最优解：0表示最优解，一行只有一个0的话，肯定优先考虑分配。 因此按行找仅有一个0的行，并且分配，分配之后，行已经被分配，因此对应的行需要删除。 同理对列操作。 若还存在没有标记的0元素，且找不到独立0元素的行(列)，从剩余0元素最少的行(列)开始，比较这行0元素所在列中0元素的数目，选择0元素最少的那列的这个0元素画圈，同时划去该行该列其余0元素。（如绕口令一般，这里推荐看视频） 打勾，画圈：没有画圈的行打√，打勾行含划0元素的列打√，打√列含画圈0元素的行打√，未打√的行画横线，打√的列画竖线。 增加0元素：寻找未被直线覆盖部分的最小元素，打 √的行减最小元素，打 √ 的列加最小元素。 重复执行2-4，直到找到n个位于不同行不同列的0元素。 其核心思想是用增广路求最大匹配，这里的行列操作实际是将增广路的思想转换为矩阵的表达，因此单纯观察匈牙利算法的矩阵解法，是很难理解其原因，建议通过图论、运筹学的基础知识去了解匈牙利算法求解过程。 更多目标跟踪中的匈牙利算法讲解推荐： 匈牙利算法&KM算法 目标跟踪初探（DeepSORT） 代码细节： 对于代价矩阵，行是tracks， 列是dets，匹配上的框才会有index返回。 DeepSORT核心——更新输出过程 卡尔曼滤波 由于目标检测算法的不稳定，直接用目标检测输出的检测框来表示目标位置的精度不佳，常常会看到框的抖动。 为了让框更稳定的描述物体的位置，deepsort中采用了卡尔曼滤波算法（Kalman filtering）来对目标位置进行输出。 卡尔曼滤波算法是斯坦利·施密特(Stanley Schmidt)在1958年提出的，当时要解决的是阿波罗飞船的导航问题，可以用于估计飞船的位置，是一个很好的运动估计。 随后，卡尔曼滤波广泛应用在天文，宇航，气象等领域。 卡尔曼滤波可以解决的核心问题是，在一个线性动态系统中，可以基于历史信息与当前输入信息，很好的估计当前最优信息，当前最优信息就是卡尔曼滤波的输出，它可以很好的过滤掉噪声（必须是高斯噪声）。 这里的历史信息，可以理解为跟踪框（tracks）（上一帧），当前输入信息是目标检测算法输出的检测框（dets），而当前时刻deepsort要输出的目标的位置，是dets+tracks经过卡尔曼滤波算法的输出，即一个当前最优信息，是一个预测的、估计的值。 为了对卡尔曼滤波有进一步认识，这里简要介绍卡尔曼滤波思想和概念。对于细节，推荐阅读图说卡尔曼滤波，， 从放弃到精通！卡尔曼滤波从理论到实践~ 这里借用视频中的公式进行讲解过程，公式中更细节内容，可以参考卡尔曼滤波的五大公式 x：观测对象，例如卫星的坐标，图像中目标的坐标，水壶中的温度等。 x：观测对象，例如卫星的坐标，图像中目标的坐标，水壶中的温度等。 t：表示时刻 -：表示估计值 ^：表示估计，由于x都是带着^的，这里可以不加以区分 F：状态转移矩阵 P：协方差矩阵 K：卡尔曼增益，用于权衡，历史信息与当前输入信息的重要程度。 对于目标跟踪算法的输出，是公式4，公式4也是最核心的内容，其余公式都在为公式4服务的。 为了理解公式4，借鉴文章如何通俗直白地理解卡尔曼滤波算法的讲解。 假设，有两台电子秤，分别进行测量一瓶水，得到的结果如图所示。 由图可知，电子秤不是绝对精准的，存在一定误差，不过当前观测值分别是160和170，那么如何融合两个数据？ 最简单的是 M = (A+B)/2 = 165。 求平均的设想里，有一个重要前提是，认为A和B的贡献是一样的，重要程度是一样的，因此各占50%的权重。 如果，A的精度更高，B精度差一些，即A的方差小一些，B方差大。这时，平均就不合适了，应该让精度高的观测值的权重更高。 权重的计算，需要考虑谁更重要，即方差更小，所以可以通过方差的比较获得权重分配。 A 测量结果 为 160 +- 3， B 测量结果 为 170 +- 9，可知A 的测量结果精度是 B 测量结果精度的 3倍。 这个公式是理解上述公式4的关键，通过将A提取出来，变为单独一项，就可以很好的衡量，基于A，要如何变更，得到最优估计值。 这里的变更加号的右边，B-A乘以一个权重，这个权重就是卡尔曼滤波中的卡尔曼增益K。其中B就是目标检测算法输出的dets，A是tracks。 而卡尔曼增益K的计算，需要依靠协方差矩阵P。 DeepSORT 小结 到此，总结一下卡尔曼滤波过程，当前帧跟踪框的信息由卡尔曼滤波器在更新阶段输出。 更新阶段需要使用到：当前帧检测框， 基于上一帧跟踪框的预测值，并且加权得到。 其中，上一帧跟踪框的预测值来自公式1。代码中是： self.tracker.predict()。 有了基于上一帧跟踪框的预测值，再输入dets，就可以得到当前帧跟踪框信息，代码中是： self.tracker.update(detections)。 在代码中，卡尔曼滤波器维护mean和covariance，分别表示公式中的预测值x，协方差矩阵P。 self.mean, self.covariance = kf.predict(self.mean, self.covariance) # mean即bbox的坐标数据 self.mean, self.covariance = kf.update(self.mean, self.covariance, detection.to_xyah()) 到这里，deepsort原理有了大概的描述，更多细节仍需要到代码中观察，这里做一个简要回顾。 跟踪框的输出： 为了更稳定，采用了卡尔曼滤波算法，将当前帧检测框信息，结合卡尔曼滤波对当前帧的预测，两者共同作用，得到输出。 目标的匹配： 为了让检测框找到对应的，合适的跟踪框，把它转化为二分图最大匹配问题，可以用匈牙利算法很好的求解。 同时，为了匹配更精准，减少身份交换，deepsort先进行新目标框的匹配（仅限前70级，级表示被跟踪的次数），然后再进行基于IoU的匹配。 跟踪框准入准出： 为了避免漏检、误检等短暂的不稳定因素，设计了预备框和正式框的概念。经过3次考验，可转正，经过30次机会仍不靠谱（未检测到），开除X籍。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-8/8.4-tracking-2.html":{"url":"chapter-8/8.4-tracking-2.html","title":"8.4 目标跟踪（下）——虎门大桥车流量统计","keywords":"","body":"8.4 目标跟踪（下）——虎门大桥车流量统计 上一小节，对deepsort的实现步骤进行了详细分析，本小节将使用deepsort代码以及yolov5来实现车流量统计。 本节，首先对deepsort源代码的设计进行简要的结构剖析，来学习代码设计，然后将其结合yolov5，实现车流量统计。 注意，代码所需的模型文件，通过网盘下载：链接：https://pan.baidu.com/s/1Ys_v1Tqta4wJMHC8NKeTTg 提取码：ucf4 注意，ckpt.t7为deepsort的模型文件，一定要放到：F:\\pytorch-tutorial-2nd\\code\\chapter-8\\tracking\\deep_sort\\deep_sort\\deep\\checkpoint下面 deepsort源码——结构分析 deepsort的代码不算复杂，设计了几个核心类，然后为各个核心功能编写了实现函数。这里绘制简要的UML图，对代码设计的思路进行学习。 对于一个业务场景，首先识别实体，并分析实体的属性和功能，下面自下而上进行分析目标跟踪当中存在的实体。 Track目标物体：目标跟踪的核心元素是目标物体，这里称为Track类，对于一个目标，需要有坐标信息，id， 特征向量列表，状态等信息。 Tracker目标跟踪器：管理所有目标，并可实现目标的更新，因此需要卡尔曼滤波器，管理目标集合tracks等信息。 KalmanFilter卡尔曼滤波器：维护卡尔曼增益矩阵，并实现预测、更新两大功能。 DeepSort类：进行统一封装，对外提供update函数，返回跟踪框。 对于级联匹配，会在Tracker类中_match()实现，其中设计了一系列模块，包括 matching_cascade：级联匹配实现，循环70次进行匹配。 min_cost_matching：实现一次最小代价匹配。 linear_assignment：匈牙利算法实现。 NearestNeighborDistanceMetric：级联匹配中距离度量功能实现，其中维护了各目标的所有特征向量，每一帧的特征向量都会被保存。最大保存100个特征向量。 if self.budget is not None: self.samples[target] = self.samples[target][-self.budget:] # 相当巧妙的实现最多记录最新的100个特征向量 到这里，deepsort大体框架以及搭建完毕，使用方法非常简单，只需要实例化DeepSort类，调用.update()即可获得跟踪框信息。 deepsort+yolov5——车流量统计 目标跟踪可以获得目标的位置及唯一标识，它只是方法，并不是目的。 基于目标跟踪方法，可以实现许多有价值的事情，例如卡口人流量计数，交通道路车流量计数与统计，警戒区域预警等。 进行行人计数或车流量计数时，需要判断目标是否经过特定区域，这时需要撞线机制来实现，撞线机制可以有两种方法实现。 一种是基于区域判断，另外一种是基于线段相交判断。 另外一种是基于线段相交判断，则是基于物体的历史轨迹曲线，判断是否与界线相交。 计数中的撞线机制 本案例采用基于区域的撞线机制，对边界设置两个区域，一般称inner和outter区域，当物体先到达inner，再进入outter，则可判断物体是离开，反之亦然。 对于inner和outter区域，每个区域需要记录曾经到达区域里的目标id，仅当两个区域同时存在过目标id，可以计数，并且删除目标id。 例如图中的ID-60，进入了inner区域（蓝色），inner区域需要观察ID-60是否存在outer区域中（黄色），当前是不存在的，因此添加到inner区域的历史列表中。 下一帧，ID-60到达黄色区域，黄色区域同样地，先判断ID-60是否来自蓝色区域，它在蓝色区域的历史记录中找到了ID-60，因此可以判断ID-60是从inner到达outer，所以outer进行加一。 反之inter加一。 在代码实现上有一些抽象，这里做简单的讲解。 如何判断物体到达inner和outter区域？ 采用mask矩阵，inner区域像素是1， outer像素是2，mask矩阵大小与图片大小一致，采用目标的位置坐标对mask矩阵索引，通过索引值==1？ 还是==2？来判断当前物体位于什么区域。 如何判断物体先、后顺序？ 区域中发现新物体时，首先判断是否存在对向区域，若不存在，才可以加入区域的物体容器中进行管理。若存在，即可删除，并且计数。 为了实现撞线机制，这里设计了三个类，分别是BoundaryType、CountBoundary和BaseCounter 处理逻辑在BaseCounter的counting()，边界区域抽象成CountBoundary，实现了必要的函数来完成计数。 下面简单介绍counting函数中，如何判断物体是从outer来，到达inter，实现inter计数+1的（反之亦然） 第1行：通过物体的x,y坐标，对索引矩阵进行索引，得到索引值。例如：[1, 2, 0, 0, 0, ...]。通过索引值可知在何区域 第4行：通过索引值列表，判断当前在inner区域的目标，并且返回它们的id 第5行：获取，当前到过outer的目标id 第8行：判断是否有交集，有交集表明，该id从outer来，已经抵达inner。可以计数。 第9行：判断是否存在差集，inner有，outer没有，表明物体可以加入inner的id_container中进行管理 第10行：由于目标完成了计数，outer_boundary中需要删除它。 第11行：由于目标第一次到来，所以注册到inner_boundary中，后续供outer_boundary查询。 bbox_area_list = self.area_mask[index_xy] # 获取bbox在图像中区域的索引，1,2分别表示在边界区域. [int,] # ======================== 先处理inner区域 ==================================== inner_tracks_currently_ids = self.get_currently_ids_by_area(tracks, bbox_area_list, BoundaryType.inner) outer_tracks_history_ids = list(self.outer_boundary.id_container.keys()) # 获取历史帧经过outer区域的目标的id # 当前与历史的交集，认为是目标从outer已经到达inner，可以计数，并且删除。 outer_2_inner_tracks_id = self.intersection(inner_tracks_currently_ids, outer_tracks_history_ids) only_at_inner_tracks_id = self.difference(inner_tracks_currently_ids, outer_tracks_history_ids) self.outer_boundary.remove_tracks(outer_2_inner_tracks_id) # 删除outer中已计数的id self.inner_boundary.register_tracks(only_at_inner_tracks_id) # 注册仅inner有的id 注意事项： 在第1行中 self.area_mask的制作中，由于采用的是像素1和2，在resize时，导致2的边界有一系列1的存在，导致了误检！ 按设计，1在2的下面，这里1反而出现在了2的上面，导致实际是“出”的，计算为了“入” 把上述代码组装起来得到01-main.py，做好模型文件、视频文件、边界点的配置，运行即可得到以下结果。 模型权重文件，视频文件可通过网盘下载： 注意，ckpt.t7为deepsort的模型文件，一定要放到：F:\\pytorch-tutorial-2nd\\code\\chapter-8\\tracking\\deep_sort\\deep_sort\\deep\\checkpoint下面 完整视频可见B站 这里为了实现边界区域点集的获取，编写了鼠标点选边界区域的代码00-draw-border.py。 运行后，鼠标双击实现选点，选点顺序必须从左上角开始，顺时针，选择完毕，terminal中打印的点集list，复制下来使用即可。 小结 目标跟踪案例中，内容比较多，这里总结一些关键知识点： SORT与DeepSORT算法步骤：本案介绍目标跟踪中出现的问题，一步步引出DeepSORT设计的复杂逻辑，由问题出发，以解决问题的方式，观察DeepSORT的步骤。 DeepSORT中的核心算法：卡尔曼滤波器与匈牙利算法，卡尔曼滤波常用于带有高斯噪声的线性运动系统，可以很好的预测运动状态。匈牙利算法可以解决二分图匹配问题，今后也可以借鉴两个算法解决实际业务问题。 DeepSORT代码结构剖析：通过UML图，分析DeepSORT代码是如何抽象、设计的，巩固面向对象编程的思想。 计数的撞线机制：介绍基于区域的撞线机制，并通过面向对象编程来实现计数器。 DeepSORT+YOLOv5的联合使用：将目标检测+目标跟踪+计数机制联合使用，构建实际应用，在主代码中可以发现，各功能模块抽象独立出去，主代码的核心代码仅两行：bboxes = detector.detect(im)； counter.counting(list_bboxs)； 目标跟踪仍是一个较大研究方向，DeepSORT仅是其中一种方法，要深入掌握目标跟踪还需学习其他方法。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "},"chapter-8/8.5-cycleGAN.html":{"url":"chapter-8/8.5-cycleGAN.html","title":"8.5 生成对抗网络——CycleGAN","keywords":"","body":"8.5 生成对抗网络——CycleGAN 简介 本小节将介绍GAN模型中有趣的模型CycleGAN。 CycleGAN是一种双向循环的GAN模型，可实现X域与Y域之间的相互转换，并且是基于unpaired data（即不需要标注，只需要收集图片）。相较于此前的pix2pix，cyclegan适用性更广，毕竟unpaired data比paired data更容易获取。 例如论文中展示的，照片与莫奈风格画之间的互相转换，斑马与马之间的转换，夏天与冬天之间的转换。 本节先介绍GAN与CycleGAN的结构，再通过代码详细介绍CycleGAN的训练、推理。 GAN简介 GAN（Generative Adversarial Nets，生成对抗网络）由 Ian J Goodfellow在2014发表于《Generative Adversarial Nets》，可谓是推开了生成模型的一扇大门。 GAN是一种从随机噪声生成特定分布数据的模型，例如生成人脸数据，手写体数据，自定义数据集等。 GAN当中有Generator与Discriminator两个模型，G负责学习从噪声到数据的映射，D负责充当损失函数，判断G生成得是否足够好，G和D交替训练，形成对抗，同步提升，最终使得G生成的数据越来越像人脸。 根据模型的结构，GAN模型延伸出一系列变体，如本文要介绍的CycleGAN，还有DCGAN，Conditional GANs，Pix2Pix，SRGAN等。 GAN的设计十分巧妙，从神经网络训练的角度考虑，GAN是将损失函数替换为，神经网络的输出，具体如下图所示： 传统模型训练，需要用loss_fun(output, label)得到loss值，然后求梯度优化。 在GAN中，巧妙了利用一个判别器模型，D_net， D_net(output) 趋向0， D_net(training_data)趋向1，依次获得loss值。 CycleGAN简介 CycleGAN是一种无监督学习方法，由Jun-Yan Zhu等人于2017年提出。 它的主要思想是通过两个生成器和两个判别器来实现两个不同域之间的图像转换。 与其他的GAN模型不同的是，CycleGAN不需要成对的图像进行训练，而是只需要两个域中的任意数量的图像即可。 下面介绍CycleGAN的模型结构与损失函数。 CycleGAN模型结构 CycleGAN模型由两个生成器，两个判别器构成。 生成器G，将X域图像变换到Y域 生成器F，将Y域图像变换到X域 判别器Dx，判别图像来自X则为1， 图像来自Y则为0 判别器Dy，判别图像来自X则为0， 图像来自Y则为1 生成器采用3层卷积+一系列残差块构成； 判别器采用PatchGANs，其特点在于对一张图片不是输出一个向量，而是输出NxNxC的张量，NxN分别对应原图中的70x70区域，即对一张图，划分多个70x70的patch，每个patch来判别它是0类，还是1类。 CycleGAN损失 cyclegan最大的特点在于损失函数的设计，除了GAN的常规两个损失函数之外，论文中增加了cycle consistency loss（循环一致性损失），用来避免模式坍塌，以及更好的让GAN模型生成合理的图像，同时，在官方代码中还增加了一项identity loss，用来增加GAN模型对于本域图像信息的学习。 因此，整体loss有8项，分别是'D_A', 'G_A', 'cycle_A', 'idt_A', 'D_B', 'G_B', 'cycle_B', 'idt_B' 生成器的损失 loss1 ：判别器的输出接近1 对于G，目标是让对应的判别器D，认为假图像是真图像，即输入是假图像，标签是1，目标是欺骗D，G就是训练好了。 self.loss_G_A = self.criterionGAN(self.netD_A(self.fake_B), True) target_tensor = self.get_target_tensor(prediction, target_is_real) # 根据self.fake_B，生成对应的标签，即N*N的标签，为patchGAN的输出匹配 loss = self.loss(prediction, target_tensor) # MSELoss() 而非BCE loss2：F(G(x)) 与 x一致 除了常规Loss，还有cycle consistency loss（循环一致性损失），目的是经过G得到的图片，返回去再经过F，应当是可以恢复得到X域的图像x_hut，并且x与x_hat应当是逐像素一模一样的。 这样的G和F才是合理的。 self.criterionCycle = torch.nn.L1Loss() self.loss_cycle_A = self.criterionCycle(self.rec_A, self.real_A) * lambda_A # lambda为缩放系数 loss3：恒等映射损失 该损失在代码中才出现，论文中并没有提到。恒等映射损失的思想是，生成器G_A接收A域图像，生成B域图像；若接收B域图像，应该生成恒等的B域图像，即B域图像一模一样，不能变。 G_A should be identity if real_B is fed: ||G_A(B) - B|| self.idt_A = self.netG_A(self.real_B) self.loss_idt_A = self.criterionIdt(self.idt_A, self.real_B) * lambda_B * lambda_idt # self.criterionIdt = torch.nn.L1Loss() 因此，对于生成器G而言，要求它： 生成的假图像，要让判别器预测为1， D(G(x)) 逼近1； G生成的图像，再经过F生成的图像，应当等于原图，此为循环一致性损失 已经是B域的图像，经过G_A，应当得到B域的原图。 判别器的loss 判别器损失较为简单，对于真图像，需要预测为1，对于假图像，需要预测为0。 其中，假图像不是基于当前batch的，而是记录过往的一批假图像，从假图像池中抽取。 fake_B = self.fake_B_pool.query(self.fake_B) self.loss_D_A = self.backward_D_basic(self.netD_A, self.real_B, fake_B) def backward_D_basic(self, netD, real, fake): # Real pred_real = netD(real) loss_D_real = self.criterionGAN(pred_real, True) # Fake pred_fake = netD(fake.detach()) loss_D_fake = self.criterionGAN(pred_fake, False) # Combined loss and calculate gradients loss_D = (loss_D_real + loss_D_fake) * 0.5 loss_D.backward() return loss_D 训练注意事项 论文中超参数：batch size =1；epoch =200；lr：前100epoch，固定0.0002，后100epoch，线性下降至0 其它注意事项： 两个域图像是否有一致性： 举个例子: 苹果 橘子: 都是球形, OK! 苹果 香蕉: Mode Collapse! 训练CycleGAN要有耐心 学习率别太高 对抗损失权重不要太高，循环一致性损失权重为1的时候，对抗损失一般设置为0.1 判别器优化频率高于生成器 使用最小二乘损失（MSE） cycleGAN的loss不能准确反应训练的好坏，不代表着训练进度，甚至不能代表结果优劣。所以还是要输出样张看效果，或许可以借鉴WGAN的思想 由于 minimax 优化的性质，许多 GAN 损失不会收敛（例外：WGAN、WGAN-GP 等）。对于 DCGAN 和 LSGAN 目标，G 和 D 损失上下波动是很正常的。只要不爆炸应该没问题。 CycleGAN代码实现 接下来，通过pytorch训练一个可以将图片转换为莫奈风格图像的CycleGAN，github已经19.5K star了，可见深受大家喜爱。 数据集准备 由于不需要标签，仅需要准备图像，所以在根目录下，存放trainA, trainB, testA, testB即可，分别存放A域的图像，B域的图像。 这里下载官方提供的monet2photo数据集，可以通过sh脚本下载，也可以手动下载（推荐） # 方法一：bash bash ./datasets/download_cyclegan_dataset.sh monet2photo # 方法二：手动下载 # apple2orange, summer2winter_yosemite, horse2zebra, monet2photo, cezanne2photo, ukiyoe2photo, vangogh2photo http://efrosgans.eecs.berkeley.edu/cyclegan/datasets/$FILE.zip # 例如莫奈数据下载 http://efrosgans.eecs.berkeley.edu/cyclegan/datasets/monet2photo.zip 数据加载 整个数据模块代码设计如下图所示： 该项目适配pix2pix， cyclegan，因此提供了多种dataset，所有的dataset都继承于BaseDataset，针对cyclegan的是unaligned_dataset.py中的UnalignedDataset。 对于dataloader，提供了一个类 CustomDatasetDataLoader，并且实现了迭代协议iter，因此\"dataloader\"是自定义的一个可迭代对象。 在主代码01_train.py中，通过33行代码：dataloader = create_dataset(opt) ，实现dataloader的创建，所有的配置信息存放在opt中。 接下来关注UnalignedDataset，它内部实现了transform，transform由opt的参数决定 第一步：缩放变换，有resize，或者基于width缩放的方式；默认基于resize_and_crop。 resize的尺寸是opt.load_size 第二步：crop的尺寸是 opt.crop_size 第三步：Normalize 这份代码中有一个值得借鉴的是，通过参数配置，来选择调用具体的类。实现方法是通过，importlib.import_module实现通过字符串形式import工具库。 def find_dataset_using_name(dataset_name): \"\"\"Import the module \"data/[dataset_name]_dataset.py\". In the file, the class called DatasetNameDataset() will be instantiated. It has to be a subclass of BaseDataset, and it is case-insensitive. \"\"\" dataset_filename = \"data.\" + dataset_name + \"_dataset\" datasetlib = importlib.import_module(dataset_filename) # 这里的dataetlib，等同于一个库，例如。import cv2的cv2, import torch的torch dataset = None target_dataset_name = dataset_name.replace('_', '') + 'dataset' for name, cls in datasetlib.__dict__.items(): if name.lower() == target_dataset_name.lower() \\ and issubclass(cls, BaseDataset): dataset = cls if dataset is None: raise NotImplementedError(\"In %s.py, there should be a subclass of BaseDataset with class name that matches %s in lowercase.\" % (dataset_filename, target_dataset_name)) return dataset 模型构建 源代码中将模型（nn.Module）， 损失函数，优化器一并放到了CycleGANModel类当中，对外提供set_input()与optimize_parameters()，实现前向传播、损失计算、反向传播，这样可以让主代码更简洁。 模型部分代码设计如下图所示 对于 netG_A/B，cyclegan中是resnetblock构成的生成器，详细可见models/networks.py的ResnetGenerator类， 主要由resnetblock的下采样和TransConv的上采样构成，最后加入tanh()激活函数。 对于netD_A/B， 是一个patchGAN，全部由卷积层构成的全卷积网络，详见 models/networks.py的NLayerDiscriminator。 整个模型构建与优化核心代码如下： model = create_model(opt) # create a model given opt.model and other options model.setup(opt) # regular setup: load and print networks; create schedulers ---------------------------------- model.set_input(data) # unpack data from dataset and apply preprocessing model.optimize_parameters() # calculate loss functions, get gradients, update network weights 模型训练 数据、模型、损失函数与优化器准备完毕，可以进行迭代训练。 如果在windows下训练，需要开启 visdom python -m visdom.server 由于此处使用了visdom进行可视化，需要先行开启visdom，否则会报错： requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError(': Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。')) [WinError 10061] 由于目标计算机积极拒绝，无法连接。 训练指令： python 01_train.py --n_epochs 200 --dataroot path/to/your/datasets/monet2photo --name monet2photo_cyclegan --model cycle_gan 日志信息、模型信息将存储于checkpoints\\monet2photo_cyclegan中 训练结果 cycleGAN的loss不能准确反应训练的好坏，不代表着训练进度，甚至不能代表结果优劣，整体趋势是，cycle loss逐渐下降，如下图所示 推理测试 预训练模型可以从这里下载：链接：https://pan.baidu.com/s/1bEPNBbAeqMumpM2pqKwb4w 提取码：q159 python 02_inference.py --dataroot G:\\deep_learning_data\\cyclegan\\monet2photo\\testB --name monet2photo_cyclegan --model test --no_dropout --model_suffix _B180 model_suffix 格式说明：模型模型文件名保存为latest_net_G_A.pth、latest_net_G_B.pth。在代码中会自动拼接： \"latest_net_G{}.pth\".format(model_suffix) 最后在F:\\pytorch-tutorial-2nd\\code\\chapter-8\\cyclegan\\results\\monet2photo_cyclegan\\test_latest下就有对应的结果图片 这里展示了120， 180， 200个epoch时的展示效果，感觉180时的效果最好。 小结 本小结先介绍了GAN与cycleGAN的模型结构，GAN是一个巧妙的利用神经网络进行损失计算的设计，CycleGAN是巧妙的利用了两个GAN相互转换，并提出循环一致性loss，最终CycleGAN的损失共8个，分别是'D_A', 'G_A', 'cycle_A', 'idt_A', 'D_B', 'G_B', 'cycle_B', 'idt_B'。 然后介绍CycleGAN源代码使用及设计，其将Dataset, DataLoader, model, loss, optim进行了高度封装，使主代码很简洁。 从此可见，无论多复杂、难理解的pytorch模型训练代码，都离不开Dataset, DataLoader, nn.Module，loss, optim，只要了解训练的步骤，这些复杂的代码都可以梳理出来。 自2014年GAN提出以来，往后的5年间提出了各式各样的GAN变体，也有了非常多有趣的应用，感兴趣的朋友可以进一步了解。 2020年之前，在图像生成领域，GAN是当之无愧的主流，但2020年《Denoising Diffusion Probabilistic Models》（Diffusion）提出后，基于扩散模型（diffusion model）的图像生成称为了学术界的宠儿，包括OpenAI提出的DALL-E系列，stability.ai提出的Stable-Diffusion。 下一节将介绍扩散模型（diffusion model）及代码实现 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年07月23日21:48:10 "}}