{"./":{"url":"./","title":"简介","keywords":"","body":"简介 本资源是PyTorch模型训练实用教程的第二版，将为广大朋友带来更丰富的PyTorch学习资源。看到PyTorch模型训练实用教程过了三年，仍旧在发光发热，依旧能帮助到初学者，这令我十分欣慰，但又非常愧疚。为什么？因为深感PyTorch模型训练实用教程的内容不够丰富，不能给初学朋友更多的帮助。为此，《PyTorch实用教程》将弥补第一版的空白，新增丰富的内容，想大家之所想，将提供在线阅读的电子书籍，以及入门友好的、可工业落地的配套代码。 本书整体分三部分，上篇：入门，中篇：应用，下篇：落地。 上篇 PyTorch基础。针对刚入门、非科班、本科生，提供PyTorch介绍，讲解开发环境的搭建，介绍PyTorch核心模块，详解核心功能函数，最后利用所讲解的PyTorch知识点构建一套自己的代码结构，为后续的应用打下基础。 中篇 产业应用。经过上篇，磨了一把好刀，接下来就用它在各领域上大显身手。计划讲解的领域包括，计算机视觉（Computer Vision）的图像分类、图像分割、目标检测、生成对抗网络等；自然语言处理（Natural Language Processing）的部分应用；语音识别；多模态等领域。（由于自己对CV比较熟悉，其他领域欢迎有志之士一同补充） 下篇 工业落地。有了工具，有了场景，接下来就要让它产生价值，变成可用的、好用的产品。本篇会涉及模型加速三板斧：模型量化、模型剪枝、模型蒸馏。此外，还会涉及主流的模型部署框架平台：TensorRT、Openvinno、ONNX等（同上，此处欢迎大家一同补充各平台的部署内容） 相信经过上、中、下篇的学习，可以帮助入门的同学少走很多弯路，快速掌握PyTorch，具备独当一面的能力，能依据实际场景选择算法模型，可以将模型部署应用，形成闭环，全流程打通。 如何使用本资源，请看前言 有任何想法和建议，欢迎与我联系：yts3221@126.com Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年04月26日21:48:10 "},"preface.html":{"url":"preface.html","title":"前言","keywords":"","body":"前言 本书背后的故事 《PyTorch实用教程》（第二版），动笔时间为2021年12月16日，什么时候能完结，并不知道。为什么会不是写完再发布？因为担心再不迈出第一步，这本书就会难产。其实，想写这本书已经很久了，至少2年多了吧（见下图），总由于各种原因，迟迟没有开始动笔，索性，采用github在线更新的方式，和各位朋友提前见面吧，你们的反馈是我最大的动力。 为什么是书？ 书籍是人类智慧的结晶，不同于普通的博客、公众号甚至课件，书籍的内容会更加完整和充实，这是受到前些天看到的一个视频有感而发，视频说的是北大退休的韩茂莉教授将在B站上延续她的课堂生涯，将她毕生所学的历史地理知识传授给更多的朋友，在第一个视频里她提到：“但凡具有一种人类形成的，知识性的精华，其实都在书中 。” 看到这句话感触颇深，因为写书的事情一直在脑海中反复回荡，但一次次的被生活的琐碎给拍灭。除了韩老师触动之外，自己这几年的经历也十分契合书写一本书，同时也欢迎有志之士与我一同完善这本《PyTorch实用教程》（第二版）。 一小步 为了不让这本书难产，于是先走出这一小步，让自己踏上书写的征程，至于后面的东西交给时间吧。 为什么写这本书 ​ 这本书是对PyTorch模型训练实用教程的改进优化，是对第一版的内容进行丰富，会增加更多的PyTorch基础，增加丰富的应用案例，同时包含模型部署上线这一关键的知识点。萌生第二版的想法大约在2019年11月，当时距离第一版发布大约一年，期间又对PyTorch有了一个深入的学习了解过程，于是想把这本书继续优化下去，帮助更多的朋友快速掌握PyTorch。可奈于当时精力有限，就迟迟没有动笔，2020年与2021年是忙碌的两年，生活的琐碎以及工作占据了大多数时间，现在（2021年12月16日22:13:10）终于有合适的条件动笔了，一刻不敢拖延，害怕这刚刚燃起的火苗又被琐碎的生活浇灭。 ​ 除了是对第一版的改进，更大的原因是一种责任。由于这几年的经历，让我感到需要出一本高质量的PyTorch书，它一定是大家爱不释手的资料，可以为大家的深度学习道路提供一点便捷，能给大家带来些许改变，这就足够了。第一版发布过去已经三年有余，仍旧能看到她在发光发热，这令我十分欣慰，但又非常愧疚。 第一版仍旧在发光发热 ​ 因为第一版的内容略显简单，内容单薄，缺乏应用案例以及工业部署落地。那么第二版就是为了弥补上述缺点，把PyTorch基础内容完善，增加CV和NLP以及多模态的工业级应用案例，最后讲解模型部署，实现工业落地，这样的教程才是完整的，不是么。 ​ 通过本书，也希望给大家带来一个清晰的深度学习模型应用流程。 读者对象 首先，适合新手，本书上篇将介绍PyTorch最基础的概念，为新手构建知识框架，上篇所有知识点配备Notebook进行图、文、代码，三位一体的学习。 其次，适合初学者，本书中篇将采用PyTorch代码进行各领域应用案例讲解，暂定包括计算机视觉、自然语言处理、语音识别和多模态，同时提供完整的代码框架，开箱即用，无需额外编程，可涵盖大多数朋友的项目需求。 再者，适合中高级朋友，本书下篇将涉及模型加速与部署内容，是算法工程师进阶的必备之路，模型加速包括剪枝、量化、蒸馏，部署暂定包括TensorRT、OpenVINO和ONNX。 上中下篇分别对应不同阶段的学习，相信大多数朋友都能从本书中获益。 如何阅读这本书 本书采用电子书在线更新方式，详见PyTorch实用教程（第二版）-电子书 全书配套代码，详见PyTorch-Tutorial-2nd 由于自身水平、精力有限，书中不可避免的会出现错误，恳请大家指正。同时欢迎大家投稿，例如NLP方向，多模态方向，模型部署，模型加速方向均可。 欢迎联系：yts3221@126.com 致谢 首先感谢老婆的理解与支持（狗头）。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年04月26日21:48:10 "},"chapter-1/":{"url":"chapter-1/","title":"第一章 PyTorch 简介与安装","keywords":"","body":"第一章 PyTorch 简介与安装 第一章 PyTorch 简介与安装 1.1 PyTorch 初认识 1.2 环境配置之Anaconda 1.3 环境配置之Pycharm 1.4 环境配置之CUDA&cuDNN 1.5 环境配置之PyTorch系列包 1.6 环境配置之Jupyter Notebook Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年04月26日21:48:10 "},"chapter-1/1.1-PyTorch-Introduction.html":{"url":"chapter-1/1.1-PyTorch-Introduction.html","title":"1.1 PyTorch 初认识","keywords":"","body":"1.1 PyTorch 初认识 一句话认识PyTorch “An open source machine learning framework that accelerates the path from research prototyping to production deployment.” ——选自 https://pytorch.org/ PyTorch是一个帮助大家加速算法模型研究到产品部署的开源机器学习框架。 PyTorch历史 FAIR（ Facebook AI Research，Facebook人工智能研究院 ）于2017年初发布PyTorch，PyTorch的命名可以拆为Py（Python）与Torch。Py就是python语言，Torch是一款早期的深度学习框架，所以PyTorch是在Torch基础上用python语言重新打造的一款深度学习框架。 那么什么是Torch呢？Torch是纽约大学在2002年开发的深度学习框架。Torch虽然很好用，但是它采用了一门较为小众的语言——Lua语言作为接口。这明显地增高了Torch的使用门槛，想要使用Torch必须学习一门新的编程语言，这让大家都望而却步。 好在Torch的幕后团队也意识到这一点，于是团队采用python语言作为接口对Torch进行了重构，于是就有了PyTorch。 PyTorch代码最早公开可追溯到2016年8月24日的v0.1.1（https://github.com/pytorch/pytorch/tags?after=v0.1.4） 随后 •2017年1月正式发布PyTorch •2018年4月更新0.4.0版，支持Windows系统 •2018年11月更新1.0稳定版，已GitHub 增长第二快的开源项目 ...... 对PyTorch版本的更新感兴趣的朋友，可以关注 PyTorch-Tags，这里是最权威版本更新信息来源，要比官方文档还要快。 PyTorch必备网站 要熟悉PyTorch，不得不熟悉PyTorch的一些官方网站，以及这些网站的使用。下面列举几个实用的PyTorch网站。 官网 https://pytorch.org/ 官网包含权威的PyTorch介绍、PyTorch官方文档、生态资源等信息。例如Get Started中，可以获取权威的安装信息。例如，特定版本下，windows系统，所支持的CUDA版本是多少，这点非常关键，往往GPU用不起来，就是CUDA版本不匹配。 除了最新稳定版，还可以下载历史版本的whl文件，进行离线安装（网速不好的朋友，建议手动下载whl，然后进行安装）。历史版本whl的在哪那里下载呢？ 是需要挖掘的，网址在上图的windows系统、Pip安装、Python、CUDA条件下才会出现，它是：https://download.pytorch.org/whl，点击torch，就可以发现所有历史版本都在这里可以找到，并且命名都有良好的规范，这里不过多介绍，在安装部分再详细讲解。 除了Get Started栏目，其它栏目也是很好的学习资料。 Ecosystem：PyTorch生态系统资源库，里面收录生态系统内的资源，也欢迎大家加入并贡献资源，里边有CV数据增强开源库——albumentations、FB的目标检测和分割算法库——detectron2、优秀的部署平台——onnxruntime等等 Mobile：移动端PyTorch实现方案及资源。 Blog：PyTorch相关新闻。 Tutorials：案例教程，这里面都是个人提供的、针对某一个应用的demo级的教程。包含如下方向，对于新手来说，可以看一下，了解个大概，但里面的代码多是demo，无法开箱即用于项目应用，这也是本书第二部分将会弥补的地方，敬请期待。 Docs：PyTorch API官方文档, 这也是我一直首推的学习资料，PyTorch的文档非常友好，可以查阅不同版本，各个API都有详细介绍，大多都有代码案例，PyTorch的基础部分主要从这里开始进行讲解。Docs下还会分PyTorch、torchvision、torchaudio、torchtext等，大家需要针对性的检索。 Resource：这里包含各种资源，如社区、新闻报道、论坛、ModelHub资源等等。 PyTorch发展趋势 为什么要学PyTorch？ 因为PyTorch发展迅猛，已经在多方面荣登深度学习框架第一的宝座，学术界绝大多数论文都有PyTorch实现，想要紧跟技术，利用新模型进行科学研究，进行项目开发的，不得不跟随学术界的趋势，所以可以看到PyTorch席卷各界。 PyTorch称王，TensorFlow答应么？一起来看看几个数据。 图1： 各大顶会期刊中，使用PyTorch的论文数量占PyTorch+TensorFlow的百分比。其实就是 p / (p+t)，这里有一个分界点就是50%，当达到50%时，说明PyTorch与TensorFlow平分秋色，当大于50%时说明PyTorch已经超过TF，而当数据超过75%，表明PyTorch已经是TF的两倍。从这个趋势可以发现转折点在2018-2019年之间发生，现在已经2021年末了，哪个框架是学术界的带头大哥？ 图2：这幅图对比的是PyTorch与TF的决定数量，可以看到TF的份额被PyTorch一步步蚕食，实线代表的PyTorch持续上扬，TF的虚线不断下探。 图片出自：https://horace.io/pytorch-vs-tensorflow/ 通过学术界的论文情况就可以说明PyTorch是未来的大势所趋，虽然说早期PyTorch在工业部署上并不如TensorFlow，但是如今PyTorch推出了libtorch，TorchServe，以及各类优秀的，适配性良好的部署框架层出不穷，如TensorRT、OpenVINO、ONNX等，都可以帮助PyTorch进行快速部署 感觉PyTorch是得学术界得天下，先让科研工作者用爽了，新模型都是PyTorch实现的，工业界的朋友总不能不用最新的算法、模型吧，只能纷纷转向PyTorch了。因此，相信大家选择使用PyTorch进行深度学习、机器学习模型开发，一定能加速你的算法模型开发，也印证了PyTorch的主旨——“An open source machine learning framework that accelerates the path from research prototyping to production deployment.” Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年04月26日21:48:10 "},"chapter-1/1.2-Anaconda.html":{"url":"chapter-1/1.2-Anaconda.html","title":"1.2 环境配置之Anaconda","keywords":"","body":"1.2 环境配置之Anaconda 工欲善其事必先利其器，想要使用PyTorch进行模型开发，必须要搭建好开发环境。听到环境安装，是否大家已经瑟瑟发抖？是否都被某些不知名的报错卡住好几天，百度各种搜不到答案，各种文章的方案都不适用？ 为了解决大家环境安装的苦恼，本章将从Python虚拟环境、Anaconda、Pycharm、CUDA、CuDNN的背景说起，给大家构建系统的认识，理清各软件之间的关系，为大家呈现一个清晰的、完整的开发环境配置。 1.1节中提到过，PyTorch是基于Python为接口提供给用户使用，因此Python语言是我们的核心，PyTorch对于python只是一个工具包（library），通过import torch的方式使用而已。因此想要搭建完整的PyTorch开发环境，其实是搭建完整的Python开发环境，同时安装上PyTorch这个工具库。 虚拟环境 为了使用PyTorch，先搞定Python环境安装。提到Python环境，就不得不讲python虚拟环境（virtual environment）的概念了。python虚拟环境是为了解决众多的工具包之间版本冲突而设计的一个纯净开发环境，简单地，可创建多个虚拟环境，不同的环境中使用不同的工具包，例如虚拟环境1中安装pytorch 1.6， 虚拟环境2中安装的是pytorch0.4，当需要用老版本pytorch时，切换到虚拟环境2，然后调用虚拟环境2中的解释器——python.exe 运行你的.py代码。当需要用pytorch1.6时，就切换到虚拟环境1，调用虚拟环境1中的python.exe运行代码。这样就很好的解决工具包版本冲突问题。 解释器 这里提到一个概念，解释器——python.exe。 解释器就是人类与CPU之间的桥梁，人写的高级语言，如print(\"Hello World\")，CPU是读不懂的，CPU只能读0/1形式的二进制文件，这时就需要一个翻译官——python.exe， python.exe读取.py文件，解释成二进制文件，让CPU读懂，并运行。这就是解释器的作用，更直观的例子，python3的解释器是无法翻译python2语法的语句print \"Hello World\"的，因此不同的python.exe其实就对应了不同的环境。 Anaconda Anaconda是为方便使用python而建立的一个软件包，其包含常用的250多个工具包，多版本python解释器和强大的虚拟环境管理工具，所以Anaconda得名python全家桶。Anaconda可以使安装、运行和升级环境变得更简单，因此使用它作为Python虚拟环境管理工具。 安装非常简单，首先进入 anaconda官网，点击“Get Started\", 点击”download anaconda installers“，看到如下图所示的信息，选择你对应的操作系统下载，安装即可。 安装完毕，可以尝试创建一个你的虚拟环境，这里需要注意创建环境的时候就要决定pyhon的版本，而pytorch的安装对python的版本有要求，所以大家先到pytorch官网看看要装的pytorch版本所支持的python版本，然后再回来创建虚拟环境。这里演示pytorch最新版本1.10的安装。由于1.10是支持python3.6/3.7/3.9的（通过 1.1介绍过的神奇网站找到信息），在这里用python3.6作为python版本进行创建虚拟环境。 >>> conda create -n pytorch-1.10-gpu python=3.6 这里的pytorch-1.10-gpu就是虚拟环境的名称，激活（activate）时的标识，同时也会在anaconda安装目录下创建pytorch-1.10-gpu的文件夹，在该文件夹存放本环境所有工具包、解释器，如下图所示： 虚拟环境创建好之后，可以看看这个文件夹里都有些什么，先来看解释器： D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\python.exe ，大家可以双击它，就可以看到解释器的相关信息，后续用到pytorch_1.10_gpu这个环境的时候，也是用这个.exe进行运行.py文件，后面用pycharm运行代码的时候会给大家callback。 到此，一个纯净的虚拟环境就创建好了，接下来需要激活（activate）这个环境，然后再里面进行各种工具包的安装。这里先暂停一下，先去看另外一个工具——Pycharm的安装及使用。 anaconda常用命令 创建环境：conda create -n your_env_name python=X.X （X.X为python版本） eg: conda create -n pytorch_tutorial python=3.7 激活环境：source activate your_env_name eg: source activate pytorch_tutorial 退出环境：source deactivate 删除环境：conda remove -n your_env_name –all eg: conda remove -n pytorch_tutorial --all 查看已有虚拟环境：conda env list / conda info -e （推荐大家自行了解更多anaconda命令） 有了anaconda帮助我们管理虚拟环境以及python工具包，接下来就可以安装IDE，用来管理项目了。请看Pycharm安装 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年04月26日21:48:10 "},"chapter-1/1.3-Pycharm.html":{"url":"chapter-1/1.3-Pycharm.html","title":"1.3 环境配置之Pycharm","keywords":"","body":"1.3 环境配置之Pycharm Pycharm——强大的python IDE Pycharm——强大的python IDE，拥有调试、语法高亮、Project管理、代码跳转、智能提示、版本控制等功能。有社区版和专业版区分，社区版为免费的，专业版需要付费，不过在校学生可通过edu邮箱进行注册，获取免费的专版使用。当然大家可以有其他方法完成购买。专业版相对于社区版功能更丰富一些，这里我采用的是pycharm.2019专业版，基础功能没有大的区别，用于演示还是OK的。 Pycharm的安装： 官网下载安装包 https://www.jetbrains.com/pycharm/ 运行pycharm-professional-2019.2.exe 选择路径，勾选Add launchers dir to the PATH，等待安装完成 激活部分：略。 这里主要讲如何创建项目，以及关联前面创建的虚拟环境pytorch_1.10_gpu。 打开pycharm，左上角的File可选择New，或者Open，如果已经有一个文件夹下有相关.py代码，那么就用Open对应的文件夹即可。这里假设已经存在pytorch-tutorial-2nd文件夹，找到它，Open即可。 我们找到pytorch-tutorial-2nd\\code\\chapter-1\\01-hello-pytorch.py，发现import torch下面有个红色波浪线，鼠标放上去会提示“No Module named torch\"，表明当前环境里并没有torch这个工具包。可好像我们并没有为当前.py文件设定好用哪个一解释器不是？所以我们先将当前项目pytorch-tutorial-2nd的虚拟环境设置为刚刚创建好的pytorch_1.10_gpu，然后再在pytorch_1.10_gpu里安装上pytorch即可。 左上角File--> Settings-->Project:pytorch-tutorial-2nd-->Project Interpreter， 然后如下图找到对应的python.exe，之后选中，点击OK,再次点击OK。就完成了虚拟环境与项目的关联，接着就可以安装pytorch了。 到这里，大家可以尝试运行 pytorch-tutorial-2nd\\code\\chapter-1\\01-hello-pytorch.py，会提示 D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\python.exe E:/pytorch-tutorial-2nd/code/chapter-1/01-hello-pytorch.py Traceback (most recent call last): File \"E:/pytorch-tutorial-2nd/code/chapter-1/01-hello-pytorch.py\", line 9, in import torch ModuleNotFoundError: No module named 'torch' Process finished with exit code 1 这里是完整的Pycharm控制台信息，我们可以看到第一行先是解释器（即对应了我们创建的虚拟环境），然后是执行的.py文件，接着是报错信息，提示没有torch这个module，下一小节我们来就来安装这个module。 pycharm拓展 pycharm是很好用的IDE，这里面提供很多快捷键，希望大家可以熟悉使用这些快捷键，例如常用的 批量注释：Ctrl + / 快速查看文档：Ctrl + q 搜索：Ctrl+f 运行：Shift + F10 Tab / Shift + Tab 缩进、不缩进当前行 Ctrl + D 复制选定的区域或行 Ctrl + Y 删除选定的行 更多功能推荐大家自行了解一下pycharm的基础使用，相信它一定是你的高效生产力。pycharm也有一些出名的教程，例如《pycharm 中文指南》pycharm中文指南。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年04月26日21:48:10 "},"chapter-1/1.4-CUDA&cuDNN.html":{"url":"chapter-1/1.4-CUDA&cuDNN.html","title":"1.4 环境配置之CUDA&cuDNN","keywords":"","body":"1.4 环境配置之CUDA&cuDNN 有了python环境，有了开发环境，下面马上到主角登场。PyTorch登场前，针对GPU版，还需要额外安装一些东西。 从1.1我们知道PyTorch的安装可根据设备类型分为GPU版或CPU版。 CPU 对于CPU版本直接通过pip或者anaconda命令安装即可，如： >>> pip3 install torch torchvision torchaudio 具体的命令可查阅：https://pytorch.org/get-started/locally/ 官网上给出的命令其实安装了3个包，分别是torch, torchvision,torchaudio，这命令会根据当前系统自动选择对应python版本的whl进行安装，不需要用户操心。但，如果网速不好，或者需要离线安装，这时可以考虑下载whl包然后自行安装，下载whl的链接：https://download.pytorch.org/whl/torch/ pytorch与torchvision版本匹配 若是手动下载的whl，需要注意pytorch与torchvision之间版本对应关系，这个可以到torchvision Github查看，这点非常重要，CV中一些报错就是因为torchvision与pytorch版本不匹配导致的。这里就copy过来，大家参考好了。 torch torchvision python main / nightly main / nightly >=3.6, 1.10.0 0.11.1 >=3.6, 1.9.1 0.10.1 >=3.6, 1.9.0 0.10.0 >=3.6, 1.8.2 0.9.2 >=3.6, 1.8.1 0.9.1 >=3.6, 1.8.0 0.9.0 >=3.6, 1.7.1 0.8.2 >=3.6, 1.7.0 0.8.1 >=3.6, 1.7.0 0.8.0 >=3.6, 1.6.0 0.7.0 >=3.6, 1.5.1 0.6.1 >=3.5, 1.5.0 0.6.0 >=3.5, 1.4.0 0.5.0 ==2.7, >=3.5, 1.3.1 0.4.2 ==2.7, >=3.5, 1.3.0 0.4.1 ==2.7, >=3.5, 1.2.0 0.4.0 ==2.7, >=3.5, 1.1.0 0.3.0 ==2.7, >=3.5, 0.2.2 ==2.7, >=3.5, 举一反三，torchaudio、torchtext同理。 GPU版本 深度学习能火，正式因为有了强大的GPU支撑，自然地，绝大多数情况下我们会安装GPU版本的pytorch。目前PyTorch不仅支持NVIDIA的GPU，还支持AMD的ROMc的GPU。不过我们还是以N卡为例，毕竟N卡还是主流，A卡仍需努力。 对于N卡，什么型号是pytorch支持的呢？首先，需要计算能力（compute capability）≥3.0的GPU。很多地方都会看到计算能力≥3.0，理论出自哪呢？ 我在官方文档里找到了出处文档 It has a CUDA counterpart, that enables you to run your tensor computations on an NVIDIA GPU with compute capability >= 3.0 那么问题来了，怎么知道自己的GPU的copute capability呢？请看NVIDA文档,选择你对应的系列，找到对应型号。 举几个例子： GPU 计算能力 GeForce RTX 2080 7.5 GeForce RTX 2070 7.5 GeForce RTX 2060 7.5 GeForce GTX 1080 6.1 GeForce GTX 1070 6.1 GeForce GTX 1060 6.1 其实，只要是近几年购买的N卡都是没有问题的。确定了显卡是支持的，接下来就要决定一个非常重要事情，就是选中对应的CUDA版本进行安装。 CUDA ​ CUDA(ComputeUnified Device Architecture)，是NVIDIA推出的运算平台。 CUDA是一种由NVIDIA推出的通用并行计算架构，该架构使GPU能够解决复杂的计算问题。 与之配套的是cuDNN, NVIDIA cuDNN是用于深度神经网络的GPU加速库。它强调性能、易用性和低内存开销。NVIDIA cuDNN可以集成到更高级别的机器学习框架中。 细心的朋友在PyTorch官网就能发现， Compute Platform中并不给出显卡型号，而是给出CUDA版本，这就要求我们安装特定版本的CUDA，才能使用特定版本的PyTorch。例如PyTorch 1.10 只支持CUDA 10.2, CUDA 11.3，以及CUDA 11.1。为什么这里用了以及呢？ 因为在官网上并没有显示CUDA 11.1，但是在https://download.pytorch.org/whl/torch，搜索，可以看到11.1的whl。 在这里选择的是10.2版本进行安装，CUDA下载通过官网，官网通常只显示最新版本cuda，这里需要大家进入具体的版本下载界面，拖到底部，找到： Archive of Previous CUDA Releases 接着可以找到对应的CUDA版本，进入下载即可，这Installer Type 有 exe (network) 和 exe (local)两种选择，我们选local的方式，下载2.6G的cuda_10.2.89_441.22_win10.exe即可。 安装方式十分简单，一直下一步即可，只需要记住安装到了哪里，这里默认路径为 C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2 下面来测试一下CUDA安装是否成功，可以打开命令窗，进入C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2\\bin，然后输入 nvcc -V cuDNN 有了CUDA平台，还需要安装cuDNN，cuDNN全称为NVIDIA CUDA Deep Neural Network (cuDNN) 。它是一个深度神经网络的加速库，里边实现了神经网络常用的操作，并且是高度优化的，可以极大地榨干NVIDA显卡的性能，因此用N卡都会用cuDNN库。 cuDNN库的安装非常简单，与其说是安装，不如说是下载库文件，放到CUDA所在的目录下。具体步骤如下： 打开网址：https://developer.nvidia.com/cudnn，点击右上角，需要注册，再登录。 登录后，点击Download cuDNN，跳转到下载页面，选择好cudnn版本，操作系统版本，即可开始下载 将下载好的压缩包cudnn-10.2-windows10-x64-v8.2.4.15.zip 解压 分别将bin、include、lib\\x64下的文件分别对应拷贝到C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2文件夹下的bin、include、lib\\x64下 打开命令窗口，在C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2\\extras\\demo_suite文件夹中分别执行bandwidthTest.exe和deviceQuery.exe。观察到Result=PASS即可 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年04月26日21:48:10 "},"chapter-1/1.5-PyTorch-install.html":{"url":"chapter-1/1.5-PyTorch-install.html","title":"1.5 环境配置之PyTorch系列包","keywords":"","body":"1.5 环境配置之PyTorch系列包 虚拟环境，Pycharm，CUDA，cuDNN均已准备好，现在终于可以安装PyTorch了，加油，就快成功啦。 现在，通过命令窗口，进入（激活）虚拟环境 E:\\pytorch-tutorial-2nd>conda activate pytorch_1.10_gpu (pytorch_1.10_gpu) E:\\pytorch-tutorial-2nd> 可通过以下命令安装 pip3 install torch==1.10.1+cu102 torchvision==0.11.2+cu102 torchaudio===0.10.1+cu102 -f https://download.pytorch.org/whl/cu102/torch_stable.html 可以看到通过pip安装，也是下载我们提到的神奇网站里的whl文件，这时大家可以根据自己的网速决定是采用pip还是自行下载的方法。 如果网速不好的话，推荐通过神奇的网站——https://download.pytorch.org/whl/torch 搜索对应的whl进行下载。然后pip install *.whl就行。 对于pip，建议大家添加镜像源。例如，清华镜像源或者中科大镜像源，这样安装python工具包的下载速度会快很多，请自行百度如何添加清华镜像源。 安装完毕，再回到pycharm，运行 pytorch-tutorial-2nd\\code\\chapter-1\\01-hello-pytorch.py，可以看到 D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\python.exe E:/pytorch-tutorial-2nd/code/chapter-1/01-hello-pytorch.py Hello World, Hello PyTorch 1.10.1+cu102 CUDA is available:True, version is 10.2 device_name: NVIDIA GeForce GTX 1660 Ti with Max-Q Design Process finished with exit code 0 表示pytorch环境安装完毕，此时我们也可以再次打开pycharm的解释器配置，可以看到当前的解释器（虚拟环境）下，拥有的相关工具包，这个界面也是后续大家检查当前环境工具包版本常用的工具，请收藏。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年04月26日21:48:10 "},"chapter-1/1.6-JupyterNotebook-install.html":{"url":"chapter-1/1.6-JupyterNotebook-install.html","title":"1.6 环境配置之Jupyter Notebook","keywords":"","body":"1.6 环境配置之Jupyter Notebook 什么是 jupyter notebook 经过前几个小节，大家已经具备了PyTorch开发环境，但本教程需要照顾初学者使用代码，让刚入门的同学有更好的代码学习体验。因此，在上篇，主要采用Jupyter Notebook进行代码演示。 注意：\"Notebook只建议用于学习目的，不建议用于项目开发\" * 3， 重要事说三遍！ 为什么？这是由于notebook自身定位决定的，先来看看jupyter notebook 的定义“The Jupyter Notebook is a web application for creating and sharing documents that contain code, visualizations, and text. It can be used for data science, statistical modeling, machine learning, and much more.”——官网 Jupyter notebook 是一个网页应用，在这个网页上可以编写代码、做可视化、写文本，这就是非常好的教学展示平台。可以在上面进行概念描述、配上代码、运行结果，并且可以按小段进行代码运行，给用户更多的交互体验，便于用户理解代码细节。 基于此，上篇主要采用notebook进行代码讲解，到了中篇，基于完整的项目代码框架进行应用开发。 关于jupyter与jupyter notebook的关系，请大家查看官网（以下开始，notebook 指代 jupyter notebook） notebook 运行逻辑 notebook不是一个简单的web应用程序，它还需要关联指定的kernel，用于执行我们的代码。相信刚接触notebook的朋友大多都被notebook, kernel的概念搞的一头雾水。如果上述概念理不清楚，就更不清楚如何配置kernel，选择指定的虚拟环境了。 下面，我们先来看看notebook的结构 图片来自官网 图中左边是用户写的代码，传输到中间的Jupyter server, server本身不能执行代码（python.exe干的活，server是不会的），server把代码传给Kernel，Kernel才是真正干活，执行代码的地方。Kernel执行完代码，把结果返回给server，再返回到用户的网页。 从图中可以看出Kernel不仅可以是python.exe，也可以是其他语言的解释器，如Julia, R等，更多kernel可以看支持的kernel列表. 通过上述示意图我们就知道了，在pytorch开发中，kernel其实就是某一个python解释器——python.exe，我们需要让当前的notebook启用对应的kernel，来进入相应的虚拟环境，这样才能运行代码。 notebook 安装 理清概念，下面进行notebook安装，我们续期是正确调用pytorch_1.10_gpu这个虚拟环境来执行notebook上的代码。 安装过程分3步： 进入虚拟环境：conda activate pytorch_1.10_gpu 安装ipykernel工具包（安装jupyter）: pip install jupyter 添加kernel到notebook： python -m ipykernel install --user --name pytorch_1.10_gpu (意思是，将python这个kernel添加到jupyter的kernel中，由于当前已经在虚拟环境中，所以第一个python表示的含义是：D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\python.exe；而pytorch_1.10_gpu是kernel的别名，用于区分不同的kernel，这里建议与虚拟环境名称保持一致就好) 启动 在命令窗中执行jupyter notebook就可以打开web应用了，网址为:http://localhost:8888; 这里默认端口为8888，如果你再次启动一个jupyter notebook，可以看到端口号变为了8889，即它是另外一个web服务。 进入之后，我们可以看到有一个/目录，我们需要找到我们的notebook文件进行打开，这里有一个小技巧，就是进入到指定文件夹后，再运行notebook，这样notebook的路径就进入了想要的文件夹。 配置kernel 我们进入 chapter-1/02-notebook-demo.ipynb，点击run，可发现如下报错 --------------------------------------------------------------------------- ModuleNotFoundError Traceback (most recent call last) in 7 \"\"\" 8 ----> 9 import torch 10 11 print(\"Hello World, Hello PyTorch {}\".format(torch.__version__)) ModuleNotFoundError: No module named 'torch' 告诉我们找不到torch这个包，这很明显，使用的kernel不是我们的D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\python.exe。 下面我们来设置一下，方法很简单： 再次运行，可看到以下信息，表明notebook的环境就配置好了。 Hello World, Hello PyTorch 1.10.1+cu102 CUDA is available:True, version is 10.2 device_name: NVIDIA GeForce GTX 1660 Ti with Max-Q Design 实用插件——jupyter_contrib_nbextensions 原生的notebook还是缺点意思，这里推荐大家安装jupyter_contrib_nbextensions插件，jupyter_contrib_nbextensions提供了非常丰富的功能，例如代码折叠、分段折叠、代码自动补全、字体大小、行号显示、目录索引等等，详见下图 插件安装十分简单，打开命令窗，进入虚拟环境，分别依次执行 : pip install jupyter_contrib_nbextensions jupyter contrib nbextension install --user 然后重启notebook，就可以看到导航栏里有Nbextensions，大家可以根据自己的喜好进行调整，更多内容请查看Github Notebook 快速上手 notebook所使用的文件格式为.ipynb，jupyter会将.ipynb转为json进行保存，这样便于版本记录以及分享。 例如下图是用sublime打开的 02-notebook-demo.ipynb 下面，我们来研究notebook界面和常用的操作。 界面中需要认识的几个模块分别是：菜单栏、工具栏、单元格（cell） 菜单栏：用得最多的是Kernel，用于中断程序、重启解释器环境、切换解释器等；其它按键顾名思义。 工具栏：一些功能的按钮，高手都是用快捷键的。 单元格：这就是承载信息的地方，cell可分为code cells, markdown cells, raw cells。用得最多的是code cells和markdown cells。 右上角有一个小圆圈，用于观察当前kernel运行状态，如果是实心的，表明kernel正在运行某个cell，被运行的cell以及等待运行的cell的左边会有一个* notebook 的两种模式 Notebook中的单元，有两种模式：命令模式(Command Mode)与编辑模式(Edit Mode)，在不同模式下我们可以进行不同的操作。 命令模式：cell的边框为蓝色，此时可对cell进行操作。在编辑模式下，按esc键进入命令模式。 编辑模式：cell的边框为绿色，此时可在单元格内编辑代码或文档。在命令模式下，按enter或return键进入编辑模式。 常用快捷键 在命令模式下，按下“h”键，就会弹出快捷键的介绍，但是太多了，不方便初学者使用，这里总结一些常用的，实用的快捷键供大家参考。 命令模式： 插入单元格： A 键上方插入，B 键在下方插入 合并单元格：选中多个单元格，Shift + M 显示行号：L 删除单元格：连续按两次D 剪切单元格：X。 通常我用X代替删除，毕竟只用按一个键，哈哈。 复制粘贴单元格： C/V 撤销删除的单元格：要撤消已删除的单元格，请按 Z 键 编辑模式： 运行单元格：Ctrl + Enter 运行并创建新单元格：Alt + Enter 分割单元格：光标放到想要分割的地方，Ctrl + Shift + - 函数详情：Shift+Tab （注意，要把模块导入才会提示函数详情！） 请大家将以上快捷键都试用一遍，这些是高频快捷键，下面给大家列举所有快捷键，请收藏。 下面再介绍两个神奇操作，分别是在单元格中执行shell命令以及magic操作。 请自行尝试!+shell命令进行体会。 magic commands Magic关键字是 IPython 的高级用法，如%matplotlib将matplolib设置为交互式 %和%%分别代表 行Magic命令 和 单元格Magic命令 演示一个魔法命令 %%timeit %%timeit a = [] for i in range(10): a.append(i) 858 ns ± 50.3 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) 表示将代码段运行了100万次，并统计运行时间。 更多更全的magic commands请看这里Jupyter 魔术命令（magic commands） 更多奇淫技巧推荐大家看看Jupyter Notebook 有哪些奇技淫巧？ 更多官方信息请查看Jupyter Notebook docs Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年04月26日21:48:10 "},"chapter-2/":{"url":"chapter-2/","title":"第二章 PyTorch 核心模块","keywords":"","body":"第二章 PyTorch 核心模块 上一章，对PyTorch的历史进行介绍，对开发环境的安装进行了详细的讲解。 本章将对PyTorch代码结构进行梳理，介绍核心模块，为后面应用PyTorch打下基础。 第二章 PyTorch 核心模块 2.1 PyTorch 模块结构 2.2 新冠肺炎分类 2.3 核心数据结构——Tensor 2.4 张量的相关函数 2.5 自动求导核心——计算图 2.6 Autograd——自动微分 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年04月26日21:48:10 "},"chapter-2/2.1-module-tree.html":{"url":"chapter-2/2.1-module-tree.html","title":"2.1 PyTorch 模块结构","keywords":"","body":"2.1 PyTorch 模块结构 上一章安装好的PyTorch是一个庞大的python库，里边包含几十个模块，这一小节就来了解都有哪些模块，每个模块代码在哪里，对应文档在哪里。从而帮助大家具象化PyTorch，清楚地知道所用的PyTorch函数、模块都在哪里，是如何调用的。 你的代码在哪？ 很多朋友应该都用过pip/conda install 进行一键安装，但你的工具库代码装到哪里并不清楚。使用的时候也知道import *，但具体引用的功能函数又是如何实现的，是模糊的。 为了让大家知道自己调用的是什么，我们先来看你安装的pytorch在哪里。上一章案例中，我们装的pytorch在：D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\Lib\\site-packages\\torch 如果pycharm中配置好了虚拟环境，大家也可以通过pycharm的快捷键，快速定位到这个文件夹。方法是，找到import torch这一行代码，按住Ctrl键，鼠标左键单击torch，就可以跳转到D:\\Anacondadata\\envs\\pytorch1.10_gpu\\Lib\\site-packages\\torch__init.py 文件。 可以看到torch文件夹中有一系列子文件夹，我们平时常用的函数都藏在这里面了，下面挑些重点注意介绍。 _pycache_ 该文件夹存放python解释器生成的字节码，后缀通常为pyc/pyo。其目的是利用空间换时间，对应的模块直接读取pyc文件，而不需再次将.py语言转换为字节码的过程，从此节省了时间。 从文件夹名称可知，它是一个cache，缓存，如果需要，我们当然可以删掉它。更多关于pycache的内容，建议额外阅读：https://www.python.org/dev/peps/pep-3147/#proposal _C 从文件夹名称就知道它和C语言有关，其实它是辅助C语言代码调用的一个模块，该文件夹里存放了一系列pyi文件，pyi文件是python用来校验数据类型的，如果调用数据类型不规范，会报错。更多pyi知识，请查阅PEP 8 -->.pyi files that are read by the type checker in preference of the corresponding .py files. PyTorch的底层计算代码采用的是C++语言编写，并封装成库，供pytorch的python语言进行调用。这点非常重要，后续我们会发现一些pytorch函数无法跳转到具体实现，这是因为具体的实现通过C++语言，我们无法在Pycharm中跳转查看。 include 上面讲到pytorch许多底层运算用的是C++代码，那么C++代码在哪里呢？ 它们在这里,在torch/csrc文件夹下可以看到各个.h/.hpp文件，而在python库中，只包含头文件，这些头文件就在include文件夹下。 lib torch文件夹最重*3的一个模块，torch文件夹占3.2GB，98%的内容都在lib中，占了3.16GB。啥？装了那么大的pytorch，几乎都在lib里面了，倒要看看里面是什么宝贝。 lib文件夹下包含大量的.lib .dll文件（分别是静态链接库和动态链接库），例如大名鼎鼎的cudnn64_7.dll（占435MB）， torch_cuda.dll（940MB）。这些底层库都会被各类顶层python api调用。这里推荐大家自行了解什么是静态链接库和动态链接库。 autograd 该模块是pytorch的核心模块与概念，它实现了梯度的自动求导，极大地简化了深度学习研究者开发的工作量，开发人员只需编写前向传播代码，反向传播部分由autograd自动实现，再也不用手动去推导数学公式，然后编写代码了（很多朋友可能不知道，在早期的深度学习框架中是没有这个功能的，例如caffe，它需要手动编写反向传播的公式代码） nn 相信这个模块是99%pytorch开发者使用频率最高的模块，搭建网络的网络层就在nn.modules里边。nn.modules也将作为一章独立展开。我们可以到D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\Lib\\site-packages\\torch\\nn\\modules里面看看是否有你熟悉的网络层？ onnx pytorch模型转换到onnx模型表示的核心模块，进入文件夹可以看到大量的opset**.py， 这里留下一个问题，各版本opset是什么意思？有什么区别？ optim 优化模块，深度学习的学习过程，就是不断的优化，而优化使用的方法函数，都暗藏在了optim文件夹中，进入该文件夹，可以看到熟悉的优化方法：adam、sgd、asgd等。以及非常重要的学习率调整模块：lr_scheduler.py。本模块也将采用独立一章进行详细剖析。 utils utils是各种软件工程中常见的文件夹，其中包含的是各类常用工具，其中比较关键的是data文件夹，tensorboard文件夹，这些都将在后续章节详细展开。第三章将展开data里的dataloader与dataset等数据读取相关的模块。 其他文件夹不再一一介绍，大家可以到官方文档查看。 以上是torch库，针对不同的应用方向，pytorch还提供了torchvision\\torchtext\\torchaudio等模块，本书重点对torchvision进行剖析，其它两个模块类似。 torchvision 同理，我们来到D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\Lib\\site-packages\\torchvision文件夹下看看有什么模块。 datasets 这里是官方为常用的数据集写的数据读取函数，例如常见的cifar, coco, mnist,svhn,voc都是有对应的函数支持，可以愉快的调用轮子，同时也可以学习大牛们是如何写dataset的。 models 这里是宝藏库，里边存放了经典的、可复现的、有训练权重参数可下载的视觉模型，例如分类的alexnet、densenet、efficientnet、mobilenet-v1/2/3、resnet等，分割模型、检测模型、视频任务模型、量化模型。这个库里边的模型实现，也是大家可以借鉴学习的好资料，可以模仿它们的代码结构，函数、类的组织。 ops 视觉任务特殊的功能函数，例如检测中用到的 roi_align, roi_pool，boxes的生成，以及focal_loss实现，都在这里边有实现。 transforms 数据增强库，相信99%的初学者用到的第一个视觉数据增强库就是transforms了，transforms是pytorch自带的图像预处理、增强、转换工具，可以满足日常的需求。但无法满足各类复杂场景，因此后续会介绍更强大的、更通用的、使用人数更多的数据增强库——Albumentations。 通过torchvision\\transforms\\transforms.py , 可以看到 torchvision包含了这些功能。 __all__ = [\"Compose\", \"ToTensor\", \"PILToTensor\", \"ConvertImageDtype\", \"ToPILImage\", \"Normalize\", \"Resize\", \"Scale\", \"CenterCrop\", \"Pad\", \"Lambda\", \"RandomApply\", \"RandomChoice\", \"RandomOrder\", \"RandomCrop\", \"RandomHorizontalFlip\", \"RandomVerticalFlip\", \"RandomResizedCrop\", \"RandomSizedCrop\", \"FiveCrop\", \"TenCrop\", \"LinearTransformation\", \"ColorJitter\", \"RandomRotation\", \"RandomAffine\", \"Grayscale\", \"RandomGrayscale\", \"RandomPerspective\", \"RandomErasing\", \"GaussianBlur\", \"InterpolationMode\", \"RandomInvert\", \"RandomPosterize\", \"RandomSolarize\", \"RandomAdjustSharpness\", \"RandomAutocontrast\", \"RandomEqualize\"] 通过上面的内容，相信大家对所安装的代码结构有了清晰认识，也知道自己将调用的代码函数都在哪里，已经为下一步工作打好基础，下一节我们极简的代码，完成第一个深度学习任务—— 新冠肺炎X光分类 。其目的在于为大家搭建模型训练框架，构建各模块的认识，为后续核心模块讲解铺平道路。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年04月26日21:48:10 "},"chapter-2/2.2-covid-19-cls.html":{"url":"chapter-2/2.2-covid-19-cls.html","title":"2.2 新冠肺炎分类","keywords":"","body":"2.2 新冠肺炎X光分类 上一节，我们学习了pytorch python API的结构，本节将以一个具体的案例介绍pytorch模型训练流程，并提出一系列问题，供大家思考。当然，这些问题也是本书后续章节一一解答的内容。 相信绝大多数朋友接触过或者看到的第一个Hello Word级图像分类都是Mnist，思来想去觉得还是换点东西，于是选择了当下与所有人都息息相关的案例——新型冠状病毒肺炎（Corona Virus Disease 2019，COVID-19），简称“新冠肺炎”。关于新冠的背景，已经无需多言，口罩、绿码、核酸检测已经融入了我们的生活。因此，想让大家更进一步的了解COVID-19，所以选用此案例。当然，最重要的目的是要了解pytorch如何完成模型训练。 案例背景 2020年1月底2月初的时候，新冠在国内/外大流行。而确定一个人是否感染新冠肺炎，是尤为重要的事情。新冠肺炎的确诊需要通过核酸检测完成，但是核酸检测并不是那么容易完成的，需要医护人员采样、送检、PCR仪器上机、出结果、发报告等一系列复杂工序，核酸检测产能完全达不到当时的检测需求。当时，就有医生提出，是否可以采用特殊方法进行诊断，例如通过CT、X光的方法，给病人拍个片，几分钟就能看出结果，比核酸检测快了不少。于是，新冠肺炎患者的胸片X光数据就不断的被收集，并发布到网上供全球科学家使用，共同抗击新冠疫情。这里就采用了https://github.com/ieee8023/covid-chestxray-dataset上的数据，同时采用了正常人的X光片，来自于：https://github.com/zoogzog/chexnet。 由于本案例目的是pytorch流程学习，因此数据仅选择了4张，分为2类，正常与新冠，训练集2张，验证集2张。标签信息存储于txt文件中。具体目录结构如下： ├─imgs │ ├─covid-19 │ │ auntminnie-a-2020_01_28_23_51_6665_2020_01_28_Vietnam_coronavirus.jpeg │ │ ryct.2020200028.fig1a.jpeg │ │ │ └─no-finding │ 00001215_000.png │ 00001215_001.png │ └─labels train.txt valid.txt 建模思路 这是一个典型的图像分类任务，这里采用面向过程的思路给大家介绍如何进行代码编写。 step 1 数据 首先，需要编写代码完成数据的读取，变成模型能够读取的格式。这里涉及pytorch的dataset，dataloader，transforms等模块。以及需要清楚地知道pytorch的模型需要怎样的格式？数据模块需要完整的工作大体如下图所示： 首先，需要将数据在硬盘上的信息，如路径，标签读取并存储起来，然后被使用，这一步骤主要是通过COVID19Dataset这个类。类里有四个函数，除了Dataset类必须要实现的三个外，我们通过get_img_info函数实现读取硬盘中的路径、标签等信息，并存储到一个列表中。后续大家可以根据不同的任务情况在这个函数中修改，只要能获取到数据的信息，供\\_getitem__函数进行读取。 接着，使用dataloader进行封装，dataloader是一个数据加载器，提供诸多方法进行数据的获取，如设置一个batch获取几个样本，采用几个进程进行数据读取，是否对数据进行打乱等功能。 其次，还需要设置对图像进行预处理(Preprocess)的操作，这里为了演示，仅采用resize 和 totensor两个方法，并且图片只需要缩放到8*8的大小，并不需要224,256,448,512,1024等大尺寸。(totensor与下一小节内容强相关) step 2 模型 数据模块构建完毕，需要扔到模型里，因此我们需要构建神经网络模型，模型接收数据并前向传播处理，输出二分类概率向量。这时就需要用到nn.Module模块和nn下的各个网络层进行搭建模型，模型的搭建就像搭积木，一层一层的摞起来。模型完成的任务就如下图所示：下图示意图是一张分辨率为4*4的图像输入到模型中，模型经过运算，输出二分类概率。中间的“?\"是什么内容呢？ 这里，“？”是构建一个极其简单的卷积神经网络，仅仅包含两个网络层，第一个层是包含1个33卷积核的2d卷积，第二个层是两个神经元的全连接层（pytorch也叫linear层）。模型的输入被限制在了8\\8，原因在于linear层设置了输入神经元个数为36， 8*8与36之间是息息相关的，他们之间的关系是为何呢？这需要大家对卷积层有一定了解了。（大家可以改一下36，改为35，或者transforms_func中的resize改为9*9，看看会报什么错，这些错或许是大家今后经常会遇到的） step3 优化 模型可以完成前向传播之后，根据什么规则对模型的参数进行更新学习呢？这就需要损失函数和优化器的搭配了，损失函数用于衡量模型输出与标签之间的差异，并通过反向传播获得每个参数的梯度，有了梯度，就可以用优化器对权重进行更新。这里就要涉及各种LossFunction和optim中的优化器，以及学习率调整模块optim.lr_scheduler。 这里，采用的都是常用的方法：交叉熵损失函数（CrossEntropyLoss）、随机梯度下降法（SGD）和按固定步长下降学习率策略（StepLR）。 step4 迭代 有了模型参数更新的必备组件，接下来需要一遍又一遍的给模型喂数据，并且监控模型训练状态，这时候就需要for循环登场，不断的从dataloader里取出数据进行前向传播，反向传播，参数更新，观察loss、acc，周而复始。当达到满足的条件，如最大迭代次数、某指标达到某个值时，进行模型保存，并break循环，停止训练。 以上就是一个经典的面向过程式的代码编写，先考虑数据怎么读进来，读进来之后喂给的模型如何搭建，模型如何更新，模型如何迭代训练到满意。请大家结合代码一步一步的观察整体过程。 在经过几十个epoch的训练之后达到了100%，模型可以成功区分从未见过的两张图片：auntminnie-a-2020_01_28_23_51_6665_2020_01_28_Vietnam_coronavirus.jpeg，00001215_000.png。 由于数据量少，随机性非常大，大家多运行几次，观察结果。不过本案例结果完全不重要！），可以看到模型的准确率（Accuracy）变化。 一系列问题 通过上述步骤及代码，虽然完成了一个图像分类任务，但其中很多细节想必大家还是弄不清楚，例如： 图像数据是哪用一行代码读取进来的？ transforms.Compose是如何工作对图像数据进行转换的？ ToTensor又有哪些操作？ 自己如何编写Dataset？ DataLoader有什么功能？如何使用？有什么需要注意的？ 模型如何按自己的数据流程搭建？ nn有哪些网络层可以调用？ 损失函数有哪些？ 优化器是如何更新model参数的？ 学习率调整有哪些方法？如何设置它们的参数？ model.train()与model.eval()作用是什么？ optimizer.zero_grad()是做什么？为什么要梯度清零？ scheduler.step() 作用是什么？应该放在哪个for循环里？ 等等 如果大家能有以上的问题提出，本小节的目的就达到了。大家有了模型训练的思路，对过程有了解，但是使用细节还需进一步学习，更多pytorch基础内容将会在后续章节一一解答。 下一小节我们将介绍流动在pytorch各个模块中的基础数据结构——Tensor（张量）。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年04月26日21:48:10 "},"chapter-2/2.3-datastruct-tensor.html":{"url":"chapter-2/2.3-datastruct-tensor.html","title":"2.3 核心数据结构——Tensor","keywords":"","body":"2.3 核心数据结构——Tensor 张量初认识 经过前两小节的铺垫，大家一定对pytorch有了初步认识，本小节就展开讲pytorch的核心数据结构——Tensor（张量）。Tensor中文翻译张量，是一个词不达意的名字。张量在不同学科中有不同的意义，在深度学习中张量表示的是一个多维数组，它是标量、向量、矩阵的拓展。标量是零维张量，向量是一维张量，矩阵是二维张量，一个RGB图像数组就是一个三维张量，第一维是图像高，第二维是图像的宽，第三维是图像颜色通道。 在pytorch中，有两个张量的相关概念极其容易混淆，分别是torch.Tensor和torch.tensor。其实，通过命名规范，可知道torch.Tensor是一个类, torch.tensor是一个函数。通常我们调用torch.tensor进行创建张量，而不直接调用torch.Tensor类进行创建。为了进一步区分两者，我们来看看它们代码实现。 torch.Tensor：类定义与torch/_tensor.py#L80，它继承torch._C._TensorBase，这里看到_C就知道要接触C++代码了。 跳转到torch/C/\\_init__.pyi #L839 可以看到： # Defined in torch/csrc/autograd/python_variable.cpp class _TensorBase(metaclass=_TensorMeta): requires_grad: _bool shape: Size 张量类的底层实现是在python_variable.cpp代码中，感兴趣的朋友可以进一步探究。 torch.tensor：pytorch的一个函数，用于将数据变为张量形式的数据，例如list, tuple, NumPy ndarray, scalar等。同样的，它的底层实现也是C++代码，我们可以跳转到函数定义，发现是torch_C_VariableFunctions.pyi文件（2.1节中介绍了.pyi文件是用于pyi文件是python用来校验数据类型的，其底层实现在对应的cpp代码中。 后续将不再区分Tensor和tensor，主要用小写tensor表示张量这个数据类型（数据结构）。 张量的作用 tensor之于pytorch等同于ndarray之于numpy，它是pytorch中最核心的数据结构，用于表达各类数据，如输入数据、模型的参数、模型的特征图、模型的输出等。这里边有一个很重要的数据，就是模型的参数。对于模型的参数，我们需要它进行更新，而更新是需要记录它的梯度，梯度的记录功能正是被张量所实现的（求梯度是autograd实现的）。 张量的历史演变 讲tensor结构之前，还需要介绍一小段历史，那就是Variable与Tensor。在0.4.0版本之前，Tensor需要经过Variable的包装才能实现自动求导。从0.4.0版本开始，torch.Tensor与torch.autograd.Variable合并，torch.Tensor拥有了跟踪历史操作的功能。虽然Variable仍可用，但Variable返回值已经是一个Tensor（原来返回值是Variable），所以今后无需再用Variable包装Tensor。 虽然Variable的概念已经被摒弃，但是了解其数据结构对理解Tensor还是有帮助的。Variable不仅能对Tensor的包装，而且能记录生成Tensor的运算（这是自动求导的关键）。在Variable对象中主要包含5个属性：data，grad，grad_fn，is_leaf，requires_grad data: 保存的是具体数据，即被包装的Tensor； grad: data对应的梯度，形状与data一致； grad_fn: 记录创建该Tensor时用到的Function，该Function在反向传播计算中使用，因此是自动求导的关键； requires_grad: 用来指示是否需要梯度； is_leaf: 用来指示是否是叶子结点，为叶子结点时，反向传播结束，其梯度仍会保存，非叶子结点的梯度被释放，以节省内存。 从Variable的主要属性中可以发现，除了data外，grad，grad_fn，is_leaf和requires_grad都是为计算梯度服务，所以Variable在torch.autogard包中自然不难理解。 但是我们的数据载体是tensor，每次需要自动求导，都要用Variable包装，这明显太过繁琐，于是PyTorch从0.4.0版将torch.Tensor与torch.autograd.Variable合并。 张量的结构 tensor是一个类，我们先来认识它有哪些属性，再去观察它有哪些方法函数可使用。 Tensor主要有以下八个主要属性，data，dtype，shape，device，grad，grad_fn，is_leaf，requires_grad。 data：多维数组，最核心的属性，其它属性都是为其服务的; dtype：多维数组的数据类型，tensor数据类型如下，常用到的三种已经用红框标注出来； shape：多维数组的形状; device: tensor所在的设备，cpu或cuda; grad，grad_fn，is_leaf和requires_grad就与Variable一样，都是梯度计算中所用到的。 张量的属性还有很多，大家可以通过Pycharm的debug功能进行查看 更多关于张量的概念背景，请查看官方文档，下一小节，我们进行张量的操作介绍。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年04月26日21:48:10 "},"chapter-2/2.4-method-tensor.html":{"url":"chapter-2/2.4-method-tensor.html","title":"2.4 张量的相关函数","keywords":"","body":"2.4 张量的相关函数 接下来开始学习各类张量的api，主要参考官方文档，通过右边目录栏可以看出有以下几个部分。 torchTensors Generators Random sampling Serialization Parallelism Locally disabling gradient computation Math operations Utilities 里面有上百个函数，这里只挑高频使用的进行讲解，建议大家自行浏览一遍官方文档，看看都有哪些功能，便于今后使用到的时候不必重复造轮子。 张量的创建 直接创建 torch.tensor torch.tensor(data, dtype=None, device=None, requires_grad=False, pin_memory=False) data(array_like) - tensor的初始数据，可以是list, tuple, numpy array, scalar或其他类型。 dtype(torch.dtype, optional) - tensor的数据类型，如torch.uint8, torch.float, torch.long等 device (torch.device, optional) – 决定tensor位于cpu还是gpu。如果为None，将会采用默认值，默认值在torch.set_default_tensor_type()中设置，默认为 cpu。 requires_grad (bool, optional) – 决定是否需要计算梯度。 pin_memory (bool, optional) – 是否将tensor存于锁页内存。这与内存的存在方式有关，通常为False。 import torch import numpy as np l = [[1., -1.], [1., -1.]] t_from_list = torch.tensor(l) arr = np.array([[1, 2, 3], [4, 5, 6]]) t_from_array = torch.tensor(arr) print(t_from_list, t_from_list.dtype) print(t_from_array, t_from_array.dtype) tensor([[ 1., -1.], ​ [ 1., -1.]]) torch.float32 tensor([[1, 2, 3], ​ [4, 5, 6]]) torch.int64 可以看到t_from_list是float32类型，而t_from_array是int64类型。如果想让tensor是其他数据类型，可以在创建tensor时使用dytpe参数确定数据类型。 import torch import numpy as np arr = np.array([[1, 2, 3], [4, 5, 6]]) t_from_array = torch.tensor(arr, dtype=torch.uint8) print(t_from_array) tensor([[1, 2, 3], ​ [4, 5, 6]], dtype=torch.uint8) torch.from_numpy 还有一种常用的通过numpy创建tensor方法是torch.from_numpy()。这里需要特别注意的是，创建的tensor和原array共享同一块内存（The returned tensor and ndarray share the same memory. ），即当改变array里的数值，tensor中的数值也会被改变。 import torch import numpy as np arr = np.array([[1, 2, 3], [4, 5, 6]]) t_from_numpy = torch.from_numpy(arr) print(\"numpy array: \", arr) print(\"tensor : \", t_from_numpy) print(\"\\n修改arr\") arr[0, 0] = 0 print(\"numpy array: \", arr) print(\"tensor : \", t_from_numpy) print(\"\\n修改tensor\") t_from_numpy[0, 0] = -1 print(\"numpy array: \", arr) print(\"tensor : \", t_from_numpy) > > numpy array: [[1 2 3] [4 5 6]] tensor : tensor([[1, 2, 3], ​ [4, 5, 6]]) 修改arr numpy array: [[0 2 3] [4 5 6]] tensor : tensor([[0, 2, 3], ​ [4, 5, 6]]) 修改tensor numpy array: [[-1 2 3] [ 4 5 6]] tensor : tensor([[-1, 2, 3], ​ [ 4, 5, 6]]) 可以看到虽然只改变了arr的值，但是tensor中的data也被改变了，这一点在使用过程中需要注意。 依数值创建 torch.zeros torch.zeros(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) 功能：依给定的size创建一个全0的tensor，默认数据类型为torch.float32（也称为torch.float）。 主要参数： layout(torch.layout, optional) - 参数表明张量在内存中采用何种布局方式。常用的有torch.strided, torch.sparse_coo等。 out(tensor, optional) - 输出的tensor，即该函数返回的tensor可以通过out进行赋值，请看例子。 example: import torch o_t = torch.tensor([1]) t = torch.zeros((3, 3), out=o_t) print(t, '\\n', o_t) print(id(t), id(o_t)) > > tensor([[0, 0, 0], ​ [0, 0, 0], ​ [0, 0, 0]]) tensor([[0, 0, 0], ​ [0, 0, 0], ​ [0, 0, 0]]) 4925603056 4925603056 可以看到，通过torch.zeros创建的张量不仅赋给了t，同时赋给了o_t，并且这两个张量是共享同一块内存，只是变量名不同。 torch.zeros_like torch.zeros_like(input, dtype=None, layout=None, device=None, requires_grad=False) 功能：依input的size创建全0的tensor。 主要参数： input(Tensor) - 创建的tensor与intput具有相同的形状。 example: import torch t1 = torch.tensor([[1., -1.], [1., -1.]]) t2 = torch.zeros_like(t1) print(t2) tensor([[0., 0.], ​ [0., 0.]]) 除了创建全0还有创建全1的tensor，使用方法是一样的，这里就不赘述。 torch.ones(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) 功能：依给定的size创建一个全1的tensor。 torch.ones_like(input, dtype=None, layout=None, device=None, requires_grad=False) 功能：依input的size创建全1的tensor。 torch.full(size, fill_value, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) 功能：依给定的size创建一个值全为fill_value的tensor。 主要参数: siz (int...) - tensor的形状。 fill_value - 所创建tensor的值 out(tensor, optional) - 输出的tensor，即该函数返回的tensor可以通过out进行赋值。 example: import torch print(torch.full((2, 3), 3.141592)) torch.full_like(input, fill_value, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) torch.full_like之于torch.full等同于torch.zeros_like之于torch.zeros，因此不再赘述。 torch.arange(start=0, end, step=1, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) 功能：创建等差的1维张量，长度为 (end-start)/step，需要注意数值区间为[start, end)。 主要参数： start (Number) – 数列起始值，默认值为0。the starting value for the set of points. Default: 0. end (Number) – 数列的结束值。 step (Number) – 数列的等差值，默认值为1。 out (Tensor, optional) – 输出的tensor，即该函数返回的tensor可以通过out进行赋值。 example: imort torch print(torch.arange(1, 2.51, 0.5)) torch.range()函数就不推荐及介绍了，因为官网说了“This function is deprecated in favor of torch.arange().” torch.linspace(start, end, steps=100, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) 功能：创建均分的1维张量，长度为steps，区间为[start, end]。 主要参数： start (float) – 数列起始值。 end (float) – 数列结束值。 steps (int) – 数列长度。 example: print(torch.linspace(3, 10, steps=5)) print(torch.linspace(1, 5, steps=3)) torch.logspace(start, end, steps=100, base=10.0, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) 功能：创建对数均分的1维张量，长度为steps, 底为base。 主要参数： start (float) – 确定数列起始值为base^start end (float) – 确定数列结束值为base^end steps (int) – 数列长度。 base (float) - 对数函数的底，默认值为10，此参数是在pytorch 1.0.1版本之后加入的。 example: torch.logspace(start=0.1, end=1.0, steps=5) torch.logspace(start=2, end=2, steps=1, base=2) torch.eye(n, m=None, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)** 功能：创建单位对角矩阵。 主要参数： n (int) - 矩阵的行数 m (int, optional) - 矩阵的列数，默认值为n，即默认创建一个方阵 example: import torch print(torch.eye(3)) print(torch.eye(3, 4)) torch.empty(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False, pin_memory=False) 功能：依size创建“空”张量，这里的“空”指的是不会进行初始化赋值操作。 主要参数： size (int...) - 张量维度 pin_memory (bool, optional) - pinned memory 又称page locked memory，即锁页内存，该参数用来指示是否将tensor存于锁页内存，通常为False，若内存足够大，建议设置为Ture，这样在转到GPU时会快一些。 torch.empty_like(input, dtype=None, layout=None, device=None, requires_grad=False) 功能：torch.empty_like之于torch.empty等同于torch.zeros_like之于torch.zeros，因此不再赘述。 torch.empty_strided(size, stride, dtype=None, layout=None, device=None, requires_grad=False, pin_memory=False) 功能：依size创建“空”张量，这里的“空”指的是不会进行初始化赋值操作。 主要参数： stride (tuple of python:ints) - 张量存储在内存中的步长，是设置在内存中的存储方式。 size (int...) - 张量维度 pin_memory (bool, optional) - 是否存于锁页内存。 依概率分布创建 torch.normal(mean, std, out=None) 功能：为每一个元素以给定的mean和std用高斯分布生成随机数 主要参数： mean (Tensor or Float) - 高斯分布的均值， std (Tensor or Float) - 高斯分布的标准差 特别注意事项： mean和std的取值分别有2种，共4种组合，不同组合产生的效果也不同，需要注意 mean为张量，std为张量，torch.normal(mean, std, out=None)，每个元素从不同的高斯分布采样，分布的均值和标准差由mean和std对应位置元素的值确定； mean为张量，std为标量，torch.normal(mean, std=1.0, out=None)，每个元素采用相同的标准差，不同的均值； mean为标量，std为张量，torch.normal(mean=0.0, std, out=None)， 每个元素采用相同均值，不同标准差； mean为标量，std为标量，torch.normal(mean, std, size, *, out=None) ，从一个高斯分布中生成大小为size的张量； example1 import mean = torch.arange(1, 11.) std = torch.arange(1, 0, -0.1) normal = torch.normal(mean=mean, std=std) print(\"mean: {}, \\nstd: {}, \\nnormal: {}\".format(mean, std, normal)) mean: tensor([ 1., 2., 3., 4., 5., 6., 7., 8., 9., 10.]), std: tensor([1.0000, 0.9000, 0.8000, 0.7000, 0.6000, 0.5000, 0.4000, 0.3000, 0.2000, ​ 0.1000]), normal: tensor([ 1.3530, -1.3498, 3.0021, 5.1200, 3.9818, 5.0163, 6.9272, 8.1171, ​ 9.0623, 10.0621]) 1.3530是通过均值为1，标准差为1的高斯分布采样得来， -1.3498是通过均值为2，标准差为0.9的高斯分布采样得来，以此类推 torch.rand(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) 功能：在区间[0, 1)上，生成均匀分布。 主要参数： size (int...) - 创建的张量的形状 torch.rand_like(input, dtype=None, layout=None, device=None, requires_grad=False) torch.rand_like之于torch.rand等同于torch.zeros_like之于torch.zeros，因此不再赘述。 torch.randint(low=0, high, size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) 功能：在区间[low, high)上，生成整数的均匀分布。 主要参数： low (int, optional) - 下限。 high (int) – 上限，主要是开区间。 size (tuple) – 张量的形状。 example print(torch.randint(3, 10, (2, 2))) torch.randint_like(input, low=0, high, dtype=None, layout=torch.strided, device=None, requires_grad=False) 功能：torch.randint_like之于torch.randint等同于torch.zeros_like之于torch.zeros，因此不再赘述。 torch.randn(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) 功能：生成形状为size的标准正态分布张量。 主要参数： size (int...) - 张量的形状 torch.randn_like(input, dtype=None, layout=None, device=None, requires_grad=False) 功能：torch.rafndn_like之于torch_randn等同于torch.zeros_like之于torch.zeros，因此不再赘述。 torch.randperm(n, out=None, dtype=torch.int64, layout=torch.strided, device=None, requires_grad=False) 功能：生成从0到n-1的随机排列。perm == permutation torch.bernoulli(input, *, generator=None, out=None) 功能：以input的值为概率，生成伯努力分布（0-1分布，两点分布）。 主要参数： input (Tensor) - 分布的概率值，该张量中的每个值的值域为[0-1] example: import torch p = torch.empty(3, 3).uniform_(0, 1) b = torch.bernoulli(p) print(\"probability: \\n{}, \\nbernoulli_tensor:\\n{}\".format(p, b)) probability: tensor([[0.7566, 0.2899, 0.4688], ​ [0.1662, 0.8341, 0.9572], ​ [0.6060, 0.4685, 0.6366]]), bernoulli_tensor: tensor([[0., 0., 1.], ​ [1., 1., 1.], ​ [1., 1., 1.]]) 张量的操作 熟悉numpy的朋友应该知道，Tensor与numpy的数据结构很类似，不仅数据结构类似，操作也是类似的，接下来介绍Tensor的常用操作。由于操作函数很多，这里就不一一举例，仅通过表格说明各个函数作用，详细介绍可查看官方文档 cat 将多个张量拼接在一起，例如多个特征图的融合可用。 concat 同cat, 是cat()的别名。 conj 返回共轭复数。 chunk 将tensor在某个维度上分成n份。 dsplit 类似numpy.dsplit().， 将张量按索引或指定的份数进行切分。 column_stack 水平堆叠张量。即第二个维度上增加，等同于torch.hstack。 dstack 沿第三个轴进行逐像素（depthwise）拼接。 gather 高级索引方法，目标检测中常用于索引bbox。在指定的轴上，根据给定的index进行索引。强烈推荐看example。 hsplit 类似numpy.hsplit()，将张量按列进行切分。若传入整数，则按等分划分。若传入list，则按list中元素进行索引。例如：[2, 3] and dim=0 would result in the tensors input[:2], input[2:3], and input[3:]. hstack 水平堆叠张量。即第二个维度上增加，等同于torch.column_stack。 index_select 在指定的维度上，按索引进行选择数据，然后拼接成新张量。可知道，新张量的指定维度上长度是index的长度。 masked_select 根据mask（0/1, False/True 形式的mask）索引数据，返回1-D张量。 movedim 移动轴。如0，1轴交换：torch.movedim(t, 1, 0) . moveaxis 同movedim。Alias for torch.movedim().（这里发现pytorch很多地方会将dim和axis混用，概念都是一样的。） narrow 变窄的张量？从功能看还是索引。在指定轴上，设置起始和长度进行索引。例如：torch.narrow(x, 0, 0, 2)， 从第0个轴上的第0元素开始，索引2个元素。x[0:0+2, ...] nonzero 返回非零元素的index。torch.nonzero(torch.tensor([1, 1, 1, 0, 1])) 返回tensor([[ 0], [ 1], [ 2], [ 4]])。建议看example，一看就明白，尤其是对角线矩阵的那个例子，太清晰了。 permute 交换轴。 reshape 变换形状。 row_stack 按行堆叠张量。即第一个维度上增加，等同于torch.vstack。Alias of torch.vstack(). scatter scatter_(dim, index, src, reduce=None) → Tensor。将src中数据根据index中的索引按照dim的方向填进input中。这是一个十分难理解的函数，其中index是告诉你哪些位置需要变，src是告诉你要变的值是什么。这个就必须配合例子讲解，请跳转到本节底部进行学习。 scatter_add 同scatter一样，对input进行元素修改，这里是 +=， 而scatter是直接替换。 split 按给定的大小切分出多个张量。例如：torch.split(a, [1,4])； torch.split(a, 2) squeeze 移除张量为1的轴。如t.shape=[1, 3, 224, 224]. t.squeeze().shape -> [3, 224, 224] stack 在新的轴上拼接张量。与hstack\\vstack不同，它是新增一个轴。默认从第0个轴插入新轴。 swapaxes Alias for torch.transpose().交换轴。 swapdims Alias for torch.transpose().交换轴。 t 转置。 take 取张量中的某些元素，返回的是1D张量。torch.take(src, torch.tensor([0, 2, 5]))表示取第0,2,5个元素。 take_along_dim 取张量中的某些元素，返回的张量与index维度保持一致。可搭配torch.argmax(t)和torch.argsort使用，用于对最大概率所在位置取值，或进行排序，详见官方文档的example。 tensor_split 切分张量，核心看indices_or_sections变量如何设置。 tile 将张量重复X遍，X遍表示可按多个维度进行重复。例如：torch.tile(y, (2, 2)) transpose 交换轴。 unbind 移除张量的某个轴，并返回一串张量。如[[1], [2], [3]] --> [1], [2], [3] 。把行这个轴拆了。 unsqueeze 增加一个轴，常用于匹配数据维度。 vsplit 垂直切分。 vstack 垂直堆叠。 where 根据一个是非条件，选择x的元素还是y的元素，拼接成新张量。看案例可瞬间明白。 scater_ scater是将input张量中的部分值进行替换。公式如下： self[index[i][j][k]][j][k] = src[i][j][k] # if dim == 0 self[i][index[i][j][k]][k] = src[i][j][k] # if dim == 1 self[i][j][index[i][j][k]] = src[i][j][k] # if dim == 2 设计两个核心问题： input哪个位置需要替换？ 替换成什么？ 答： 从公式可知道，依次从index中找到元素放到dim的位置，就是input需要变的地方。 变成什么呢？ 从src中找，src中与index一样位置的那个元素值放到input中。 案例1： >>> src = torch.arange(1, 11).reshape((2, 5)) >>> src tensor([[ 1, 2, 3, 4, 5], [ 6, 7, 8, 9, 10]]) >>> index = torch.tensor([[0, 1, 2, 0]]) >>> torch.zeros(3, 5, dtype=src.dtype).scatter_(0, index, src) tensor([[1, 0, 0, 4, 0], [0, 2, 0, 0, 0], [0, 0, 3, 0, 0]]) dim=0, 所以行号跟着index的元素走。其它跟index的索引走。 第一步：找到index的第一个元素index[0, 0]是0， 那么把src[0, 0]（是1）放到input[0, 0]第二步：找到index的第二个元素index[0, 1]是1， 那么把src[0, 1]（是2）放到input[1, 1]第三步：找到index的第三个元素index[0, 2]是2， 那么把src[0, 2]（是3）放到input[2, 2]第四步：找到index的第四个元素index[0, 3]是0， 那么把src[0, 3]（是4）放到input[0, 3] 案例2： >>> src = torch.arange(1, 11).reshape((2, 5)) >>> src tensor([[ 1, 2, 3, 4, 5], [ 6, 7, 8, 9, 10]]) >>> index = torch.tensor([[0, 2, 4], [1, 2, 3]]) >>> index tensor([[0, 2, 4], [1, 2, 3]]) >>> torch.zeros(3, 5, dtype=src.dtype).scatter_(1, index, src) tensor([[1, 0, 2, 0, 3], [0, 6, 7, 8, 0], [0, 0, 0, 0, 0]]) dim=1：告诉input（零矩阵）的索引，沿着列进行索引，行根据index走。 index：2*3，告诉input（零矩阵），你的哪些行是要被替换的。 src：input要替换成什么呢？从src里找，怎么找？通过index的索引对应的找。 第一步：找到index的第一个元素index[0, 0]是0， 那么把src[0, 0]（是1）放到input[0, 0]第二步：找到index的第二个元素index[0, 1]是2， 那么把src[0, 1]（是2）放到input[0, 2]第三步：找到index的第三个元素index[0, 2]是4， 那么把src[0, 2]（是3）放到input[0, 4]第四步：找到index的第四个元素index[1, 0]是1， 那么把src[1, 0]（是6）放到input[1, 1]第五步：找到index的第五个元素index[1, 1]是2， 那么把src[1, 1]（是7）放到input[1, 2]第六步：找到index的第六个元素index[1, 2]是3， 那么把src[1, 2]（是8）放到input[1, 3] 这里可以看到 index的元素是决定input的哪个位置要变 变的值是从src上对应于index的索引上找。可以看到src的索引与index的索引保持一致的 案例3：one-hot的生成 >>> label = torch.arange(3).view(-1, 1) >>> label tensor([[0], [1], [2]]) >>> torch.zeros(3, 3).scatter_(1, label, 1) tensor([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]]) 第一步：找到index的第一个元素index[0, 0]是0， 那么把src[0, 0]（是1）放到input[0, 0] 第二步：找到index的第二个元素index[1, 0]是1， 那么把src[1, 0]（是1）放到input[1, 1] 第三步：找到index的第三个元素index[2, 0]是2， 那么把src[2, 0]（是1）放到input[2, 2] （one-hot的案例不利于理解scater函数，因为它的行和列是一样的。。。其实input[x, y] 中的x,y是有区别的，x是根据index走，y是根据index的元素值走的，而具体的值是根据src的值。） 张量的随机种子 随机种子（random seed）是编程语言中基础的概念，大多数编程语言都有随机种子的概念，它主要用于实验的复现。针对随机种子pytorch也有一些设置函数。 seed 获取一个随机的随机种子。Returns a 64 bit number used to seed the RNG. manual_seed 手动设置随机种子，建议设置为42，这是近期一个玄学研究。说42有效的提高模型精度。当然大家可以设置为你喜欢的，只要保持一致即可。 initial_seed 返回初始种子。 get_rng_state 获取随机数生成器状态。Returns the random number generator state as a torch.ByteTensor. set_rng_state 设定随机数生成器状态。这两怎么用暂时未知。Sets the random number generator state. 以上均是设置cpu上的张量随机种子，在cuda上是另外一套随机种子，如torch.cuda.manual_seed_all(seed)， 这些到cuda模块再进行介绍，这里只需要知道cpu和cuda上需要分别设置随机种子。 张量的数学操作 张量还提供大量数学操作，估计了一下，有快一百个函数，这里就不再一一分析，只需要知道有哪几大类，用到的时候来查吧。 Pointwise Ops： 逐元素的操作，如abs, cos, sin, floor, floor_divide, pow等 Reduction Ops: 减少元素的操作，如argmax, argmin, all, any, mean, norm, var等 Comparison Ops：对比操作， 如ge, gt, le, lt, eq, argsort, isnan, topk, Spectral Ops: 谱操作，如短时傅里叶变换等各类信号处理的函数。 Other Operations：其它， clone， diag，flip等 BLAS and LAPACK Operations：BLAS（Basic Linear Algebra Subprograms）基础线性代数）操作。如, addmm, dot, inner, svd等。 小结 本节介绍了张量主要的操作函数，并归类到各个小结，这些仅是张量的部分操作，更多操作还请大家多多看官方文档。对于张量，主要是要理解2.3小节中张量的结构以及作用，对于它的操作就像numpy一样简单易用。 下一节就开始讲解pytorch的核心——autograd，autograd也是现代深度学习框架的核心，是实现自动微分的具体实现。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年04月26日21:48:10 "},"chapter-2/2.5-computational-graphs.html":{"url":"chapter-2/2.5-computational-graphs.html","title":"2.5 自动求导核心——计算图","keywords":"","body":"2.5 计算图 前两小节对tensor进行了详细介绍，知道了tensor是pytorch的核心数据结构，各类数据均以tensor来表示，并且tensor类中有许多属性与求导/梯度有关，下面就深入学习pytorch的自动求导模块——autograd。在autograd正式开始之前，需要了解一个重要概念——计算图（Computational Graphs）。 在学习自动求导系统之前，需要了解计算图的概念。计算图（Computational Graphs）是一种描述运算的“语言”，它由节点(Node)和边(Edge)构成。 节点表示数据，如标量，向量，矩阵，张量等； 边表示运算，如加、减、乘、除、卷积、relu等； 记录所有节点和边的信息，可以方便的完成自动求导，假设有这么一个计算： y = (x+ w) * (w+1) 将每一步细化为： a = x + w b = w + 1 y = a * b 得到计算图如下： 有了计算图，我们可以尝试进行forward，带入x,w的输入数据，就得到结果y。 同样的，加入需要获取各参数的导数，也可以方便的获得。 计算图求导 假设我们要算y对w的导数，在计算图中要怎么做呢？ 先来看w和y之间的关系，w会通过左边这条路走到y，也会通过右边这条路走到y，所以梯度也是一样的，会经过这两条路返传回来。 所以y对w的偏导有两条路径，可以写成以下形式， ∂y/∂w = ∂y/∂a ∂a/∂w + ∂y/∂b ∂b/∂w，然后可以通过计算图依次求出。 如图所示： 这样我们得到 y对w的导数是5，我们可以拿纸和笔推一下，是否是一样的。 我们发现，所有的偏微分计算所需要用到的数据都是基于w和x的，这里，w和x就称为叶子结点。 叶子结点是最基础的结点，其数据不是由运算生成的，因此是整个计算图的基石，是不可轻易”修改“的。而最终计算得到的y就是根节点，就像一棵树一样，叶子在上面，根在下面。 叶子结点 叶子结点是最基础的结点，其数据不是由运算生成的，因此是整个计算图的基石，是不可轻易”修改“的。而最终计算得到的y就是根节点，就像一棵树一样，叶子在上面，根在下面。 张量有一个属性是is_leaf, 就是用来指示一个张量是否为叶子结点的属性。 我们通过代码，实现以上运算，并查看该计算图的叶子结点和梯度。 import torch w = torch.tensor([1.], requires_grad=True) x = torch.tensor([2.], requires_grad=True) a = torch.add(w, x) b = torch.add(w, 1) # retain_grad() y = torch.mul(a, b) y.backward() print(w.grad) # 查看叶子结点 print(\"is_leaf:\\n\", w.is_leaf, x.is_leaf, a.is_leaf, b.is_leaf, y.is_leaf) # 查看梯度 print(\"gradient:\\n\", w.grad, x.grad, a.grad, b.grad, y.grad) # 查看 grad_fn print(\"grad_fn:\\n\", w.grad_fn, x.grad_fn, a.grad_fn, b.grad_fn, y.grad_fn) tensor([5.]) is_leaf: True True False False False gradient: tensor([5.]) tensor([2.]) None None None grad_fn: None None 我们发现y就不是叶子结点了，因为它是由结点w和结点x通过乘法运算得到的。 补充知识点1：非叶子结点在梯度反向传播结束后释放 只有叶子节点的梯度得到保留，中间变量的梯度默认不保留；在pytorch中，非叶子结点的梯度在反向传播结束之后就会被释放掉，如果需要保留的话可以对该结点设置retain_grad() 补充知识点2：grad_fn是用来记录创建张量时所用到的运算，在链式求导法则中会使用到。 思考一下y对w求导的过程，我们知道只要记录下计算图中的结点（数据）和边（运算），就可以通过链式法则轻易的求取梯度。 所以在pytorch中，自动微分的关键就是记录数据和该结点的运算。回想一下张量的结构当中其实就记录了这两个重要的东西。 在张量中，数据对应着data，结点的运算对应着grad_fn，大家现在应该明白为什么结点的运算叫grad_fn而不叫fn了吧，因为这个运算是在求梯度的时候使用的。 静态图与动态图 以上就是计算图的简单介绍。计算图根据计算图的搭建方式可以划分为静态图和动态图。 pytorch是典型的动态图，TensorFlow是静态图（TF 2.x 也支持动态图模式）。 怎么样的搭建方式是动态的？怎么样的才是静态的呢？ 第一种判断：这就要看运算，是在计算图搭建之后，还是两者同步进行 先搭建计算图，再运算，这就是静态图机制。 而在运算的同时去搭建计算图，这就是动态图机制。 第二种判断：也可以通过判断运算过程中，计算图是否可变动来区分静态图与动态图。 在运算过程中，计算图可变动的，那么就是动态图，计算图不可变，是静止的，那么就是静态图。 下面来看两个示意图。 图1为pytorch的静态图示意，图2为TensorFlow的静态图示意。 动态图优点： 易懂性：程序按照编写命令的顺序进行执行 灵活性：可依据模型运算结果来决定计算图 静态图优点： 高效性：优化计算图，提高运算效率（但在gpu时代，这一点对于初学者而言可忽略不计） 缺点： 晦涩性：需要学习 seesion, placeholder等概念，debug难 以上是关于计算图概念的介绍，下一小节将详细剖析autograd机制及其常用的功能函数，预告一下，下一节内容也非常多，需要反复阅读。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年04月26日21:48:10 "},"chapter-2/2.6-autograd.html":{"url":"chapter-2/2.6-autograd.html","title":"2.6 Autograd——自动微分","keywords":"","body":"2.6 Autograd 了解计算图后，我们可以开始学习autograd。这里再次回顾pytorch官网的一张示意图 在进行h2h、i2h、next_h、loss的计算过程中，逐步的搭建计算图，同时针对每一个变量（tensor）都存储计算梯度所必备的grad_fn，便于自动求导系统使用。当计算到根节点后，在根节点调用.backward()函数，即可自动反向传播计算计算图中所有节点的梯度。这就是pytorch自动求导机制，其中涉及张量类、计算图、grad_fn、链式求导法则等基础概念，大家可以自行补充学习。 autograd 官方定义 来看看官方文档中对autograd的解释： Conceptually, autograd keeps a record of data (tensors) and all executed operations (along with the resulting new tensors) in a directed acyclic graph (DAG) consisting of Function objects. In this DAG, leaves are the input tensors, roots are the output tensors. By tracing this graph from roots to leaves, you can automatically compute the gradients using the chain rule. In a forward pass, autograd does two things simultaneously: run the requested operation to compute a resulting tensor maintain the operation’s gradient function in the DAG. The backward pass kicks off when .backward() is called on the DAG root. autograd then: computes the gradients from each .grad_fn, accumulates them in the respective tensor’s .grad attribute using the chain rule, propagates all the way to the leaf tensors. from： https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html#more-on-computational-graphs 划重点： 自动求导机制通过有向无环图（directed acyclic graph ，DAG）实现 在DAG中，记录数据（对应tensor.data）以及操作（对应tensor.grad_fn） 操作在pytorch中统称为Function，如加法、减法、乘法、ReLU、conv、Pooling等，统统是Function autograd 的使用 autograd的使用有很多方法，这里重点讲解一下三个，并在最后汇总一些知识点。更多API推荐阅读官方文档 torch.autograd.backward torch.autograd.grad torch.autograd.Function torch.autograd.backward backward函数是使用频率最高的自动求导函数，没有之一。99%的训练代码中都会用它进行梯度求导，然后更新权重。 使用方法可以参考第二章第二节-新冠肺炎分类的代码，loss.backward()就可以完成计算图中所有张量的梯度求解。 虽然绝大多数都是直接使用，但是backward()里边还有一些高级参数，值得了解。 torch.autograd.backward(tensors, grad_tensors=None, retain_graph=None, create_graph=False, grad_variables=None, inputs=None) tensors (Sequence[Tensor] or Tensor) – 用于求导的张量。如上例的loss。 grad_tensors (Sequence[Tensor or None] or Tensor, optional) – 雅克比向量积中使用，详细作用请看代码演示。 retain_graph (bool, optional) – 是否需要保留计算图。pytorch的机制是在方向传播结束时，计算图释放以节省内存。大家可以尝试连续使用loss.backward()，就会报错。如果需要多次求导，则在执行backward()时，retain_graph=True。 create_graph (bool, optional) – 是否创建计算图，用于高阶求导。 inputs (Sequence[Tensor] or Tensor, optional) – Inputs w.r.t. which the gradient be will accumulated into .grad. All other Tensors will be ignored. If not provided, the gradient is accumulated into all the leaf Tensors that were used to compute the attr::tensors. 补充说明：我们到使用的时候都是在张量上直接调用.backward()函数，但这里却是torch.autograd.backward，为什么不一样呢？ 其实Tensor.backward()接口内部调用了autograd.backward。 请看使用示例 retain_grad参数使用 对比两个代码段，仔细阅读pytorch报错信息。 ##### retain_graph=True import torch w = torch.tensor([1.], requires_grad=True) x = torch.tensor([2.], requires_grad=True) a = torch.add(w, x) b = torch.add(w, 1) y = torch.mul(a, b) y.backward(retain_graph=True) print(w.grad) y.backward() print(w.grad) tensor([5.]) tensor([10.]) 运行上面代码段可以看到是正常的，下面这个代码段就会报错，报错信息提示非常明确：Trying to backward through the graph a second time。并且还给出了解决方法： Specify retain_graph=True if you need to backward through the graph a second time 。这也是pytorch代码写得好的地方，出现错误不要慌，仔细看看报错信息，里边可能会有解决问题的方法。 ##### retain_graph=False import torch w = torch.tensor([1.], requires_grad=True) x = torch.tensor([2.], requires_grad=True) a = torch.add(w, x) b = torch.add(w, 1) y = torch.mul(a, b) y.backward() print(w.grad) y.backward() print(w.grad) tensor([5.]) --------------------------------------------------------------------------- RuntimeError Traceback (most recent call last) in 10 y.backward() 11 print(w.grad) ---> 12 y.backward() 13 print(w.grad) D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\lib\\site-packages\\torch\\_tensor.py in backward(self, gradient, retain_graph, create_graph, inputs) 305 create_graph=create_graph, 306 inputs=inputs) --> 307 torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs) 308 309 def register_hook(self, hook): D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\lib\\site-packages\\torch\\autograd\\__init__.py in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs) 154 Variable._execution_engine.run_backward( 155 tensors, grad_tensors_, retain_graph, create_graph, inputs, --> 156 allow_unreachable=True, accumulate_grad=True) # allow_unreachable flag 157 158 RuntimeError: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward. grad_tensors使用 w = torch.tensor([1.], requires_grad=True) x = torch.tensor([2.], requires_grad=True) a = torch.add(w, x) b = torch.add(w, 1) y0 = torch.mul(a, b) # y0 = (x+w) * (w+1) dy0/dw = 2w + x + 1 y1 = torch.add(a, b) # y1 = (x+w) + (w+1) dy1/dw = 2 loss = torch.cat([y0, y1], dim=0) # [y0, y1] grad_tensors = torch.tensor([1., 2.]) loss.backward(gradient=grad_tensors) # Tensor.backward中的 gradient 传入 torch.autograd.backward()中的grad_tensors # w = 1* (dy0/dw) + 2*(dy1/dw) # w = 1* (2w + x + 1) + 2*(w) # w = 1* (5) + 2*(2) # w = 9 print(w.grad) tensor([9.]) torch.autograd.grad orch.autograd.grad(outputs, inputs, grad_outputs=None, retain_graph=None, create_graph=False, only_inputs=True, allow_unused=False) 功能：计算outputs对inputs的导数 主要参数： outputs (sequence of Tensor) – 用于求导的张量，如loss inputs (sequence of Tensor) – 所要计算导数的张量 grad_outputs (sequence of Tensor) – 雅克比向量积中使用。 retain_graph (bool, optional) – 是否需要保留计算图。pytorch的机制是在方向传播结束时，计算图释放以节省内存。大家可以尝试连续使用loss.backward()，就会报错。如果需要多次求导，则在执行backward()时，retain_graph=True。 create_graph (bool, optional) – 是否创建计算图，用于高阶求导。 allow_unused (bool, optional) – 是否需要指示，计算梯度时未使用的张量是错误的。 此函数使用上比较简单，请看案例： import torch x = torch.tensor([3.], requires_grad=True) y = torch.pow(x, 2) # y = x**2 # 一阶导数 grad_1 = torch.autograd.grad(y, x, create_graph=True) # grad_1 = dy/dx = 2x = 2 * 3 = 6 print(grad_1) # 二阶导数 grad_2 = torch.autograd.grad(grad_1[0], x) # grad_2 = d(dy/dx)/dx = d(2x)/dx = 2 print(grad_2) (tensor([6.], grad_fn=),) (tensor([2.]),) torch.autograd.Function 有的时候，想要实现自己的一些操作（op），如特殊的数学函数、pytorch的module中没有的网络层，那就需要自己写一个Function，在Function中定义好forward的计算公式、backward的计算公式，然后将这些op组合到模型中，模型就可以用autograd完成梯度求取。 这个概念还是很抽象，平时用得不多，但是自己想要魔改网络时，常常需要自己写op，那么它就很好用了，为了让大家掌握自定义op——Function的写法，特地从多处收集了四个案例，大家多运行代码体会Function如何写。 案例1： exp 案例1：来自 https://pytorch.org/docs/stable/autograd.html#function 假设需要一个计算指数的功能，并且能组合到模型中，实现autograd，那么可以这样实现 第一步：继承Function第二步：实现forward第三步：实现backward 注意事项： forward和backward函数第一个参数为ctx，它的作用类似于类函数的self一样，更详细解释可参考如下： In the forward pass we receive a Tensor containing the input and return a Tensor containing the output. ctx is a context object that can be used to stash information for backward computation. You can cache arbitrary objects for use in the backward pass using the ctx.save_for_backward method. backward函数返回的参数个数与forward的输入参数个数相同, 即，传入该op的参数，都需要给它们计算对应的梯度。 import torch from torch.autograd.function import Function class Exp(Function): @staticmethod def forward(ctx, i): # ============== step1: 函数功能实现 ============== result = i.exp() # ============== step1: 函数功能实现 ============== # ============== step2: 结果保存，用于反向传播 ============== ctx.save_for_backward(result) # ============== step2: 结果保存，用于反向传播 ============== return result @staticmethod def backward(ctx, grad_output): # ============== step1: 取出结果，用于反向传播 ============== result, = ctx.saved_tensors # ============== step1: 取出结果，用于反向传播 ============== # ============== step2: 反向传播公式实现 ============== grad_results = grad_output * result # ============== step2: 反向传播公式实现 ============== return grad_results x = torch.tensor([1.], requires_grad=True) y = Exp.apply(x) # 需要使用apply方法调用自定义autograd function print(y) # y = e^x = e^1 = 2.7183 y.backward() print(x.grad) # 反传梯度, x.grad = dy/dx = e^x = e^1 = 2.7183 # 关于本例子更详细解释，推荐阅读 https://zhuanlan.zhihu.com/p/321449610 tensor([2.7183], grad_fn=) tensor([2.7183]) 从代码里可以看到，y这个张量的 grad_fn 是 ExpBackward，正是我们自己实现的函数，这表明当y求梯度时，会调用ExpBackward这个函数进行计算这也是张量的grad_fn的作用所在 案例2：为梯度乘以一定系数 Gradcoeff 案例2来自： https://zhuanlan.zhihu.com/p/321449610 功能是反向传梯度时乘以一个自定义系数 class GradCoeff(Function): @staticmethod def forward(ctx, x, coeff): # ============== step1: 函数功能实现 ============== ctx.coeff = coeff # 将coeff存为ctx的成员变量 x.view_as(x) # ============== step1: 函数功能实现 ============== return x @staticmethod def backward(ctx, grad_output): return ctx.coeff * grad_output, None # backward的输出个数，应与forward的输入个数相同，此处coeff不需要梯度，因此返回None # 尝试使用 x = torch.tensor([2.], requires_grad=True) ret = GradCoeff.apply(x, -0.1) # 前向需要同时提供x及coeff，设置coeff为-0.1 ret = ret ** 2 print(ret) # 注意看： ret.grad_fn ret.backward() print(x.grad) tensor([4.], grad_fn=) tensor([-0.4000]) 在这里需要注意 backward函数返回的参数个数与forward的输入参数个数相同即，传入该op的参数，都需要给它们计算对应的梯度。 案例3：勒让德多项式 案例来自：https://github.com/excelkks/blog假设多项式为：$y = a+bx+cx^2+dx^3$时，用两步替代该过程 $y= a+b\\times P_3(c+dx), P_3(x) = \\frac{1}{2}(5x^3-3x)$ import torch import math from torch.autograd.function import Function class LegendrePolynomial3(Function): @staticmethod def forward(ctx, x): \"\"\" In the forward pass we receive a Tensor containing the input and return a Tensor containing the output. ctx is a context object that can be used to stash information for backward computation. You can cache arbitrary objects for use in the backward pass using the ctx.save_for_backward method. \"\"\" y = 0.5 * (5 * x ** 3 - 3 * x) ctx.save_for_backward(x) return y @staticmethod def backward(ctx, grad_output): \"\"\" In the backward pass we receive a Tensor containing the gradient of the loss with respect to the output, and we need to compute the gradient of the loss with respect to the input. \"\"\" ret, = ctx.saved_tensors return grad_output * 1.5 * (5 * ret ** 2 - 1) a, b, c, d = 1, 2, 1, 2 x = 1 P3 = LegendrePolynomial3.apply y_pred = a + b * P3(c + d * x) print(y_pred) 127.0 案例4：手动实现2D卷积 案例来自：https://pytorch.org/tutorials/intermediate/custom_function_conv_bn_tutorial.html案例本是卷积与BN的融合实现，此处仅观察Function的使用，更详细的内容，十分推荐阅读原文章下面看如何实现conv_2d的 import torch from torch.autograd.function import once_differentiable import torch.nn.functional as F def convolution_backward(grad_out, X, weight): \"\"\" 将反向传播功能用函数包装起来，返回的参数个数与forward接收的参数个数保持一致，为2个 \"\"\" grad_input = F.conv2d(X.transpose(0, 1), grad_out.transpose(0, 1)).transpose(0, 1) grad_X = F.conv_transpose2d(grad_out, weight) return grad_X, grad_input class MyConv2D(torch.autograd.Function): @staticmethod def forward(ctx, X, weight): ctx.save_for_backward(X, weight) # ============== step1: 函数功能实现 ============== ret = F.conv2d(X, weight) # ============== step1: 函数功能实现 ============== return ret @staticmethod def backward(ctx, grad_out): X, weight = ctx.saved_tensors return convolution_backward(grad_out, X, weight) weight = torch.rand(5, 3, 3, 3, requires_grad=True, dtype=torch.double) X = torch.rand(10, 3, 7, 7, requires_grad=True, dtype=torch.double) torch.autograd.gradcheck(Conv2D.apply, (X, weight)) # gradcheck 功能请自行了解，通常写完Function会用它检查一下 y = Conv2D.apply(X, weight) label = torch.randn_like(y) loss = F.mse_loss(y, label) print(weight.grad) loss.backward() print(weight.grad) None tensor([[[[1.4503, 1.3995, 1.4427], [1.4725, 1.4247, 1.4995], [1.4584, 1.4395, 1.5462]], ...... [[1.4645, 1.4461, 1.3604], [1.4523, 1.4556, 1.3755], [1.4204, 1.4346, 1.4323]]]], dtype=torch.float64) ​ autograd相关的知识点 autograd使用过程中还有很多需要注意的地方，在这里做个小汇总。 知识点一：梯度不会自动清零 知识点二： 依赖于叶子结点的结点，requires_grad默认为True 知识点三： 叶子结点不可执行in-place 知识点四： detach 的作用 知识点五： with torch.no_grad()的作用 知识点一：梯度不会自动清零 import torch w = torch.tensor([1.], requires_grad=True) x = torch.tensor([2.], requires_grad=True) for i in range(4): a = torch.add(w, x) b = torch.add(w, 1) y = torch.mul(a, b) y.backward() print(w.grad) # 梯度不会自动清零，数据会累加， 通常需要采用 optimizer.zero_grad() 完成对参数的梯度清零 # w.grad.zero_() tensor([5.]) tensor([5.]) tensor([5.]) tensor([5.]) 知识点二：依赖于叶子结点的结点，requires_grad默认为True 结点的运算依赖于叶子结点的话，它一定是要计算梯度的，因为叶子结点梯度的计算是从后向前传播的，因此与其相关的结点均需要计算梯度，这点还是很好理解的。 import torch w = torch.tensor([1.], requires_grad=True) # x = torch.tensor([2.], requires_grad=True) a = torch.add(w, x) b = torch.add(w, 1) y = torch.mul(a, b) print(a.requires_grad, b.requires_grad, y.requires_grad) print(a.is_leaf, b.is_leaf, y.is_leaf) True True True False False False 知识点三：叶子张量不可以执行in-place操作 叶子结点不可执行in-place，因为计算图的backward过程都依赖于叶子结点的计算，可以回顾计算图当中的例子，所有的偏微分计算所需要用到的数据都是基于w和x（叶子结点），因此叶子结点不允许in-place操作。 a = torch.ones((1, )) print(id(a), a) a = a + torch.ones((1, )) print(id(a), a) a += torch.ones((1, )) print(id(a), a) 2361561191752 tensor([1.]) 2362180999432 tensor([2.]) 2362180999432 tensor([3.]) w = torch.tensor([1.], requires_grad=True) x = torch.tensor([2.], requires_grad=True) a = torch.add(w, x) b = torch.add(w, 1) y = torch.mul(a, b) w.add_(1) y.backward() --------------------------------------------------------------------------- RuntimeError Traceback (most recent call last) in 6 y = torch.mul(a, b) 7 ----> 8 w.add_(1) 9 10 y.backward() RuntimeError: a leaf Variable that requires grad is being used in an in-place operation. 知识点四：detach 的作用 通过以上知识，我们知道计算图中的张量是不能随便修改的，否则会造成计算图的backward计算错误，那有没有其他方法能修改呢？当然有，那就是detach() detach的作用是：从计算图中剥离出“数据”，并以一个新张量的形式返回，并且新张量与旧张量共享数据，简单的可理解为做了一个别名。 请看下例的w，detach后对w_detach修改数据，w同步地被改为了999 w = torch.tensor([1.], requires_grad=True) x = torch.tensor([2.], requires_grad=True) a = torch.add(w, x) b = torch.add(w, 1) y = torch.mul(a, b) y.backward() w_detach = w.detach() w_detach.data[0] = 999 print(w) tensor([999.], requires_grad=True) 知识点五：with torch.no_grad()的作用 autograd自动构建计算图过程中会保存一系列中间变量，以便于backward的计算，这就必然需要花费额外的内存和时间。而并不是所有情况下都需要backward，例如推理的时候，因此可以采用上下文管理器——torch.no_grad()来管理上下文，让pytorch不记录相应的变量，以加快速度和节省空间。详见：https://pytorch.org/docs/stable/generated/torch.no_grad.html?highlight=no_grad#torch.no_grad 小结 本章终于结束，本章目的是为大家介绍pytorch的核心模块，包括pytorch代码库结构，以便于今后阅读源码，知道从哪里找代码；包括第一个分类模型训练，便于大家理解模型训练过程；包括核心数据结构——张量，便于理解整个pytorch的数据；包括计算图与autograd，便于大家熟悉自动微分的过程及自定义op的方法。 下一章将通过借助covid-19任务，详细介绍pytorch的数据读取机制，以及各种数据形式的读取，包括csv形式、txt形式、杂乱文件夹形式等一切关于数据读取、加载、操作的模块都将涉及。 小记：动笔一个多月，才写了两章，尤其autograd和tensor写了大半个月，希望后面能有更多时间精力早日完成，加油！2022年1月18日 ​ ​ Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年04月26日21:48:10 "},"chapter-3/":{"url":"chapter-3/","title":"第三章 PyTorch 数据模块","keywords":"","body":"第三章 PyTorch 数据模块 第三章 PyTorch 数据模块 3.1 Dataset 3.2 DataLoader 3.3 Dataset-useful-api 3.4 transforms 3.5 torchvision 经典dataset学习 第三章简介 经过前两章的铺垫，本章终于可以讲讲项目代码中重要的模块——数据模块。 数据模块包括哪些内容呢？相信大家多少会有一些感觉，不过最好结合具体任务来剖析数据模块。 我们回顾2.2中的COVID-19分类任务，观察一下数据是如何从硬盘到模型输入的。 我们倒着推， 模型接收的训练数据是 data：outputs = model(data) data来自train_loader： for data, labels in train_loader: train_loader 来自 DataLoader与train_data：train_loader = DataLoader(dataset=train_data, batch_size=2) train_data 来自 COVID19Dataset：train_data = COVID19Dataset(root_dir=img_dir, txt_path=path_txt_train, transform=transforms_func) COVID19Dataset继承于Dataset：COVID19Dataset(Dataset) 至此，知道整个数据处理过程会涉及pytorch的两个核心——Dataset， DataLoader。 Dataset是一个抽象基类，提供给用户定义自己的数据读取方式，最核心在于getitem中间对数据的处理。 DataLoader是pytorch数据加载的核心，其中包括多个功能，如打乱数据，采样机制（实现均衡1:1采样），多进程数据加载，组装成Batch形式等丰富的功能。 本章将围绕着它们两个展开介绍pytorch的数据读取、预处理、加载等功能。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年04月26日21:48:10 "},"chapter-3/3.1-dataset.html":{"url":"chapter-3/3.1-dataset.html","title":"3.1 Dataset","keywords":"","body":"3.1 torch.utils.data.Dataset 数据交互模块——Dataset 虽然说pytorch数据模块的核心是DataLoader，但是对于使用者而言，改动最多的、与源数据最接近的是Dataset， 本小节就详细分析Dataset的作用，并通过三个案例学习如何编写自定义Dataset来读取自己的数据集。 Dataset的功能 pytorch提供的torch.utils.data.Dataset类是一个抽象基类An abstract class representing a Dataset，供用户继承，编写自己的dataset，实现对数据的读取。在Dataset类的编写中必须要实现的两个函数是__getitem__和__len__(由于markdown语法问题，后续双下划线就省略了)。 getitem：需要实现读取一个样本的功能。通常是传入索引（index，可以是序号或key），然后实现从磁盘中读取数据，并进行预处理（包括online的数据增强），然后返回一个样本的数据。数据可以是包括模型需要的输入、标签，也可以是其他元信息，例如图片的路径。getitem返回的数据会在dataloader中组装成一个batch。即，通常情况下是在dataloader中调用Dataset的getitem函数获取一个样本。 len：返回数据集的大小，数据集的大小也是个最要的信息，它在dataloader中也会用到。如果这个函数返回的是0，dataloader会报错：\"ValueError: num_samples should be a positive integer value, but got num_samples=0\" 这个报错相信大家经常会遇到，这通常是路径没写对，导致你的dataset找不到数据，数据个数为0。 了解Dataset类的概念，下面通过一幅示意图，来理解Dataset与DataLoader的关系。 dataset负责与磁盘打交道，将磁盘上的数据读取并预处理好，提供给DataLoader，而DataLoader只需要关心如何组装成批数据，以及如何采样。采样的体现是出现在传入getitem函数的索引，这里采样的规则可以通过sampler由用户自定义，可以方便地实现均衡采样、随机采样、有偏采样、渐进式采样等，这个留在DataLoader中会详细展开。 在这里，我们先关心一下Dataset如何与磁盘构建联系。 从2.2的例子中可以看到，我们为COVID19Dataset定义了一个_get_img_info函数，它就是用来建立磁盘关系的，在这个函数中处理样本的路径信息、标签信息，存储到一个list中，供getitem函数使用。getitem函数只需要拿到序号，就可获得图片的路径信息、标签信息，接着进行图片预处理，最后返回一个样本信息。 希望大家体会_get_img_info函数的作用，对于各式各样的数据形式，都可以用这个模板实现Dataset的构建，只需要在_get_img_info中把数据信息（路径、标签等）读取进来放到list中，供getite使用即可。 三个Dataset案例 相信大家在做自己的任务时，遇到的第一个问题就是，怎么把自己的数据放到github的模型上跑起来。很多朋友通常会把自己的数据制作到与现成项目数据一模一样的数据形式，然后调用代码。这样虽然快捷，但是缺少灵活性。 为了让大家能掌握各类数据形式的读取，这里构建三个不同的数据形式进行编写Dataset。 第一个：2.2中的类型。数据的划分及标签在txt中。 第二个：数据的划分及标签在文件夹中体现 第三个：数据的划分及标签在csv中 详细请结合 配套代码，深刻体会_get_img_info及Dataset做了什么事情。 代码输出主要有两部分， 第一部分是两种dataset的getitem输出。 第二部分是结合DataLoader进行数据加载。 先看第一部分，输出的是 PIL对象及图像标签，这里可以进入getitem函数看到采用了 img = Image.open(path_img).convert('L') 对图片进行了读取，得到了PIL对象，由于transform为None，不对图像进行任何预处理，因此getitem函数返回的图像是PIL对象。 2 (, 1) 2 (, 1) 第二部分是结合DataLoader的使用，这种形式更贴近真实场景，在这里为Dataset设置了一些transform，有图像的缩放，ToTensor， normalize三个方法。因此，getitem返回的图像变为了张量的形式，并且在DataLoader中组装成了batchsize的形式。大家可以尝试修改缩放的大小来观察输出，也可以注释normalize来观察它们的作用。 0 torch.Size([2, 1, 4, 4]) tensor([[[[-0.0431, -0.1216, -0.0980, -0.1373], [-0.0667, -0.2000, -0.0824, -0.2392], [-0.1137, 0.0353, 0.1843, -0.2078], [ 0.0510, 0.3255, 0.3490, -0.0510]]], [[[-0.3569, -0.2863, -0.3333, -0.4118], [ 0.0196, -0.3098, -0.2941, 0.1059], [-0.2392, -0.1294, 0.0510, -0.2314], [-0.1059, 0.4118, 0.4667, 0.0275]]]]) torch.Size([2]) tensor([1, 0]) 关于transform的系列方法以及工作原理，将在本章后半部分讲解数据增强部分再详细展开。 小结 本小结介绍了torch.utils.data.Dataset类的结构及工作原理，并通过三个案例实践，加深大家对自行编写Dataset的认识，关于Dataset的编写，torchvision也有很多常用公开数据集的Dataset模板，建议大家学习，本章后半部分也会挑选几个Dataset进行分析。下一小节将介绍DataLoader类的使用。 额外学习建议 IDE的debug： 下一小节的代码将采用debug模式进行逐步分析，建议大家提前熟悉pycharm等IDE的debug功能。 python的迭代器：相信很多初学者对代码中的“next(iter(train_set))”不太了解，这里建议大家了解iter概念、next概念、迭代器概念、以及双下划线函数概念。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年04月26日21:48:10 "},"chapter-3/3.2-dataloader.html":{"url":"chapter-3/3.2-dataloader.html","title":"3.2 DataLoader","keywords":"","body":"3.2 DataLoader dataloader简介 按照上图的顺序，本小节就来到pytorch数据加载最核心模块——DataLoader。 torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, sampler=None, batch_sampler=None, num_workers=0, collate_fn=None, pin_memory=False, drop_last=False, timeout=0, worker_init_fn=None, multiprocessing_context=None, generator=None, *, prefetch_factor=2, persistent_workers=False) 从以上可以看到，DataLoader类有14个变量，因此称为最核心模块，一点不为过。 DataLoader功能繁多，这里根据官方文档可总结为以下5大点： 支持两种形式数据集读取：map-style and iterable-style datasets, 自定义采样策略：customizing data loading order, 自动组装成批数据：automatic batching, 多进程数据加载：single- and multi-process data loading, 自动实现锁页内存（Pinning Memory）：automatic memory pinning. 支持两种形式数据集读取 两种形式的数据集分别是映射式(Map-style)与迭代式(Iterable-style)，在3.1小结中讲解的Dataset类就是映射式，因为它（getitem）提供了序号到数据的映射。迭代式则是编写一个可迭代对象，从中依次获取数据，此处不详细展开，感兴趣可以了解IterableDataset 注：往后不做特别说明，Dataset均表示映射式Dataset。 自定义采样策略 DataLoader可借助Sampler自定义采样策略，包括为每个类别设置采样权重以实现1:1的均衡采样，或者是自定义采样策略，关于Sampler会在后面小结详细展开，它是一个涨点神奇。 自动组装成批数据 mini-batch形式的训练称为了深度学习的标配，如何把数据组装成一个batch数据？DataLoader内部自动实现了该功能，并且可以通过batch_sampler、collate_fn来自定义组装的策略，十分灵活。 多进程数据加载 通常GPU运算消耗数据会比CPU读取加载数据要快，CPU“生产”跟不上GPU“消费”，因此需要多进程进行加载数据，以满足GPU的消费需求。通常指要设置num_workers 为CPU核心数，如16核的CPU就设置为16。 自动实现锁页内存（Pinning Memory） 锁页内存的概念通常在操作系统课程里才会涉及，非CS的同学可能会很懵，感兴趣的可以去了解一下。Pinning Memory是空间换时间的做法，将指定的数据“锁”住，不会被系统移动（交换）到磁盘中的虚拟内存，因此可以加快数据的读取速率。简单的可以理解为常用的衣服就“锁”在你的衣柜里，某些时候（如夏天），暂时不用的衣服——冬季大衣，则会移动到收纳柜里，以腾出空间放其它常用的衣服，等到冬天来临，需要用到大衣的时候，再从收纳柜里把大衣放到衣柜中。但是冬天拿大衣的时候就会慢一些，如果把它“锁”在你的衣柜，那么冬天获取它的时候自然快了，但占用了你的空间。这就是空间换时间的一个例子。这里的“锁”就是固定的意思，大家可补充学习一下OS的内容。 DataLoader API DataLoader提供了丰富的功能，下面介绍常用的功能，高阶功能等到具体项目中再进行分析。 dataset：不用说，它是一个Dataset实例，要能实现从索引（indices/keys）到样本的映射。（即getitem函数） batch_size：每个batch的样本量 shuffle：是否对打乱样本顺序。训练集通常要打乱它！验证集和测试集无所谓。 sampler：设置采样策略。后面会详细展开。 batch_sampler：设置采样策略， batch_sampler与sampler二选一，具体选中规则后面代码会体现。 num_workers： 设置多少个子进程进行数据加载（data loading） collate_fn：组装数据的规则， 决定如何将一批数据组装起来。 pin_memory：是否使用锁页内存，具体行为是“the data loader will copy Tensors into CUDA pinned memory before returning them” drop_last：每个epoch是否放弃最后一批不足batchsize大小的数据，即无法被batchsize整除时，最后会有一小批数据，是否进行训练，如果数据量足够多，通常设置为True。这样使模型训练更为稳定，大家千万不要理解为某些数据被舍弃了，因为每个epoch，dataloader的采样都会重新shuffle，因此不会存在某些数据被真正的丢弃。 下面通过配套代码加深dataloader的理解，并且观察DataLoader 与 Dataset是如何配合使用的。 运行代码，可看到输出如下信息： 0 torch.Size([2, 3, 224, 224]) torch.Size([2]) tensor([1, 0]) 1 torch.Size([2, 3, 224, 224]) torch.Size([2]) tensor([0, 1]) 2 torch.Size([1, 3, 224, 224]) torch.Size([1]) tensor([0]) 0 torch.Size([3, 3, 224, 224]) torch.Size([3]) tensor([0, 0, 1]) 1 torch.Size([2, 3, 224, 224]) torch.Size([2]) tensor([1, 0]) 0 torch.Size([2, 3, 224, 224]) torch.Size([2]) tensor([0, 0]) 1 torch.Size([2, 3, 224, 224]) torch.Size([2]) tensor([0, 1]) 这里主要观察batch_size和drop_last的作用，以及图片组装成batch之后的shape。 这里构建一个数据量为5的dataset，这样可以采用batchsize=2和3来观察drop_last的作用。 dataloader内部代码 下一步，我们将采用debug模式，深入dataloader内部，观察它是如何进行采样的，如何调用dataset的getitem获取数据，如何组装一个batch的。这里我们仅观察单进程模式，因此大家的num_works注意设置为0。 首先在for i, (inputs, target) in enumerate(train_loader_bs2) 设置一个断点，然后debug模式运行代码，接着持续采用 Step Into方式运行代码，下面就列出依次会进入的代码： 第一步：初始化dataloader迭代器 for i, (inputs, target) in enumerate(train_loader_bs2) DataLoader的iter() DataLoader的_get_iterator() SingleProcessDataLoaderIter的_init。 注：至此，仅完成了DataLoader的初始化，需要再一次进入dataloader才开始读取数据。 第二步：依次循环该迭代器 来到 BaseDataLoaderIter的_next：进入521行：data = self._next_data() 来到 _SingleProcessDataLoaderIter的_next_data：此函数调用了两个重要功能，第一个获取一个batch的索引，第二个获取此batch的数据。下面一个一个来看。 进入 _SingleProcessDataLoaderIter的_next_data：进入560行， index = self._next_index() 来到 _BaseDataLoaderIter的_next_index()： 这里是对sampler的包装，调用sampler获取一批索引，进入512行 来到BatchSampler的iter()：函数中有yield，这是一个迭代器，从这里可以看到sampler是如何工作的。默认情况下，这里用的是RandomSampler， 它会实现采样的顺序及频率。在本函数中，对self.sampler依次迭代，拿到足够一个batchsize的索引时，就yield。 回到 _SingleProcessDataLoaderIter的_next_data：第561行，经过index = self._next_index() ，已经获得一个batch所对应的index，接着进入self._dataset_fetcher.fetch(index) 来到 _MapDatasetFetcher的fetch：mapdataset就是前面讲到的map-style dataset。看到第49行，是一个列表生成式，在这里，调用了我们自己写的dataset，继续进入。 来到 AntsBeesDataset的getitem：进入到这里，大家就豁然开朗了吧，知道dataset是如何被dataloader使用的。下面，直接跳出去，回到 fetch看看如何组装的。 来到 _MapDatasetFetcher的fetch：第52行self.collate_fn(data)， 这里采用collate_fn对数据进行组装，继续进入。 来到 collate.py的default_collate()：这是pytorch默认的组装函数，值得大家认真学习。这个函数通常是一个递归函数，第一次进入时可以发现会来到第84行：return [default_collate(samples) for samples in transposed]。会依次再进入一次default_collate()。 这里的逻辑是这样的： 首先将dataset返回的一系列数据解包再zip，为的是将相同数据放到一起。即getitem的return返回有img和label，这里就是为了将多个img放到一起，多个label放到一起，当然大家可以在getitem返回其它有用信息（例如图片的路径）。 接着再次进入default_collate函数时，会对实际的数据进行组装。例如img的数据会进入if isinstance(elem, torch.Tensor)，然后会看到img数据是这样被组装起来的：torch.stack(batch, 0, out=out)，因此可知一个batch的图像数据第一个维度是B，整体是BCH*W。 至此，一个batch数据已经读取、加载完毕，依次跳出函数，可回到for i, (inputs, target) in enumerate(train_loader_bs2)。 这个时候，再观察inputs, target，一定会更清晰了，知道它们是如何从硬盘到模型需要的形式。并且通过上述debug过程，我们可以知道sampler的机制、collate_fn的机制，方便今后进行高级的改造。希望大家一定要debug几遍上述过程，并且记录。 小结 以上就是关于DataLoader的概念的介绍，通过两个小节相信大家对数据读取有了初步认识，可pytorch的数据处理远不止于此，它还提供了很多使用的方法，例如数据集的拼接，数据集的截取，数据的划分等，想了解怎么使用，请接着往下看。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年04月26日21:48:10 "},"chapter-3/3.3-dataset-useful-api.html":{"url":"chapter-3/3.3-dataset-useful-api.html","title":"3.3 Dataset-useful-api","keywords":"","body":"3.3 系列api 前言：2022-1月至4月完全没有更新，这三个月发生的事情太多了，国际上有俄乌，国内有上海，公司里有xxx项目，不管怎么样，过去的终将过去，继续学习PyTorch吧，加油！ 前几个小节已经把pytorch的数据读取、加载、预处理机制和逻辑关系理清楚了，下面讲一下实用的API，包括数据集的拼接、截取、划分，以及十分重要的采样策略——sampler。 concat 在实际项目中，数据的来源往往是多源的，可能是多个中心收集的，也可能是多个时间段收集，很难将可用数据统一到一个数据形式。通常有两种做法，一种是固定一个数据形式，所有获取到的数据经过整理，变为统一格式，然后用一个Dataset即可读取。还有一种更为灵活的方式是为每批数据编写一个Dataset，然后使用torch.utils.data.ConcatDataset类将他们拼接起来，这种方法可以灵活的处理多源数据，也可以很好的使用别人的数据及Dataset。 下面还是来看COVID-19的例子，大家知道想要获取大量的COVID-19数据，肯定是多源的，不同国家、不同机构、不同时间的X光片收集过来之后，如何把他们整理起来供模型训练呢？先看这个github仓库covid-chestxray-dataset，他们是这样做的，将采集到的数据统一整理，并生成metadata（元信息），但有的时候有现成的Dataset之后，我们可通过拼接的方法将所有数据拼接成一个大的dataset进行使用。 请结合代码阅读，在2.2与3.2中分别实现了COVID19Dataset、COVID19Dataset2、COVID19Dataset3，假设在项目开始时拿到了COVID19Dataset，做了一段时间来了新数据2和3，那么像把他们放到一起充当训练集，可以用concat完成。可以看到代码将3个数据集拼接得到总的数据集，数据量为2+2+2=6。这里的concatdataset其实还是一个dataset类，它内部还是有len和getitem，里面的getitem代码思路值得学习。concatdataset通过给数据集编号、所有样本编号，然后在__getitem函数中将dataloader传进来的整体样本序号进行计算，得到匹配的数据集序号，以及在该数据集内的样本编号。 可能有点绕，请看图：假设dataloader想要第5个样本，传入index=4， 这时getitem会计算第五个样本在第三个数据集的第1个位置。然后通过self.datasets[datasetidx][sampleidx]来获取数据。这样对外进行一层封装，内部实现仍旧调用各个dataset的__getitem，这样是不是很巧妙呢？ def __getitem__(self, idx): if idx len(self): raise ValueError(\"absolute value of index should not exceed dataset length\") idx = len(self) + idx dataset_idx = bisect.bisect_right(self.cumulative_sizes, idx) if dataset_idx == 0: sample_idx = idx else: sample_idx = idx - self.cumulative_sizes[dataset_idx - 1] return self.datasets[dataset_idx][sample_idx] Subset subset可根据指定的索引获取子数据集，Subset也是Dataset类，同样包含_len_和__getitem\\，其代码编写风格也可以学习一下. CLASStorch.utils.data.Subset(dataset, indices)[SOURCE] Subset of a dataset at specified indices. Parameters dataset (Dataset) – The whole Dataset indices (sequence) – Indices in the whole set selected for subset def __init__(self, dataset: Dataset[T_co], indices: Sequence[int]) -> None: self.dataset = dataset self.indices = indices def __getitem__(self, idx): if isinstance(idx, list): return self.dataset[[self.indices[i] for i in idx]] return self.dataset[self.indices[idx]] def __len__(self): return len(self.indices) 使用上非常简单，代码看一眼就明白， 这里不再赘述 random_split 该函数的功能是随机的将dataset划分为多个不重叠的子集，适合用来划分训练、验证集（不过不建议通过它进行，因为对用户而言，其划分不可见，不利于分析）。 使用也非常简单，只需要设置每个子集的数据量，传给lengths即可。 torch.utils.data.random_split(dataset, lengths, generator=)[SOURCE] Randomly split a dataset into non-overlapping new datasets of given lengths. Optionally fix the generator for reproducible results, e.g.: Parameters dataset (Dataset) – Dataset to be split lengths (sequence) – lengths of splits to be produced generator (Generator) – Generator used for the random permutation ---------------------------------------------------------------------- 分割线 ------------------------------------------------------------------ sampler 下面进入另外一个主题——sampler， sampler是在dataloader中起到挑选数据的功能，主要是设置挑选策略，如按顺序挑选、随机挑选、按类别分概率挑选等等，这些都可以通过自定义sampler实现。 在上一节我们已经用过了一个sampler，那就是batch_sampler，我们先学习一下它的用法，然后再去了解 RandomSampler， SequentialSampler， 以及SubsetRandomSampler和WeightedRandomSampler。 sampler的概念比较复杂，建议大家将BatchSampler、RandomSampler和SequentialSampler放在一起学习。 sampler 与 batch_sampler 首先讲一下dataloader类的sampler变量与batch_sampler变量的区别，在dataloader里会有这两个变量，第一次碰到时候很懵，怎么还有两个采样器，dataloader到底用的哪一个？还是两个都用？经过一番调试，终于搞清楚了。 本质上它们两个都是采样器，当采用auto_collation时，采用batch_sampler。依据如下：dataloader.py 365行 @property def _index_sampler(self): ​ if self._auto_collation: ​ return self.batch_sampler ​ else: ​ return self.sampler 来看一下两者定义： sampler (Sampler or Iterable, optional) – defines the strategy to draw samples from the dataset. Can be any Iterable with len implemented. If specified, shuffle must not be specified. batch_sampler (Sampler or Iterable, optional) – like sampler, but returns a batch of indices at a time. Mutually exclusive with batch_size, shuffle, sampler, and drop_last. 从定义可知道batch_sampler是一次返回一个batch的索引。通常我们用的都是batch_sampler，其对应的是BatchSampler类。 BatchSampler 下面先学习BatchSampler类。回顾3.3的dataloader获取一个样本的机制，会在一个self.nextindex()中调用实际的sampler迭代器，继续进入会来到BatchSampler类的__iter函数，dataloader初始化的时候根据参数配置，自动设置了采样策略为BatchSampler， 依据如下：dataloader.py 第272行代码 if batch_size is not None and batch_sampler is None: # auto_collation without custom batch_sampler batch_sampler = BatchSampler(sampler, batch_size, drop_last) dataloader.py 365行 @property def _index_sampler(self): if self._auto_collation: return self.batch_sampler else: return self.sampler 定位到了BatchSampler，下面来看看类的定义以及传进去的参数是什么。 torch.utils.data.BatchSampler(sampler, batch_size, drop_last) 后两个参数好理解，第一个参数传入的是一个sampler采样器，在这里会有两种情况，如果需要shuffle，则传入RandomSampler，不需要打乱，则传入SequentialSampler。 依据如下, dataloader.py 267行。 if shuffle: sampler = RandomSampler(dataset, generator=generator) else: sampler = SequentialSampler(dataset) 到这里，BatchSampler、RandomSampler和SequentialSampler三者之间的关系逐渐清晰. BatchSampler是在其它两者之上封装了一个批抽取的功能，一次yield一个batch的index，而样本采样的顺序取决于RandomSampler和SequentialSample。 来学习一下BatchSampler如何产生一个batch的序号，并且支持drop_last的功能。 def __iter__(self) -> Iterator[List[int]]: batch = [] for idx in self.sampler: batch.append(idx) if len(batch) == self.batch_size: yield batch batch = [] # 当for循环结束，且batch的数量又不满足batchsize时，则进入以下代码 # 其实就是drop_last的逻辑代码 if len(batch) > 0 and not self.drop_last: yield batch 理解了三者的关系（BatchSampler、RandomSampler和SequentialSampler），RandomSampler和SequentialSampler就很容易理解，来看它们的核心iter函数，学习一下如何编写顺序迭代器以及随机迭代器。 SequentialSampler 顺序迭代器没啥好说的，得到一个按顺序的迭代器。这个顺序就来自 range()函数。 def __iter__(self) -> Iterator[int]: return iter(range(len(self.data_source))) RandomSampler RandomSampler的iter函数核心在于设置一个随机策略，随机策略委托给generator实现，在使用的时候非常简单，默认情况下会使用这行代码实现：yield from torch.randperm(n, generator=generator).tolist()， 利用torch的随机方法生成一个随机整数序列，对于generator默认采用的是随机一个随机种子进行设置。更多的随机概念可以自行了解torch.Generator()、torch.randperm()。 def __iter__(self) -> Iterator[int]: n = len(self.data_source) if self.generator is None: seed = int(torch.empty((), dtype=torch.int64).random_().item()) generator = torch.Generator() generator.manual_seed(seed) else: generator = self.generator if self.replacement: for _ in range(self.num_samples // 32): yield from torch.randint(high=n, size=(32,), dtype=torch.int64, generator=generator).tolist() yield from torch.randint(high=n, size=(self.num_samples % 32,), dtype=torch.int64, generator=generator).tolist() else: yield from torch.randperm(n, generator=generator).tolist() 下面学习另外两个实用的采样器：SubsetRandomSampler和WeightedRandomSampler。 SubsetRandomSampler 顾名思义，可以通过索引定义一个子集的随机采样器，直接看代码 ``` ​ def iter(self) -> Iterator[int]: ​ for i in torch.randperm(len(self.indices), generator=self.generator): ​ yield self.indices[i] 从代码可知道，这个采样器返回的样本总数是传入的索引的长度，这里体现了subset，而随机则是每次会随机的从子集里挑选1个数据返回。 ---------------------------------------------------------------------- 分割线 ------------------------------------------------------------------ WeightedRandomSampler 不知大家是否自行处理过数据均衡采样？最简单粗暴的方法是否是把数据少的样本复制n份，直到所有类别样本数量一致，这是一种“笨”办法，其实可以通过采样器进行加权的采样，下面来看看WeightedRandomSampler。 先来看它的原型： torch.utils.data.WeightedRandomSampler(weights, num_samples, replacement=True, generator=None) Samples elements from [0,..,len(weights)-1] with given probabilities (weights). weights (sequence) – 每个样本的采样权重，权重之和不必为1，只需要关心各样本之间的比例即可。 num_samples (int) – 采样数量，一般设为样本总量。 replacement (bool) –是否有放回采样。 True，表示有放回。 generator (Generator) – 自定义生成器，通常用默认的。 在pytorch的机制里，sampler为每个sample设置权重，因此在设置的时候不仅要指定每个类的采样概率，还要把各类采样概率分发到每个样本上，再传给WeightedRandomSampler。这个机制与常识有一点点不一样，直观的理解应该是为每个类别设置采样概率就好，但这却是为每个样本设置权重，因此需要额外操作两行代码。 下面通过两个案例学习如何使用WeightedRandomSampler。 案例1： sampler初认识 # 第一步：计算每个类的采样概率 weights = torch.tensor([1, 5], dtype=torch.float) # 第二步：生成每个样本的采样概率 train_targets = [sample[1] for sample in train_data.img_info] samples_weights = weights[train_targets] # 第三步：实例化WeightedRandomSampler sampler_w = WeightedRandomSampler( ​ weights=samples_weights, ​ num_samples=len(samples_weights), ​ replacement=True) sampler的构建分三步： 计算各类的采样概率：这里手动设置，是为了让大家可以调整不同的比率，观察dataloader采出样本的变化。下一个例子中采用样本数量进行计算，来达到均衡采样。 生成每个样本的概率：从pytorch机制了解到，需要为每个样本设置采样概率，这里采用的方法是按类别分发即可。在这里有一点需要注意，就是样本标签的顺序需要与dataset中的getitem中的索引顺序保持一致！由于这里采用了dataset.img_info来维护这个顺序，因此可以轻松获得样本顺序。 实例化WeightedRandomSampler 通过运行配套代码可以看到 > torch.Size([2]) tensor([1, 1]) torch.Size([2]) tensor([1, 1]) torch.Size([2]) tensor([1, 1]) torch.Size([2]) tensor([1, 1]) torch.Size([2]) tensor([1, 0]) torch.Size([2]) tensor([1, 1]) torch.Size([2]) tensor([1, 1]) torch.Size([2]) tensor([1, 1]) torch.Size([2]) tensor([1, 1]) torch.Size([2]) tensor([1, 1]) 这里发现出现了很多次[1, 1]。这是因为有放回采样，并且样本1的采样概率比0高很多。 通过这个例子，希望大家能了解 WeightedRandomSampler的使用流程 WeightedRandomSampler采样机制可以为有放回的 有的样本在整个loader中可能不会选中 案例2：不均衡数据集进行均衡采样 点击进入配套代码 下面利用WeightedRandomSampler实现一个10类别的不均衡数据集采样，使它变为1:1的采样。 下面制作了一个虚拟的不均衡数据集，每个类别数量分别是 10， 20，..., 100。总共550张样本，下面希望通过WeightedRandomSampler实现一个dataloader，每次采样550张样本，各类别的数量大约为55。 代码的核心在于统计各类样本的数量，可仔细阅读 # 第一步：计算各类别的采样权重 # 计算每个类的样本数量 train_targets = [sample[1] for sample in train_data.img_info] label_counter = collections.Counter(train_targets) class_sample_counts = [label_counter[k] for k in sorted(label_counter)] # 需要特别注意，此list的顺序！ # 计算权重，利用倒数即可 weights = 1. / torch.tensor(class_sample_counts, dtype=torch.float) 最后可以看到每个epoch采样到的数据几乎实现1:1，可以很好的实现按照设置的权重比例采样。 > Counter({9: 100, 8: 90, 7: 80, 6: 70, 5: 60, 4: 50, 3: 40, 2: 30, 1: 20, 0: 10}) Counter({9: 100, 8: 90, 7: 80, 6: 70, 5: 60, 4: 50, 3: 40, 2: 30, 1: 20, 0: 10}) Counter({9: 100, 8: 90, 7: 80, 6: 70, 5: 60, 4: 50, 3: 40, 2: 30, 1: 20, 0: 10}) Counter({9: 100, 8: 90, 7: 80, 6: 70, 5: 60, 4: 50, 3: 40, 2: 30, 1: 20, 0: 10}) Counter({9: 100, 8: 90, 7: 80, 6: 70, 5: 60, 4: 50, 3: 40, 2: 30, 1: 20, 0: 10}) Counter({9: 100, 8: 90, 7: 80, 6: 70, 5: 60, 4: 50, 3: 40, 2: 30, 1: 20, 0: 10}) Counter({9: 100, 8: 90, 7: 80, 6: 70, 5: 60, 4: 50, 3: 40, 2: 30, 1: 20, 0: 10}) Counter({9: 100, 8: 90, 7: 80, 6: 70, 5: 60, 4: 50, 3: 40, 2: 30, 1: 20, 0: 10}) Counter({9: 100, 8: 90, 7: 80, 6: 70, 5: 60, 4: 50, 3: 40, 2: 30, 1: 20, 0: 10}) Counter({9: 100, 8: 90, 7: 80, 6: 70, 5: 60, 4: 50, 3: 40, 2: 30, 1: 20, 0: 10}) 接下来运用sampler Counter({0: 62, 4: 62, 8: 61, 9: 58, 6: 57, 3: 54, 1: 51, 7: 50, 5: 48, 2: 47}) Counter({5: 72, 7: 59, 6: 59, 8: 57, 1: 57, 0: 55, 4: 53, 2: 49, 9: 48, 3: 41}) Counter({0: 71, 3: 64, 5: 60, 9: 57, 4: 56, 2: 54, 1: 54, 6: 51, 8: 43, 7: 40}) Counter({4: 64, 7: 62, 3: 60, 8: 58, 1: 54, 5: 54, 0: 53, 6: 51, 2: 50, 9: 44}) Counter({8: 68, 0: 62, 7: 60, 6: 58, 2: 55, 3: 51, 9: 50, 5: 50, 1: 50, 4: 46}) Counter({5: 66, 4: 59, 9: 57, 0: 56, 1: 55, 3: 54, 7: 53, 2: 51, 8: 51, 6: 48}) Counter({3: 72, 9: 68, 5: 65, 6: 58, 4: 56, 8: 49, 1: 47, 2: 47, 0: 45, 7: 43}) Counter({4: 63, 2: 62, 7: 60, 9: 59, 3: 58, 8: 57, 6: 52, 0: 50, 5: 45, 1: 44}) Counter({8: 73, 3: 62, 6: 55, 0: 55, 2: 54, 4: 53, 7: 51, 1: 50, 9: 49, 5: 48}) Counter({5: 61, 3: 61, 2: 60, 9: 57, 1: 57, 7: 55, 6: 55, 4: 53, 8: 47, 0: 44}) 进一步地，为了便于大家理解“weights (sequence) – a sequence of weights, not necessary summing up to one”这句话，在代码中增加了 > # weights = 12345. / torch.tensor(class_sample_counts, dtype=torch.float) 大家可以随机修改weight的尺度，观察采样结果 关于采样策略有很多的研究，也有现成的工具库可以使用，推荐大家看看这个repo 小结 本小结将常用的dataset、dataloader配套方法进行了讲解，包括数据集的拼接、子集挑选、子集划分和sampler。其中sampler是涨点神器，推荐掌握。在sampler中，先通过代码单步调试了解RandomSampler，然后顺藤摸瓜找到SequentialSampler和SubsetRandomSampler, 最后通过两个案例详细介绍涨点神器——WeightedRandomSampler的代码编写。 同时推荐大家拓展阅读关于数据采样策略对模型精度的论文，典型的主题是——长尾分布（Long Tail） 下一小节将介绍另外一个涨点首选神器——数据增强模块。先从torchvision的transform模块讲起，然后拓展到更强大的Albumentations Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年04月26日21:48:10 "},"chapter-3/3.4-transforms.html":{"url":"chapter-3/3.4-transforms.html","title":"3.4 transforms","keywords":"","body":"3.4 transforms 本结分为两部分，首先介绍pytorch的图像数据增强函数库——transforms，分析它的工作机制，同时介绍常用的方法。 transforms简介 数据增强（Data augmentation）已经成为深度学习时代的标配，数据增强目的是为了增加训练数据的丰富度，让模型见过多样性的数据以增加模型的泛化能力。更多关于数据增强的概念，推荐大家阅读动手学的image-augmentation章节 一般地，数据增强可分为在线(online)与离线(offline)两种方式，离线方式指的是在训练开始之前将数据进行变换，变换后的图片保存到硬盘当中，在线方式则是在训练过程中，每一次加载训练数据时对数据进行变换，以实现让模型看到的图片都是增强之后的。其实，这两种方法理论上是等价的，一般的框架都采用在线方式的数据增强，pytorch的transforms就是在线方式。后续不做特别说明，数据增强特指在线数据增强。 transforms是常见图像变换库，包含二十多种基础方法以及多种组合功能，通常可以用Compose把各方法串联在一起使用。大多数的transforms类都有对应的 functional transforms ，可供用户自定义调整。transforms提供的主要是PIL格式和Tensor的变换，并且对于图像的通道也做了规定，默认情况下一个batch的数据是(B, C, H, W) 形状的张量。 在transforms库中包含二十多种对变换方法，那么多的方法里应该如何挑选，以及如何设置参数呢？ 这是值得大家仔细思考的地方，数据增强的方向一定是测试数据集中可能存在的情况。 举个例子，做人脸检测可以用水平翻转（如前置相机的镜像就是水平翻转），但不要用垂直翻转（这里指一般业务场景，特殊业务场景有垂直翻转的人脸就另说）。因为真实应用场景不存在倒转（垂直翻转）的人脸，因此在训练过程选择数据增强时就不能加垂直翻转。 运行机制 在正式介绍transforms的系列方法前，先来了解pytorch对数据增强的运行机制，我们继续通过debug模式在dataloader部分进行调试，观察一张图片是如何进行数据增强的。 同样的，我们回顾2.2小结的COVID-19代码，在dataloader中设置断点，进行debug。这里有一个小技巧，我们可以到dataset的getitem函数里设置一个断点，因为我们前面知道了图像的读取及处理是在dataset的getitem里，因此可以直接进入dataset，不必在dataloader里绕圈。当然，前提是需要大家熟悉dataloader的运行机制。 在第48行img = self.transform(img)设置断点，可以看到self.transform是一个Compose对象，继续进入self.transform(img) 来到 transforms.py 的Compose类的 __call__函数：这个函数的逻辑是依次调用compose对象里的变换方法，从此处也可看出数据是串联的，上一个方法的输出是下一个方法输入，这就要求各个方法之间传输的数据对象要一致。继续单步运行，进入第一个t(img)， 第一个t是Resize。 来到D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py的Module类的_call_impl函数：Module类是pytorch模型、网络层的核心，这个类有1854行代码，下一章将详细介绍模型模块以及Module。在这里我们暂且知道Resize这个变换方法是一个Module类，它实际的调用在1102行，进入1102行会来到Resize类的forward方法。 来到 D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\Lib\\site-packages\\torchvision\\transforms\\transforms.py的Resize类的forward函数：可以看到此函数仅一行代码F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)，继续进入它。 来到D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\Lib\\site-packages\\torch\\nn\\functional.py 的resize函数：functional模块是对一系列操作的封装，这里看到419行，resize功能的实现。继续进入419行。 来到 D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\Lib\\site-packages\\torchvision\\transforms\\functional_pil.py的resize函数：这里终于进入到最核心的Resize方法实现了，这个函数里需要时间缩放的w,h，这里的计算代码非常值得大家学习，同时函数进来之后对参数的一系列判断，也值得借鉴。从此函数可以看到它利用了PIL库的resize函数对PIL图像进行resize。最终对图像resize是这265行代码：return img.resize(size[::-1], interpolation) 然后依次返回，回到transforms.py的Compose类的call函数，此时 img = t(img)完成了1次对图像的变换。接着继续执行for循环，把compose中的变换执行完毕，就对图像做完了变换、增强。 总结一下，一开始采用transforms.Compose把变换的方法包装起来，放到dataset中；在dataloader依次读数据时，调用dataset的getitem，每个sample读取时，会根据compose里的方法依次地对数据进行变换，以此完成在线数据增强。而具体的transforms方法通常包装成一个Module类，具体实现会在各functional中。 熟悉此运行机制，便于大家今后自己编写数据增强方法，嵌入到自己的工程中。 系列API 通过单步debug，了解了transforms运行机制，下面看看transforms库提供的一系列方法及使用。更全面的方法介绍请直接看官方文档，官方文档配备了一个图解transforms的教程 这里不再一一展开各方法介绍，只挑选几个代表性的方法展开讲解，其余方法可以到第一版中阅读transforms的二十二个方法 在这里，结合COVID-2019 X光分类场景进行系列API的使用介绍。主要内容包括： 具体变换方法使用：resize、Normalize、totensor、FiveCrop、TenCrop 特殊方法使用：RandomChoice、RandomOrder、Lambda 自动数据增强：AutoAugmentPolicy、AutoAugment、RandAugment 具体变换方法使用 Compose 此类用于包装一系列的transforms方法，在其内部会通过for循环依次调用各个方法。这个在上面的代码调试过程中已经分析清楚了。 Resize Resize(size, interpolation=, max_size=None, antialias=None) 功能：支持对PIL或Tensor对象的缩放，关于size的设置有些讲究，请结合代码尝试int方式与tuple方式的差异。int方式是会根据长宽比等比例的缩放图像，这个在AlexNet论文中提到先等比例缩放再裁剪出224*224的正方形区域。 ToTensor 功能：将PIL对象或nd.array对象转换成tensor，并且对数值缩放到[0, 1]之间，并且对通道进行右移。具体地，来看源代码 ...\\Lib\\site-packages\\torchvision\\transforms\\functional.py 下的to_tensor函数 ···python img = img.permute((2, 0, 1)).contiguous() if isinstance(img, torch.ByteTensor): ​ return img.to(dtype=default_float_dtype).div(255) 对PIL对象的通道进行右移，由原来的(H x W x C)变为了(C x H x W) ， 接着对数值进行除以255，若是正常的图像像素，那么数值被缩放到了[0, 1]之间。 Normalize Normalize(mean, std, inplace=False) 功能：对tensor对象进行逐通道的标准化，具体操作为减均值再除以标准差，一般使用imagenet的128万数据R\\G\\B三通道统计得到的mean和std，mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]。相信大家今后再看到这一组数据就明白它们到底怎么来的了。 FiveCrop&TenCrop 这两个方法是AlexNet论文中提及，是一个涨点神器，具体使用方式是一张图片经过多区域裁剪得到5/10张图片，同时放到模型进行推理，得到5/10个概率向量，然后取它们的平均/最大/最小得到这一张图片的概率。 FiveCrop表示对图片进行上下左右以及中心裁剪，获得 5 张图片，并返回一个list，这导致我们需要额外处理它们，使得他们符合其它transforms方法的形式——3D-tensor。 TenCrop同理，在FiveCrop的基础上增加水平镜像，获得 10 张图片，并返回一个 list。 它们的使用与普通的transforms有一点区别，需要代码层面的一些改变，下面就通过具体例子讲解它们的注意事项。 代码 授人以渔：其余的二十多个不在一一介绍，只需要到官方文档上查看，并到配套代码中运行，观察效果即可。 特殊方法使用 PyTorch 不仅可设置对数据的操作，还可以对这些操作进行随机选择、组合，让数据增强更加灵活。 具体有以下4个方法： Lambda RandomChoice RandomOrder RandomApply Lambda 功能：可进行自定义的操作，例如上文的FiveCrop中利用lambda很好的处理了上下游transforms数据维度不一致的问题。transforms.Lambda(lambda crops: torch.stack([ToTensor()(crop) for crop in crops])) RandomChoice 功能：以一定的概率从中选择一个变换方法执行。 RandomOrder 功能：随机打乱一串变换方法。 RandomApply 功能：以一定的概率执行这一串变换方法。这与RandomChoice的区别仅在于它将一组变换看成一个选择单位，RandomChoice是一次选一个，RandomApply是一次选一组（list） 具体使用可配合配套代码 自动数据增强 从transforms丰富的变换方法以及灵活的组合函数可以知道，数据增强的策略可以千变万化，怎样的策略会更好？Google Brain团队就针对这个问题，利用它们的钞能力进行研究，采用RNN网络自动搜索组合策略，寻找较好的数据增强策略，详细可以看这篇文章AutoAugment: Learning Augmentation Strategies from Data。文章中利用RNN搜索出来的策略，可以在Imagenet、Cifar-10和SVHN三个数据集上达到当时的SOTA，pytorch中也提供了基于AutoAugment论文的三个数据集的自动数据增强策略，下面一起来学习它们。 AutoAugmentPolicy 通过论文AutoAugment: Learning Augmentation Strategies from Data我们知道它研究出了针对三个数据集的数据增强策略，在pytorch中同样的提供对应的策略，并设计了AutoAugmentPolicy来指示，直接看源代码，一目了然envs\\pytorch_1.10_gpu\\Lib\\site-packages\\torchvision\\transforms\\autoaugment.py： class AutoAugmentPolicy(Enum): \"\"\"AutoAugment policies learned on different datasets. Available policies are IMAGENET, CIFAR10 and SVHN. \"\"\" IMAGENET = \"imagenet\" CIFAR10 = \"cifar10\" SVHN = \"svhn\" AutoAugment torchvision.transforms.AutoAugment(policy: torchvision.transforms.autoaugment.AutoAugmentPolicy = , interpolation: torchvision.transforms.functional.InterpolationMode = , fill: Optional[List[float]] = None) 功能：自动数据增强方法的封装，支持三种数据增强策略，分别是IMAGENET、CIFAR10 和SVHN 参数： policy ：需要是AutoAugmentPolicy类 interpolation：设置插值方法 fill ：设置填充像素的像素值，默认为0，黑色。 AutoAugment也是一个Module类，具体的变换操作在forward()函数中体现，建议大家看看源代码，pytorch_1.10_gpu\\Lib\\site-packages\\torchvision\\transforms\\autoaugment.py 里面有详细的三组数据增强策略的顺序与参数 例如ImageNet的数据增强策略总共有25组变换，共50个变换： return [ ((\"Posterize\", 0.4, 8), (\"Rotate\", 0.6, 9)), ((\"Solarize\", 0.6, 5), (\"AutoContrast\", 0.6, None)), ((\"Equalize\", 0.8, None), (\"Equalize\", 0.6, None)), ((\"Posterize\", 0.6, 7), (\"Posterize\", 0.6, 6)), ((\"Equalize\", 0.4, None), (\"Solarize\", 0.2, 4)), ((\"Equalize\", 0.4, None), (\"Rotate\", 0.8, 8)), ((\"Solarize\", 0.6, 3), (\"Equalize\", 0.6, None)), ((\"Posterize\", 0.8, 5), (\"Equalize\", 1.0, None)), ((\"Rotate\", 0.2, 3), (\"Solarize\", 0.6, 8)), ((\"Equalize\", 0.6, None), (\"Posterize\", 0.4, 6)), ((\"Rotate\", 0.8, 8), (\"Color\", 0.4, 0)), ((\"Rotate\", 0.4, 9), (\"Equalize\", 0.6, None)), ((\"Equalize\", 0.0, None), (\"Equalize\", 0.8, None)), ((\"Invert\", 0.6, None), (\"Equalize\", 1.0, None)), ((\"Color\", 0.6, 4), (\"Contrast\", 1.0, 8)), ((\"Rotate\", 0.8, 8), (\"Color\", 1.0, 2)), ((\"Color\", 0.8, 8), (\"Solarize\", 0.8, 7)), ((\"Sharpness\", 0.4, 7), (\"Invert\", 0.6, None)), ((\"ShearX\", 0.6, 5), (\"Equalize\", 1.0, None)), ((\"Color\", 0.4, 0), (\"Equalize\", 0.6, None)), ((\"Equalize\", 0.4, None), (\"Solarize\", 0.2, 4)), ((\"Solarize\", 0.6, 5), (\"AutoContrast\", 0.6, None)), ((\"Invert\", 0.6, None), (\"Equalize\", 1.0, None)), ((\"Color\", 0.6, 4), (\"Contrast\", 1.0, 8)), ((\"Equalize\", 0.8, None), (\"Equalize\", 0.6, None)), ] 特别说明：这里反复提到的自动数据增强在实际应用中它们是固定的一组变换策略，这是获得这一组策略的过程是通过强化学习自动搜素的，所以称之为自动数据增强策略。 RandAugment RandAugment是进行N次（num_ops ）变换，变换方法从策略池中随机挑选。pytorch官方文档对于RandAugment给了较高的评价——“RandAugment is a simple high-performing Data Augmentation technique which improves the accuracy of Image Classification models.” 参数： num_ops ：执行多少次变换 magnitude ：每个变换的强度， num_magnitude_bins：与变化强度的采样分布有关 如果对autoaugmentation不熟悉的话，理解RandAugment的参数可能有点困难，这里结合代码看一看就知道了。 RandAugment仍旧是一个Module类，来看它的forward()， def forward(self, img: Tensor) -> Tensor: \"\"\" img (PIL Image or Tensor): Image to be transformed. Returns: PIL Image or Tensor: Transformed image. \"\"\" fill = self.fill if isinstance(img, Tensor): if isinstance(fill, (int, float)): fill = [float(fill)] * F.get_image_num_channels(img) elif fill is not None: fill = [float(f) for f in fill] for _ in range(self.num_ops): op_meta = self._augmentation_space(self.num_magnitude_bins, F.get_image_size(img)) op_index = int(torch.randint(len(op_meta), (1,)).item()) op_name = list(op_meta.keys())[op_index] magnitudes, signed = op_meta[op_name] magnitude = float(magnitudes[self.magnitude].item()) if magnitudes.ndim > 0 else 0.0 if signed and torch.randint(2, (1,)): magnitude *= -1.0 img = _apply_op(img, op_name, magnitude, interpolation=self.interpolation, fill=fill) return img 前面的代码段主要是根据规则获取需要进行的变换方法名称：op_name；变换的强度：magnitude，从 op_index = int(torch.randint(len(op_meta), (1,)).item()) op_name = list(op_meta.keys())[op_index] 这两行代码可以看到，每次采用的变换是随机的选择。 而变换强度magnitude则是根据一个区间里选择，不同变换方法的强度区间在这里： def _augmentation_space(self, num_bins: int, image_size: List[int]) -> Dict[str, Tuple[Tensor, bool]]: return { # op_name: (magnitudes, signed) \"Identity\": (torch.tensor(0.0), False), \"ShearX\": (torch.linspace(0.0, 0.3, num_bins), True), \"ShearY\": (torch.linspace(0.0, 0.3, num_bins), True), \"TranslateX\": (torch.linspace(0.0, 150.0 / 331.0 * image_size[0], num_bins), True), \"TranslateY\": (torch.linspace(0.0, 150.0 / 331.0 * image_size[1], num_bins), True), \"Rotate\": (torch.linspace(0.0, 30.0, num_bins), True), \"Brightness\": (torch.linspace(0.0, 0.9, num_bins), True), \"Color\": (torch.linspace(0.0, 0.9, num_bins), True), \"Contrast\": (torch.linspace(0.0, 0.9, num_bins), True), \"Sharpness\": (torch.linspace(0.0, 0.9, num_bins), True), \"Posterize\": (8 - (torch.arange(num_bins) / ((num_bins - 1) / 4)).round().int(), False), \"Solarize\": (torch.linspace(255.0, 0.0, num_bins), False), \"AutoContrast\": (torch.tensor(0.0), False), \"Equalize\": (torch.tensor(0.0), False), } TrivialAugmentWide TrivialAugment是采用NAS技术搜索得到的一组数据增强策略，推荐阅读原文TrivialAugment: Tuning-free Yet State-of-the-Art Data Augmentation 使用方法也非常简单，直接看代码即可。 想了解细节，请查看D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\Lib\\site-packages\\torchvision\\transforms\\autoaugment.py TrivialAugment核心 def _augmentation_space(self, num_bins: int) -> Dict[str, Tuple[Tensor, bool]]: return { # op_name: (magnitudes, signed) \"Identity\": (torch.tensor(0.0), False), \"ShearX\": (torch.linspace(0.0, 0.99, num_bins), True), \"ShearY\": (torch.linspace(0.0, 0.99, num_bins), True), \"TranslateX\": (torch.linspace(0.0, 32.0, num_bins), True), \"TranslateY\": (torch.linspace(0.0, 32.0, num_bins), True), \"Rotate\": (torch.linspace(0.0, 135.0, num_bins), True), \"Brightness\": (torch.linspace(0.0, 0.99, num_bins), True), \"Color\": (torch.linspace(0.0, 0.99, num_bins), True), \"Contrast\": (torch.linspace(0.0, 0.99, num_bins), True), \"Sharpness\": (torch.linspace(0.0, 0.99, num_bins), True), \"Posterize\": (8 - (torch.arange(num_bins) / ((num_bins - 1) / 6)).round().int(), False), \"Solarize\": (torch.linspace(255.0, 0.0, num_bins), False), \"AutoContrast\": (torch.tensor(0.0), False), \"Equalize\": (torch.tensor(0.0), False), } 小结 本小节详细剖析transforms运行机制，熟悉内部工作原理，大家可自行编写变换方法嵌入模型训练中。同时教授大家学习使用transforms的二十多种方法的方法——授人以渔，最后介绍了自动数据增强策略的原理及代码实践。 希望大家利用好数据增强，给自己的模型涨点，一定要记住数据增强的方向是朝着测试集（真实应用场景情况下）的数据分布、数据情况去变换，千万不要什么都往上加。 预告：原计划在本章节介绍albumentations，但由于本章未涉及图像分割、目标检测，以及本章内容也不少了，因此将albumentations放到后续章节，适时进行讲解。 为什么要用albumentations？ pytorch的transforms有什么不足么？ 当然有不足了， pytorch的transforms在处理图像分割与目标检测这一类需要图像与标签同时变换的时候不太方便（也能处理，只是不方便）。尽请期待。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年04月26日21:48:10 "},"chapter-3/3.5-torchvision-dataset.html":{"url":"chapter-3/3.5-torchvision-dataset.html","title":"3.5 torchvision 经典dataset学习","keywords":"","body":"3.5 torchvision 经典dataset学习 前面已经学习了Dataset，DataLoader，以及常用的函数，已经可以满足绝大多数的需求，但距离熟练编写自己的Dataset可能还有一段距离。 为了让大家能轻松掌握各种情况下的dataset编写，本小节对torchvision中提供的几个常见dataset进行剖析，观察它们的代码共性，总结编写dataset的经验。 X-MNIST 由于MNIST数据使用广泛，在多领域均可基于这个小数据集进行初步的研发与验证，因此基于MNIST数据格式的各类X-MNIST数据层出不穷，在mnist.py文件中也提供了多个X-MNIST的编写，这里需要大家体会类继承。 可以看到FashionMNIST、KMNIST两个dataset仅需要修改数据url（mirrors、resources）和类别名称（classes），其余的函数均可复用MNIST中写好的功能，这一点是面向对象编程优点的体现。 来看dataset的 getitem，十分简洁，因为已经把图片和标签处理好，存在self.data和self.targets中使用了： def __getitem__(self, index: int) -> Tuple[Any, Any]: img, target = self.data[index], int(self.targets[index]) img = Image.fromarray(img.numpy(), mode='L') if self.transform is not None: img = self.transform(img) if self.target_transform is not None: target = self.target_transform(target) return img, target 代码参阅：D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\Lib\\site-packages\\torchvision\\datasets\\mnist.py cifar-10 cifar-10是除MNIST之外使用最多的一个公开数据集，同样的来看它dataset的编写，奔主题 def __getitem__(self, index: int) -> Tuple[Any, Any]: img, target = self.data[index], self.targets[index] # doing this so that it is consistent with all other datasets # to return a PIL Image img = Image.fromarray(img) if self.transform is not None: img = self.transform(img) if self.target_transform is not None: target = self.target_transform(target) return img, target 核心代码还是这一行： img, target = self.data[index], self.targets[index] 那么去看看self.data和self.targets是如何从磁盘上获取的？通过代码搜索可以看到它们来自这里(D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\Lib\\site-packages\\torchvision\\datasets\\cifar.py CIFAR10 类的 init函数)： # now load the picked numpy arrays for file_name, checksum in downloaded_list: file_path = os.path.join(self.root, self.base_folder, file_name) with open(file_path, 'rb') as f: entry = pickle.load(f, encoding='latin1') self.data.append(entry['data']) if 'labels' in entry: self.targets.extend(entry['labels']) else: self.targets.extend(entry['fine_labels']) self.data = np.vstack(self.data).reshape(-1, 3, 32, 32) self.data = self.data.transpose((0, 2, 3, 1)) # convert to HWC 这一段的作用于MNIST的_load_data()， 我们的_get_img_info()一样，就是读取数据信息。 总结： getitem函数中十分简洁，逻辑简单 初始化时需完成数据信息的采集，存储到变量中，供getitem使用 VOC 前面介绍的都是玩具数据集，比较复杂的目标检测数据会不会很难写？答案是，不会，仍旧可以用我们分析出来的逻辑进行编写。 下面来看第一个大规模应用的目标检测数据集——PASCAL VOC， D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\Lib\\site-packages\\torchvision\\datasets\\voc.py的 VOCDetection类的getitem函数： def __getitem__(self, index: int) -> Tuple[Any, Any]: \"\"\" Args: index (int): Index Returns: tuple: (image, target) where target is a dictionary of the XML tree. \"\"\" img = Image.open(self.images[index]).convert(\"RGB\") target = self.parse_voc_xml(ET_parse(self.annotations[index]).getroot()) if self.transforms is not None: img, target = self.transforms(img, target) return img, target 更简洁了，与我们的案例中的getitem一样一样的，那么images和annotations从哪里来？相比大家已经知道答案了，那就是初始化的时候根据数据格式、数据组织结构，从磁盘中读取。 COCO 说到目标检测就不得不提COCO数据集，COCO数据集是微软提出的大规模视觉数据集，主要用于目标检测，它从数据量、类别量都远超VOC，对于深度学习模型的落地应用起到了推动作用。 对于CV那么重要的COCO，它的dataset难吗？答案是，不，更简单了。整个类仅40多行！ getitem函数连注释都显得是多余的： def __getitem__(self, index: int) -> Tuple[Any, Any]: id = self.ids[index] image = self._load_image(id) target = self._load_target(id) if self.transforms is not None: image, target = self.transforms(image, target) return image, target 其实，这一切得益于COCO的应用过于广泛，因此有了针对COCO数据集的轮子——pycocotools，它非常好用，建议使用COCO数据集的话，一定要花几天时间熟悉pycocotools。pycocotools里面把getitem需要的东西都准备好了，因此这个类只需要40多行代码。 小结 本章从数据模块中两个核心——Dataset&Dataloader出发，剖析pytorch是如何从硬盘中读取数据、组装数据和处理数据的。在数据处理流程中深入介绍数据预处理、数据增强模块transforms，并通过notebook的形式展示了常用的transforms方法使用，最后归纳总结torchvision中常见的dataset，为大家将来应对五花八门的任务时都能写出dataset代码。 下一章将介绍模型模块，敬请期待。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年04月26日21:48:10 "},"chapter-4/":{"url":"chapter-4/","title":"第四章 PyTorch 模型模块","keywords":"","body":"第四章 PyTorch 模型模块 第四章 PyTorch 模型模块 4.1 Module&Parameter 4.2 Module的容器 4.3 常用网络层 4.4 Module常用API函数 4.5 Hook函数及Grad-CAM 4.6 经典模型代码分析 4.7 权重初始化方法 第四章简介 上一章介绍了数据相关的Dataset、DataLoader、transforms，已经能把数据从磁盘中有序的读取并处理以及加载成batch形式。接下来就需要一个强大的模型来处理它，本章就针对模型部分进行展开，这也是深度学习最核心的地方，其中包括一个模型如何创建各网络层、各网络层如何搭建、参数如何管理与初始化、如何截取某些层的特征图等一系列问题。 首先介绍核心类——Module 再介绍常用的模块容器——Containers 接着讲解常用网络层的使用 再学习module常用函数与hook函数应用 最后介绍权重初始化方法——nn.init Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年04月26日21:48:10 "},"chapter-4/4.1-module&Parameter.html":{"url":"chapter-4/4.1-module&Parameter.html","title":"4.1 Module&Parameter","keywords":"","body":"4.1 Module & parameter Module初认识 深度学习指深度神经网络，也是我们常说的模型（Model），一个模型包含很多个网络层，多个网络层拼接构建成一个模型。在pytorch中模型是一个Module，各网络层、模块也是Module，本小节就介绍模型/模块的抽象——Module。后续不加以说明的话，模型、模块、网络层都可指代Module。 Module是所有神经网络的基类，所有的模型都必须继承于Module类，并且它可以嵌套，一个Module里可以包含另外一个Module。要想理解清楚这句话就必须清楚了解一个Module是如何工作的。在第二章我们就构建了一个Module——TinnyCNN，第三章讲解transform的时候也用到了Module，并且知道它的前向传播具体执行是在forward()函数当中，其实Module定义了一些列属性来管理模块的功能，分别用8个有序字典进行管理，分别是： self._modules = OrderedDict() self._parameters = OrderedDict() self._buffers = OrderedDict() self._backward_hooks = OrderedDict() self._forward_hooks = OrderedDict() self._forward_pre_hooks = OrderedDict() self._state_dict_hooks = OrderedDict() self._load_state_dict_pre_hooks = OrderedDict() 它们的作用分别是 modules : 存储管理nn.Module类 parameters: 存储管理nn.Parameter类 buffers：存储管理缓冲属性，如BN层中的running_mean *_hooks：存储管理钩子函数 讲到这，大家估计很懵，因为与前面接触到的内容完全搭不上边。但是这些又是Module的核心知识点，为了降低大家的学习曲线斜率，在这里暂且只需要知道一个Module有这些关键属性用于管理Module，以及在哪里找到它们——debug模式下的Protected Attributes看到它们的详情。 forward函数 除了八大核心属性之外，还有一个函数不得不了解，那就是forward函数，forward之于Module等价于getitem之于Dataset。forward函数是模型每次调用的具体实现，所有的模型必须实现forward函数，否则调用时会报错 Traceback (most recent call last): File \"E:/pytorch-tutorial-2nd/code/chapter-2/02_COVID_19_cls.py\", line 150, in main() File \"E:/pytorch-tutorial-2nd/code/chapter-2/02_COVID_19_cls.py\", line 111, in main outputs = model(data) File \"D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1102, in _call_impl return forward_call(*input, **kwargs) File \"D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 201, in _forward_unimplemented raise NotImplementedError NotImplementedError Process finished with exit code 1 到这里，总结一下Module： Module是所有模型的基类 每个module有8个字典管理它的核心属性 一个module可以包含多个子module 一个module相当于一个运算，必须实现forward函数 一个模型的创建 下面通过简单的代码慢慢去熟悉Module，回顾TinnyCNN的创建与使用，可以总结出一个模型的创建需要考虑两个要素： 构建子模块：构建网络所需要的网络层，如卷积层，池化层，全联接层等等 拼接子模块：在forward函数中定义需要执行的功能，即将子模块以一定的方式拼接起来，完成对数据的前向传播 模型的创建就像搭积木，首先收集到需要的基础部件，是三角形、正方形还是六边形，然后以一定的方式拼接起来，如果要一个屋子就先放正方形，然后放三角形。如果需要一个汽车就先放两个圆形，再放一个长方形。 同理，模型搭建也是，先知道有哪些网络层是需要的，那么再init函数里进行初始化，先让此类获得这些网络层可用。具体如何用，需要在forward函数中写清楚。就像下面这个图一样。 知道了Module有哪些关键属性，以及一个模型如何创建，下面回顾2.2小结的COVID-19分类代码，采用debug方式观察TinnyCNN的创建——model = TinnyCNN(2)， 以及它的推理： outputs = model(data) TinnyCNN的创建 代码在：code/chapter-2/02_COVID_19_cls.py 模型实例化的代码是这行： model = TinnyCNN(2) 我们打下断点，采用debug运行，进行分析如下： 进入 TinnyCNN 类的init函数：这里进行初始化，可以看到第一行就是调用父类的init函数，父类是Module，因此我们继续step into进去看看； 来到 Module类的init函数：这里会初始化那8个有序字典，以及一些关键属性，如training等。我们跳出去； 回到TinnyCNN 类的init函数：父类init函数结束，就来到自定义的组件定义部分，这里我们需要一个卷积层、一个全连接层供搭积木使用。这里的nn.Conv2d也是一个module，大家可以自行step into进去观察它的创建，这里暂且知道它是一个module即可。同理，nn.Linear也是。init函数里收集了需要搭积木的组件，下面跳出去。 回到主代码：model = TinnyCNN(2)，这样一个模型就创建好了，我们可以看到model下面就有了这些属性： 重点看红框的三个内容，分别是convolution_layer、fc和_modules。前两个没啥好说的，是init函数中自定义的类属性名称，而第三个_modules什么时候“悄悄”地记录了我们自己定义的convolution_layer和fc呢？ 这就需要大家了解一下python的基础了，请看这行代码： self.convolution_layer = nn.Conv2d(1, 1, kernel_size=(3, 3)) 在类属性赋值的时候，即这行代码中的“=”号，会调用类的__setattr__方法，在module.py的1180行代码是setatrr的实现，里面会将“=”号右边的值放到相应的地方去，如module会放到_modules里，parameter会放到_parameters里。 至此，对于模型的创建流程有了解后，下面看看模型的推理是如何进行的，它可不是简单的进入forward函数就完事了，中间还有复杂的辅助功能，一起往下看。 TinnyCNN的推理 继续采用debug，往下看。 先来到模型调用的地方：outputs = model(data)，采用step into进入； 来到Module类的call_impl函数：熟悉python的朋友就疑惑了，为什么进入的是它而不是\\_call__函数？（python规定可被调用的对象，其实现是在__call__\\函数里）其实并没有错，只Module类对call函数重命名了罢了，可以看到1148行 __call__ : Callable[..., Any] = _call_impl 在早期版本的pytorch中还没有这一层包装，请各位专家指导一下为什么采用这种方式？ 在_call_impl函数当中才会调用forward函数来实现数据的前向传播，但module除了forward调用之外，还有一些辅助功能，那就是一系列的hook函数的使用，这里暂且放下，后续会展开hook函数的作用。这里只需要关心怎么进入forward的。如果没有设置任何hook函数，则直接进行forward函数的调用 if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks or _global_forward_hooks or _global_forward_pre_hooks): return forward_call(*input, **kwargs) step into 进入 return forward_call(input, *kwargs)，就会发现来到了自定义的forward函数。 来到TinnyCNN类的forward函数：这里就是我们如何拼接网络层，组装积木的地方了。 通常会在这里调用其他module来完成数据的处理，例如使用nn.Conv2d来进行卷及操作，除了使用module对象，其它的数学运算、功能函数（如torch.nn.functionals里的系列函数）、for循环等都是可以使用的。 值得说的一点是，一些激活函数它没有可训练参数，也不是module类，因此会在forward函数中直接调用，而不需要在init中初始化。比如 ：out = F.relu(self.conv1(x)) 中的F.relu。 最后要强调一点是：forward函数中需要注意前后层数据的格式，类似transforms的实现一样，上一层的输出一定要对得上下一层的输入，否则会报错，常见的报错是Linear层接收到了不合适的数据。建议大家把TinnyCNN的forward函数的第二行注释掉：# x = x.view(x.size(0),-1)，运行代码并观察错误，这个错误是90%以上的朋友都会遇到的：RuntimeError: mat1 and mat2 shapes cannot be multiplied (12x6 and 36x2)。 到这里一个模型的搭建以及前向推理就很清晰了，构建自己的网络只需要三步： 写一个类继承于Module init函数中把需要的网络层创建好 forward函数中把模型如何搭建的规则写好 Parameter 在Module中有一个重要的对象——Parameter，参数。它继承于Tensor，与Tensor差别不太大，主要作用是用来区分可训练的参数与常规的Tensor。 在这里要做一下说明，权重、参数和超参数，它们的含义。一般情况下模型的权重就表示模型的参数，它们是可训练的，通过反向传播算法不断的更新；而超参数如卷积核大小、学习率、迭代次数是不能通过反向传播算法去更新的。很明显Parameter就指模型的参数，如卷积层的卷积核权重和偏置，Linear层的权重和偏置，BN层的α和β等等。 Module中对于参数是采用_parameters 进行管理的，并且提供相应的api可以对module内所有参数进行调用与读取。回顾2.2 COVID-19的优化器实例化这行代码： optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4) 代码中表示把model.parameters()返回的内容给优化器，让优化器更新model.parameters()，从这里可进一步理解parameter类的作用，以及各网络层它们的参数都会初始化为parameter类。 可以看看 D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\Lib\\site-packages\\torch\\nn\\modules\\conv.py的131行代码 self.weight = Parameter(torch.empty( (out_channels, in_channels // groups, *kernel_size), **factory_kwargs)) 对默认的卷积核采用empty初始化数值，然后包装成Parameter类。 小结 到这里，一个简单模型是如何创建、如何工作的我们就已经讲解完了。但随着深度神经网络的拓扑结构越来越复杂，层数越来越多，只靠上面的方法无法很好的构建神经网络，还需要借助一些容器把固定的模块封装起来，循环地进行调用。下一节将介绍Module的容器，包括以下5个 - - Sequential A sequential container. ModuleList Holds submodules in a list. ModuleDict Holds submodules in a dictionary. ParameterList Holds parameters in a list. Parameter DictHolds parameters in a dictionary. Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年04月26日21:48:10 "},"chapter-4/4.2-containers.html":{"url":"chapter-4/4.2-containers.html","title":"4.2 Module的容器","keywords":"","body":"4.2 Module容器——Containers 容器的概念出现在日常生活的方方面面，每天喝水的杯子用来装一些水，书包用来装一些办公用品，衣柜用来装一些衣服。因此，不难抽象出来容器，它是将一些东西放到一个地方进行有效管理、使用。 在深度学习模型里面，有一些网络层需要放在一起使用，如 conv + bn + relu 的组合。在module的容器是将一组操作捆绑在一起的东西，在pytorch官方文档中把Module也定义为Containers，或许是因为“Modules can also contain other Modules”。 对于Module类可查看4.1小结，这里详细介绍两个常用的容器Sequential与ModuleList，同时介绍ModuleDict，ParameterList，ParameterDict。 Sequential sequential是pytorch里使用最广泛的一个容器，它的作用是将一系列网络层按固定的先后顺序串起来，当成一个整体，调用时数据从第一个层按顺序执行到最后一个层。回顾一下transforms的Compose就可以体会到按顺序的含义了。 sequential可以直接传module，也可以传OrderedDict，OrderedDict可以让容器里的每个module都有名字，方便调用。 请看两段官方代码： model = nn.Sequential( nn.Conv2d(1,20,5), nn.ReLU(), nn.Conv2d(20,64,5), nn.ReLU() ) # Using Sequential with OrderedDict. This is functionally the # same as the above code model = nn.Sequential(OrderedDict([ ('conv1', nn.Conv2d(1,20,5)), ('relu1', nn.ReLU()), ('conv2', nn.Conv2d(20,64,5)), ('relu2', nn.ReLU()) ])) 来看一个实际案例： AlexNet是新一代CNN的开山之作，也是这一轮深度学习潮流里，计算机视觉任务的开山之作。对于现代CNN，通常会把前面的卷积层、池化层称为特征提取部分，最后的全连接层当作分类器，这一点在代码编写上将有所体现。 例如，在D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\Lib\\site-packages\\torchvision\\models\\alexnet.py 下的AlexNet，它把前面的卷积池化都放到Sequential这个容器当中，并且命名为self.features。在最后还有一个名为self.classifier的Sequential容器，它包含3个Linear层及激活函数、Dropout。这里正如下图所示，把模型大卸两块。 def forward(self, x: torch.Tensor) -> torch.Tensor: x = self.features(x) x = self.avgpool(x) x = torch.flatten(x, 1) x = self.classifier(x) return x ​ Sequential的调用 Sequential容器把一堆module包起来之后，它在forward中是如何使用的呢？ 下面请看配套代码，主要采用debug模式，观察Alexnet的forward中，两个Sequential容器是如何forward的，同时也要看看Alexnet这个模型的属性。 在 output = model(fake_input) 设置断点，step into，然后进入熟悉的_call_impl，关于module内部的代码这里直接略过，不熟悉的朋友请回到4.1小节阅读。 这里直接跳到Alexnet类的forward函数，第一行就是执行x = self.features(x)，继续step into观察这个sequential容器是如何工作的，进入它 来到了Module类下的_call_impl函数：没错，又来到了_call_impl，因为sequential它也是一个module，因此在调用self.features的时候，会进入_call_impl， 下面需要大家有耐心的进入self.features的forward函数，其实就是1102行进去； 来到Sequential类的forward函数，它十分简洁，如下所示： def forward(self, input): ​ for module in self: ​ input = module(input) ​ return input 这段代码是不是十分的熟悉呢？ transforms当中也是这样去实现一个Compose里的变换的。 从此处可知道，Sequential类的功能是将一系列网络层按固定的先后顺序串起来，当成一个整体，调用时数据从第一个层按顺序执行到最后一个层，各层之间的数据必须能对接起来。 接着回到 Alexnet的forward函数下，观察一下Alexnet这个module的属性 重点看_modules属性，它有3个key-value，其中有2个是Sequential类，因为Sequential属于module类，继续展开一个Sequential来看看 可以看到该容器下的一系列网络层，并且是排了序的，这些对于后续理解网络结构、理解网络权重加载的key是十分重要的 ModuleList ModuleList 是将各个网络层放到一个“列表”中，便于迭代的形式调用。 ModuleList与python List的区别 这里注意是“列表”而不是列表，因为ModuleList管理的module与python的List管理的module是有不同的，大家是否还记得module的setattr函数？在那里会对类属性进行判断管理，只有ModuleList里的网络层才会被管理，如果是List里的网络层则不会被管理，也就不能迭代更新了。 ModuleList 代码使用 假设要构建一个10层的全连接网络，如果用Sequential，那就要手写10行nn.Linear，而用ModuleList是这样的： class MyModule(nn.Module): def __init__(self): super(MyModule, self).__init__() self.linears = nn.ModuleList([nn.Linear(10, 10) for i in range(10)]) # self.linears = [nn.Linear(10, 10) for i in range(10)] # 观察model._modules，将会是空的 def forward(self, x): for sub_layer in self.linears: x = sub_layer(x) return x 需要对python的 list进行一个ModuleList封装，这样才可以在model的_modules属性下看到创建的10个Linear层。 推荐大家看看class ModuleList(Module)的实现，里边并不会像Sequential那样提供forward，即管理的网络层由用户自行调用，可以for循环全用，也可以通过if判断，有条件的选择部分网络层使用。同时ModuleList也提供了类似List的方法，insert\\append\\extend等。 ModuleDict ModuleList可以像python的List一样管理各个module，但对于索引而言有一些不方便，因为它没有名字，需要记住是第几个元素才能定位到指定的层，这在深度神经网络中有一点不方便。 而ModuleDict就是可以像python的Dict一样为每个层赋予名字，可以根据网络层的名字进行选择性的调用网络层。 请看代码 class MyModule2(nn.Module): def __init__(self): super(MyModule2, self).__init__() self.choices = nn.ModuleDict({ 'conv': nn.Conv2d(3, 16, 5), 'pool': nn.MaxPool2d(3) }) self.activations = nn.ModuleDict({ 'lrelu': nn.LeakyReLU(), 'prelu': nn.PReLU() }) def forward(self, x, choice, act): x = self.choices[choice](x) x = self.activations[act](x) return x ParameterList & ParameterDict 除了Module有容器，Parameter也有容器。与ModuleList和ModuleDict类似的，Paramter也有List和Dict，使用方法一样，这里就不详细展开，可以参考Module的容器。 可以看两段官方文档代码感受一下 class MyModule(nn.Module): def __init__(self): super(MyModule, self).__init__() self.params = nn.ParameterDict({ 'left': nn.Parameter(torch.randn(5, 10)), 'right': nn.Parameter(torch.randn(5, 10)) }) def forward(self, x, choice): x = self.params[choice].mm(x) return x # ParaemterList class MyModule(nn.Module): def __init__(self): super(MyModule, self).__init__() self.params = nn.ParameterList([nn.Parameter(torch.randn(10, 10)) for i in range(10)]) def forward(self, x): # ParameterList can act as an iterable, or be indexed using ints for i, p in enumerate(self.params): x = self.params[i // 2].mm(x) + p.mm(x) return x 小结 随着深度神经网络拓扑结构越来越复杂，网络模块多、杂、乱，因此需要Module容器来管理、组织各个网络层，便于forward函数中调用。 使用频率最高的是Sequential，其次是ModuleList，其余的均为进阶用法，在各类魔改网络中才会涉及。 这里深刻理解Sequential的机制、理解一个module是如何把Sequential里的module管理到自己的_modules属性中，对于后续使用模型是非常重要的。 熟悉了Module类，各种容器封装，下一小节将介绍一些常用的网络层，如卷积、池化、全连接、激活函数等。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年04月26日21:48:10 "},"chapter-4/4.3-common-module.html":{"url":"chapter-4/4.3-common-module.html","title":"4.3 常用网络层","keywords":"","body":"4.3 常用网络层 本小节将介绍几个常用的layers，核心目的是传授如何学习各layers的方法，今后更多layers也可自行从官方文档中学习。 Convolutional Layers 卷积整体分两大类，正常卷积与转置卷积（Transpose Convolution），除此之外还有Lazy系列的正常卷积与转置卷积，Lazy系列就是懒惰系列，为那些懒得计算输入特征图的通道数的人设计的，经过第一次forward之后，该网络层的in_channels将被确定。 下面通过官方文档详细学习Conv2d这个卷积层，在文档中会详细介绍该层的功能，各参数含义，计算公式，以及示例代码。 torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros') 主要功能：对多个二维平面组成的信号进行二维卷积 主要参数： in_channels (int) – Number of channels in the input image。输入这个网络层的图像的通道数是多少。 out_channels (int) – Number of channels produced by the convolution。此网络层输出的特征图的通道数是多少，等价于卷积核数量是多少。 kernel_size (int or tuple) – Size of the convolving kernel。卷积核大小。 stride (int or tuple, optional) – Stride of the convolution. Default: 1。卷积核卷积过程的步长。 padding (int, tuple or str, optional) – Padding added to all four sides of the input. Default: 0。对于输入图像的四周进行填充的数量进行控制，可指定填充像素数量，也可以指定填充模式，如\"same\", \"valid\"，具体含义参见文档，这是从TF中借鉴过来的。 padding_mode (string, optional) – 'zeros', 'reflect', 'replicate' or 'circular'. Default: 'zeros'。填充的像素值如何确定。默认填充0。 dilation (int or tuple, optional) – Spacing between kernel elements. Default: 1。孔洞卷积的孔洞大小。 groups (int, optional) – Number of blocked connections from input channels to output channels. Default: 1。分组卷积的分组。 bias (bool, optional) – If True, adds a learnable bias to the output. Default: True。是否采用偏置。 nn.Conv2d是图像领域里99%模型都用到的，它的计算公式及细节需要大家了如指掌，具体公式如下：` 这里建议大家结合各种动图进行学习，推荐这个repo， Pooling Layers Pooling layer叫池化层，池化是形象词，就像下雨天篮球场上低洼的地方会聚集周围的雨水一样，由大变小的过程。 自然它的作用是将特征图分辨率变小，通常减小一半。如下图所示，相同颜色的区域”池化“为1个像素，4x4的图像变为了2x2的图像。 图片来源:https://www.geeksforgeeks.org/cnn-introduction-to-pooling-layer/ 1个像素代替4个像素，那应该用什么值呢？针对这个问题的解决方法，可对池化层进行划分为最大值池化、平均值池化、分数阶池化、基于范数的池化。分别对应torch.nn中的Maxpool, Avgpool, FractionalMaxPool, LPPool。 由于它们只是在计算像素时才用的方法不同，下面就以Maxpool为例讲解池化层。 torch.nn.MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False) 功能：2D最大池化 参数： kernel_size – 池化窗口大小 stride – 滑窗步长 padding – 原图填充大小 dilation – 孔洞大小 return_indices – 是否返回最大值所在位置，主要在 torch.nn.MaxUnpool2d 中使用，是上采样的一种策略 ceil_mode – 当无法整除时，是向下取整还是向上取整，默认为向下。 池化层输出特征图的大小计算公式如下，细心的朋友会发现它与卷积层是一样的。 针对最大池化还有一个特殊的地方是它可以记录最大值所在的位置，供上采样时（MaxUnpool2d）所用，这个在图像分割任务中会有涉及。MaxUnpool2d的使用非常简单，参数设置很容易。原型如下： torch.nn.MaxUnpool2d(kernel_size, stride=None, padding=0)，具体使用可看配套代码。 自适应池化层 上面针对池化像素如何取值进行划分，其实针对窗口大小的选择也可划分，还有另外一种特殊的池化方法，那就是AdaptiveXpool， 它的作用是自适应窗口大小，保证经过池化层之后的图像尺寸是固定的，这个在接入全连接层之前经常会见到。 使用也很方便，只需要设置想要的输出大小即可，详细可见配套代码。torch.nn.AdaptiveMaxPool2d(output_size, return_indices=False) Padding Layers Padding layer在许多魔改网络中常用到，功能是给特征图周围填充一定的像素，调整特征图分辨率的一种方法。既然是填充就涉及两个问题，填充多少个像素？像素应该如何确定？ 针对第二个问题，可将padding layer划分为三类，镜像填充、边界重复填充，指定值填充、零值填充，分别对应nn的三大类，nn.ReflectionPad2d， nn.ReplicationPad2d， nn.ZeroPad2d， nn.ConstantPad2d，使用非常简单，详细可见配套代码。 Linear Layers Linear Layers包含4个层分别是nn.Identity，nn.Linear， nn.Bilinear， nn.LazyLinear nn.Identity 是恒等映射，不对输入做任何变换，它通常用于占位。 nn.Linear 就是大家熟悉的全连接层(Fully Connection Layer)，可实现 y= Wx + b nn.Bilinear 是双线性层，它有两个输入，实现公式 y = x1Wx2 +b nn.LazyLinear 是nn.Linear的lazy版本，也就是懒惰的Linear层，它在第一次推理时自动根据输入特征图的尺寸来设定in_features，免去了手动计算in_features的麻烦。 Linear层十分简单，就不用代码演示了。 Normaliation Layers Normaliation Layers 里包含主流的标准化网络层，分别有BN、LN、IN、GN以及早期的LRN。这一些列的层已经成为现在深度学习模型的标配，它们充当一种正则，对数据的分布进行变换，使数据分布变到0均值，1标准差的形式。实验结果发现这样做可以加速模型训练，让模型更稳定，精度更高。 其中最出名的当属2015年提出的BatchNorm, 来自于Google团队的Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift，关于BN的介绍网上有很多文章，大家可自行学习，在代码实现上我们需要熟悉网络层内部的参数，以及训练与推理过程中的差异。 BatchNorm 会对输入进行减均值、除以标准差、乘以γ、加β的操作。如下图所示： 其中γ与β是Parameter，是可训练的参数，与卷积层的卷积核、FC层的权重一样，容易理解。 均值与标准差就没那么简单了，在训练过程，它们是通过指数移动平均统计得来，在测试时则是用固定的、不会再变化的均值和方差。 从此也可知道，当模型设置在训练状态(model.train() )与推理状态(model.eval() )时，BN层的操作输出是会不一样的。 方法原型如下： torch.nn.BatchNorm2d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, device=None, dtype=None) num_features – 输入的通道数，该参数将决定BN层有多少个γ和β eps – 分母增加的一个小数，防止除以0，默认值为1e-5 momentum – 指数滑动平均的动量值，Default: 0.1 affine – 是否执行乘以γ、加β的操作，要理解为什么叫affine需要去看论文。Default: True track_running_stats – 是否需要执行记录统计均值、统计方差。默认是开启的，如果不开启，则计算时的均值方差只来自当前batch的计算值。 Default: True 具体使用方法详细可见配套代码，请尝试调整各个参数，观察输出的变化以及网络层本身参数的变化。 BN提出之后几乎成了深度学习模型的标配，但在一些任务中BN的均值、方差计算方式就不太适用了，针对均值、方差的统计方式不同，就有了GN、LN、IN。 GN是针对batch size小（一些任务占显存大，只能用小batch跑），统计的均值方差存在较大差异而提出的分组进行统计，详细参见：Group Normalization LN是针对RNN这样的序列网络设计的，以层为单位进行统计均值、方差，详细参见：Layer Normalization IN是针对风格迁移这类GAN任务中，不同风格实例的差异较大，以实例为单位进行统计均值、方差，详细参见：Instance Normalization: The Missing Ingredient for Fast Stylization LRN是2012年深度学习图像领域开山之作——AlexNet中采用的正则化方法，现在很少采用，详细参见：ImageNet Classifification with Deep Convolutional Neural Networks Dropout Layers Dropout——随机失活和LRN一样在Alexnet论文中所采用，以防止模型过拟合，针对它的正则化作用探讨可参见由Hinton一作发表的论文Improving neural networks by preventing co-adaptation of feature detectors。 Dropout 的操作非常简单，以概率p随机的让部分神经元暂时失活，失活表示它不与任何神经元连接，如下图所示： 图片出自：《Dropout: A Simple Way to Prevent Neural Networks from Overfitting》 训练过程的每一次forward，都会重新进行随机失活。在测试（推理）过程，所有神经元都参与工作，不再采用随机失活。更详细的操作及理论分析，推荐阅读《Dropout: A Simple Way to Prevent Neural Networks from Overfitting》。 Dropout使用注意事项： Dropout通常用于nn.Linear层之前； Dropout执行后，神经元个数会减少，导致数据尺度发生变化. 论文中给出的方法是在测试时，需要将神经元数据尺度缩放 1/p倍，因为在训练时候减少了p倍。（p为随机失活的概率）。但在工程应用的时候，最好是减少推理的步骤，于是pytorch把数据尺度的缩放弄到了训练中，在训练时，对数据进行1/(1-p)的放大。（Furthermore, the outputs are scaled by a factor of 1/(1-p) during training. ） 关于数据尺度缩放，这里设计了验证实验，可到配套代码中运行并查看。 Alpha Dropout Dropout的随机失活会导致数据分布的变化，而数据分布对于模型训练的稳定是非常关键的，因此有针对这个问题提出了一种保持输入均值和方差不变的Dropout——Alpha Dropout。理论分析建议阅读论文Self-Normalization Neural Networks FeatureAlphaDropout是基于通道维度进行的，并且不同于Dropout的置零，它是将神经元设置为SELU激活函数的负饱和值，通常 Alpha Dropout都是搭配SELU激活函数的，具体推导还是要看论文Self-Normalization Neural Networks，一篇102页的论文。 Non-linear Layers 非线性激活函数是深度学习的命根子，倘若没有非线性变换函数，那么1亿层的Linear层堆叠，也只能等价于1层网络（通过矩阵乘法法则可推导）。因此非线性激活函数是深度学习之所以能称之为深度的重要因素。 对于非线性激活函数，pytorch划分为了两大类，这是非常合理的！分别是Non-linear Activations (weighted sum, nonlinearity) 和Non-linear Activations (other)。 其实可以作用进行划分 为了对神经元进行非线性变换的称为非线性激活函数 为了对输出神经元进行Softmax的、变为概率分布形式的称为特殊非线性激活函数 更通俗的划分是： 非softmx的； softmax系列； 对于非softmax，大家肯定不陌生，如sigmoid、tanh、ReLU、PReLU等，这些就不过多介绍，请大家自行查阅文档 对于softmax需要简单讲一讲，softmax的作用是将一个向量转换为一个概率分布的形式，以便于实现loss的计算，计算过程如下图所示： 计算公式如下： 看着一头雾水，其实很好理解。一个概率向量它的要求至少有这两个 非负 求和等于1 对于非负，用上幂函数，就可以实现了； 对于求和对于1，那就所有元素除以一个求和项，所有元素再加起来的时候分子就等于分母，自然求和等于1了，Softmax的设计思路真巧妙！ 对于Softmax系列的激活函数，可参考文档 小结 到这里对pytorch常用的网络层接口进行了介绍与代码分析，由于深度学习模型发展迅速，难以详尽介绍每一个网络层的使用，但pytorch都有详细的文档可以学习，希望大家可以通过本节内容学习如何学习pytorch的系列函数、类方法使用。 本小节配套代码中有这些网络层的演示： 更多更详细的网络层使用介绍，可查看文档中的目录，这里简介每个主题的内容 Containers： 模型容器 Convolution Layers：卷积层 Pooling layers：池化层 Padding Layers：填充层 Non-linear Activations (weighted sum, nonlinearity)：非线性激活函数 Non-linear Activations (other)：Softmax系列激活函数 Normalization Layers：标准化层 Recurrent Layers：RNN 网络层 Transformer Layers： Transformer 网络层 Linear Layers：线性层 Dropout Layers： 随机失活层 Sparse Layers：稀疏网络层 Distance Functions：计算距离函数 Loss Functions：计算损失函数 Vision Layers：CV任务网络层 Shuffle Layers：随机打乱功能层 DataParallel Layers (multi-GPU, distributed)：多GPU网络层，多gpu需要用层的概念进行包装 Utilities：各功能函数层 Quantized Functions：量化功能函数 Lazy Modules Initialization：“懒惰”初始化功能模块 到这里，Module的类型就介绍完毕，下一小节将学习Module内部有哪些api，如何使用它们对一个Module进行管理，如模型的网络层查看、管理，模型的参数查看、管理，以及Hook函数的用法。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年04月26日21:48:10 "},"chapter-4/4.4-module-api.html":{"url":"chapter-4/4.4-module-api.html","title":"4.4 Module常用API函数","keywords":"","body":"4.4 Module常用函数 本小节汇总介绍Module常用的方法，由于文档中是按首字母排序进行展示所有方法，未按用途进行归类，不便于理解各函数之间的关系。在这里，特地把相同功能、成对的函数放到一起，供大家参考学习。 常用方法包括： 设置模型训练、评估模式 eval train 设置模型存放在cpu/gpu/xpu cpu cuda to xpu 获取模型参数、加载权重参数 load_state_dict state_dict 管理模型的modules, parameters, sub_module parameters children modules named_children named_modules named_parameters get_parameter get_submodule add_module 设置模型的参数精度，可选半精度、单精度、双精度等 bfloat16 half float double 对子模块执行特定功能 apply zero_grad 以上是不完全的列举，有些非高频使用的函数请到文档中查阅。下面通过简介和配套代码的形式学习上述函数的使用。 设置模型训练、评估模式 eval：设置模型为评估模式，这一点与上小节介绍的BN，Dropout息息相关，即评估模式下模型的某些层执行的操作与训练状态下是不同的。 train：设置模型为训练模式，如BN层需要统计runing_var这些统计数据，Dropout层需要执行随机失活等。 使用方法太简单，不做代码展示。 设置模型存放在cpu/gpu 对于gpu的使用会在后面设置单独小节详细介绍，由于这里是基础学习，暂时可不考虑运算速度问题。这里既然遇到了相关的概念，就简单说一下。 pytorch可以利用gpu进行加速运算，早期只支持NVIDIA公司的GPU，现在也逐步开始支持AMD的GPU。使用gpu进行运算的方法很简单，就是把需要运算的数据放到gpu即可。方法就是 xxx.cuda()，若想回到cpu运算，那就需要xxx.cpu()即可。不够有一种更好的方法就是to()，to方法可将对象放到指定的设备中去，如to.(\"cpu\") 、 to.(\"cuda)、to(\"cuda:0\") 等。 cpu：将Module放到cpu上。 cuda：将Module放到cuda上。为什么是cuda不是gpu呢？因为CUDA（Compute Unified Device Architecture）是NVIDIA推出的运算平台，数据是放到那上面进行运算，而gpu可以有很多个品牌，因此用cuda更合理一些。 to：将Module放到指定的设备上。 关于to通常会配备torch.cuda.is_available()使用，请看配套代码学习。 获取模型参数、加载权重参数 模型训练完毕后，我们需要保存的核心内容是模型参数，这样可以供下次使用，或者是给别人进行finetune。相信大家都用ImageNet上的预训练模型，而使用方法就是官方训练完毕后保存模型的参数，供我们下载，然后加载到自己的模型中。在这里就涉及两个重要操作：保存模型参数与加载模型参数，分别要用到以下两个函数。 state_dict：返回参数字典。key是告诉你这个权重参数是放到哪个网络层。 load_state_dict：将参数字典中的参数复制到当前模型中。这里的复制要求key要一一对应，若key对不上，自然模型不知道要把这个参数放到哪里去。绝大多数开发者都会在load_state_dict这里遇到过报错，如 RuntimeError: Error(s) in loading state_dict for ResNet: Missing key(s) in state_dict: xxxxxxxx 　　Unexpected key(s) in state_dict: xxxxxxxxxx 这通常是拿到的参数字典与模型当前的结构不匹配。 对于load_state_dict函数，还有两个参数可以设置，请看原型： 参数： state_dict (dict) – a dict containing parameters and persistent buffers. strict (bool, optional) – whether to strictly enforce that the keys in state_dict match the keys returned by this module’s state_dict() function. Default: True 返回项 missing_keys is a list of str containing the missing keys unexpected_keys is a list of str containing the unexpected keys 上述两个方法具体的使用请看配套代码。 管理模型的modules, parameters, sub_module 模型中需要管理的主要是parameter与module，每个对象都有两种方式读取，分别是带名字和不带名字的。针对module还有一个称为children的方法，它与modules方法最大的不同在于modules会返回module本身。具体差异通过配套代码一看便明了。 parameters：返回一个迭代器，迭代器可抛出Module的所有parameter对象 named_parameters：作用同上，不仅可得到parameter对象，还会给出它的名称 modules：返回一个迭代器，迭代器可以抛出Module的所有Module对象，注意：模型本身也是module，所以也会获得自己。 named_modules：作用同上，不仅可得到Module对象，还会给出它的名称 children：作用同modules，但不会返回Module自己。 named_children：作用同named_modules，但不会返回Module自己。 获取某个参数或submodule 当想查看某个部分数据时，可以通过get_xxx方法获取模型特定位置的数据，可获取parameter、submodule，使用方法也很简单，只需要传入对应的name即可。 get_parameter get_submodule 设置模型的参数精度，可选半精度、单精度、双精度等 为了调整模型占存储空间的大小，可以设置参数的数据类型，默认情况是float32位（单精度），在一些场景可采用半精度、双精度等，以此改变模型的大小或精度。Module提供了几个转换权重参数精度的方法，分别如下： half：半精度 float：单精度 double：双精度 bfloat16：Brain Floating Point 是Google开发的一种数据格式，详细参见wikipedia 对子模块执行特定功能 zero_grad：将所有参数的梯度设置为0，或者None apply：对所有子Module执行指定fn(函数)，常见于参数初始化。这个可以参见配套代码。 小结 本节对Module的常用API函数进行了介绍，包括模型两种状态，模型存储于何种设备，模型获取参数，加载参数，管理模型的modules，设置模型参数的精度，对模型子模块执行特定功能。 由于Module是核心模块，其涉及的API非常多，短时间不好消化，建议大家结合代码用例，把这些方法都过一遍，留个印象，待日后项目开发需要的时候知道有这些函数可以使用即可。 下一小节将介绍Module中的Hook函数。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年04月26日21:48:10 "},"chapter-4/4.5-hook-func.html":{"url":"chapter-4/4.5-hook-func.html","title":"4.5 Hook函数及Grad-CAM","keywords":"","body":"4.5 hook函数 注：本小节主要参考《PyTorch模型训练实用教程》（第一版），主要更新了PyTorch新版本的函数——torch.nn.Module.register_full_backward_hook。 -------------------------------------------------分割线--------------------------------------------------------------- 本小节将介绍Module中的三个Hook函数以及Tensor的一个Hook函数 torch.Tensor.register_hook torch.nn.Module.register_forward_hook torch.nn.Module.register_forward_pre_hook torch.nn.Module.register_full_backward_hook 同时使用hook函数优雅地实现Grad-CAM，效果如下图所示： ​ Grad-CAM是CAM(class activation map，类激活图)的改进，可对任意结构的CNN进行类激活可视化，不需要修改网络结构或者重新训练，详细理论请参见Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization 什么是hook？ Hook函数在多门编程语言中均有出现，是一个经典的编程方式。hook意为钩、挂钩、鱼钩。 引用知乎用户“马索萌”对hook的解释：“(hook)相当于插件。可以实现一些额外的功能，而又不用修改主体代码。把这些额外功能实现了挂在主代码上，所以叫钩子，很形象。” 简单讲，就是不修改主体，而实现额外功能。对应到在pytorch中，主体就是forward和backward，而额外的功能就是对模型的变量进行操作，如“提取”特征图，“提取”非叶子张量的梯度，修改张量梯度等等。 hook的出现与pytorch运算机制有关，pytorch在每一次运算结束后，会将中间变量释放，以节省内存空间，这些会被释放的变量包括非叶子张量的梯度，中间层的特征图等。 但有时候，想可视化中间层的特征图，又不能改动模型主体代码，该怎么办呢？这时候就要用到hook了。 举个例子演示hook提取非叶子张量的梯度： import torch def grad_hook(grad): y_grad.append(grad) y_grad = list() x = torch.tensor([[1., 2.], [3., 4.]], requires_grad=True) y = x+1 y.register_hook(grad_hook) z = torch.mean(y*y) z.backward() print(\"type(y): \", type(y)) print(\"y.grad: \", y.grad) print(\"y_grad[0]: \", y_grad[0]) >>> ('type(y): ', ) >>> ('y.grad: ', None) >>> ('y_grad[0]: ', tensor([[1.0000, 1.5000], [2.0000, 2.5000]])) 可以看到y.grad的值为None，这是因为y是非叶子结点张量，在z.backward()完成之后，y的梯度被释放掉以节省内存，但可以通过torch.Tensor的类方法register_hook将y的梯度提取出来。 torch.Tensor.register_hook torch.Tensor.register_hook (Python method, in torch.Tensor.register_hook) 功能：注册一个反向传播hook函数，这个函数是Tensor类里的，当计算tensor的梯度时自动执行。 为什么是backward？因为这个hook是针对tensor的，tensor中的什么东西会在计算结束后释放？ 那就是gradient，所以是backward hook. 形式： hook(grad) -> Tensor or None ，其中grad就是这个tensor的梯度。 返回值：a handle that can be used to remove the added hook by calling handle.remove() 应用场景举例：在hook函数中可对梯度grad进行in-place操作，即可修改tensor的grad值。 这是一个很酷的功能，例如当浅层的梯度消失时，可以对浅层的梯度乘以一定的倍数，用来增大梯度； 还可以对梯度做截断，限制梯度在某一区间，防止过大的梯度对权值参数进行修改。 下面举两个例子，例1是如何获取中间变量y的梯度，例2是利用hook函数将变量x的梯度扩大2倍。 例1： import torch y_grad = list() def grad_hook(grad): y_grad.append(grad) x = torch.tensor([2., 2., 2., 2.], requires_grad=True) y = torch.pow(x, 2) z = torch.mean(y) h = y.register_hook(grad_hook) z.backward() print(\"y.grad: \", y.grad) print(\"y_grad[0]: \", y_grad[0]) h.remove() # removes the hook >>> ('y.grad: ', None) >>> ('y_grad[0]: ', tensor([0.2500, 0.2500, 0.2500, 0.2500])) 可以看到当z.backward()结束后，张量y中的grad为None，因为y是非叶子节点张量，在梯度反传结束之后，被释放。 在对张量y的hook函数（grad_hook）中，将y的梯度保存到了y_grad列表中，因此可以在z.backward()结束后，仍旧可以在y_grad[0]中读到y的梯度为tensor([0.2500, 0.2500, 0.2500, 0.2500]) 例2： import torch def grad_hook(grad): grad *= 2 x = torch.tensor([2., 2., 2., 2.], requires_grad=True) y = torch.pow(x, 2) z = torch.mean(y) h = x.register_hook(grad_hook) z.backward() print(x.grad) h.remove() # removes the hook >>> tensor([2., 2., 2., 2.]) 原x的梯度为tensor([1., 1., 1., 1.])，经grad_hook操作后，梯度为tensor([2., 2., 2., 2.])。 torch.nn.Module.register_forward_hook 功能：Module前向传播中的hook,module在前向传播后，自动调用hook函数。 形式：hook(module, input, output) -> None or modified output 。注意不能修改input和output 返回值：a handle that can be used to remove the added hook by calling handle.remove() 举例：假设网络由卷积层conv1和池化层pool1构成，输入一张4*4的图片，现采用forward_hook获取module——conv1之后的feature maps，示意图如下： ​ import torch import torch.nn as nn class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv1 = nn.Conv2d(1, 2, 3) self.pool1 = nn.MaxPool2d(2, 2) def forward(self, x): x = self.conv1(x) x = self.pool1(x) return x def farward_hook(module, data_input, data_output): fmap_block.append(data_output) input_block.append(data_input) if __name__ == \"__main__\": # 初始化网络 net = Net() net.conv1.weight[0].fill_(1) net.conv1.weight[1].fill_(2) net.conv1.bias.data.zero_() # 注册hook fmap_block = list() input_block = list() net.conv1.register_forward_hook(farward_hook) # inference fake_img = torch.ones((1, 1, 4, 4)) # batch size * channel * H * W output = net(fake_img) # 观察 print(\"output shape: {}\\noutput value: {}\\n\".format(output.shape, output)) print(\"feature maps shape: {}\\noutput value: {}\\n\".format(fmap_block[0].shape, fmap_block[0])) print(\"input shape: {}\\ninput value: {}\".format(input_block[0][0].shape, input_block[0])) 首先初始化一个网络，卷积层有两个卷积核，权值分别为全1和全2，bias设置为0，池化层采用2*2的最大池化。 在进行forward之前对module——conv1注册了forward_hook函数，然后执行前向传播（output=net(fake_img)），当前向传播完成后， fmap_block列表中的第一个元素就是conv1层输出的特征图了。 这里注意观察farward_hook函数有data_input和data_output两个变量，特征图是data_output这个变量，而data_input是conv1层的输入数据， conv1层的输入是一个tuple的形式。 hook函数调用逻辑 下面剖析一下module是怎么样调用hook函数的呢？ output = net(fakeimg) net是一个module类，对module执行 module(input)是会调用module._call module.call ：会进入_call_impl，回顾Module那一小节，call_impl是有很多其它代码，这就是对hook函数的处理，可以看到，让注册了hook函数，模型的forward不再是4.1小节里分析的1102行代码进行，而是分别执行对应的hook函数。1109行是执行每个forward_pre_hook的，1120行是执行forward的，1123行是执行forward_hook的， 1144行是执行full_backward_hook的。 def _call_impl(self, *input, **kwargs): forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward) # If we don't have any hooks, we want to skip the rest of the logic in # this function, and just call forward. if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks or _global_forward_hooks or _global_forward_pre_hooks): return forward_call(*input, **kwargs) # Do not call functions when jit is used full_backward_hooks, non_full_backward_hooks = [], [] if self._backward_hooks or _global_backward_hooks: full_backward_hooks, non_full_backward_hooks = self._get_backward_hooks() if _global_forward_pre_hooks or self._forward_pre_hooks: for hook in (*_global_forward_pre_hooks.values(), *self._forward_pre_hooks.values()): result = hook(self, input) if result is not None: if not isinstance(result, tuple): result = (result,) input = result bw_hook = None if full_backward_hooks: bw_hook = hooks.BackwardHook(self, full_backward_hooks) input = bw_hook.setup_input_hook(input) result = forward_call(*input, **kwargs) if _global_forward_hooks or self._forward_hooks: for hook in (*_global_forward_hooks.values(), *self._forward_hooks.values()): hook_result = hook(self, input, result) if hook_result is not None: result = hook_result if bw_hook: result = bw_hook.setup_output_hook(result) # Handle the non-full backward hooks if non_full_backward_hooks: var = result while not isinstance(var, torch.Tensor): if isinstance(var, dict): var = next((v for v in var.values() if isinstance(v, torch.Tensor))) else: var = var[0] grad_fn = var.grad_fn if grad_fn is not None: for hook in non_full_backward_hooks: wrapper = functools.partial(hook, self) functools.update_wrapper(wrapper, hook) grad_fn.register_hook(wrapper) self._maybe_warn_non_full_backward_hook(input, result, grad_fn) return result 这里需要注意两点： hook_result = hook(self, input, result)中的input和result不可以修改。这里的input对应forward_hook函数中的data_input，result对应forward_hook函数中的data_output，在conv1中，input就是该层的输入数据，result就是经过conv1层操作之后的输出特征图。虽然可以通过hook来对这些数据操作，但是不能修改这些值，否则会破坏模型的计算。 注册的hook函数是不能带返回值的，否则抛出异常，这个可以从代码中看到 if hook_result is not None: raise RuntimeError 总结一下调用流程： net(fake_img) --> net.call : result = self.forward(input, *kwargs) --> net.forward: x = self.conv1(x) --> conv1.call:hook_result = hook(self, input, result) hook就是注册了的forward_hook函数。 torch.nn.Module.register_forward_pre_hook 功能：执行forward()之前调用hook函数。 形式：hook(module, input) -> None or modified input 应用场景：register_forward_pre_hook与forward_hook一样，是在module.call中注册的，与forward_hook不同的是，其在module执行forward之前就运行了，具体可看module.call中的代码。 torch.nn.Module.register_full_backward_hook 功能：Module反向传播中的hook,每次计算module的梯度后，自动调用hook函数。 形式：hook(module, grad_input, grad_output) -> tuple(Tensor) or None 注意事项： 当module有多个输入或输出时，grad_input和grad_output是一个tuple。 register_full_backward_hook 是修改过的版本，旧版本为register_backward_hook，不过官方已经建议弃用，不需要再了解。 返回值：a handle that can be used to remove the added hook by calling handle.remove() 应用场景举例：提取特征图的梯度 Grad-CAM 实现 采用register_full_backward_hook实现特征图梯度的提取，并结合Grad-CAM（基于类梯度的类激活图可视化）方法对卷积神经网络的学习模式进行可视化。 关 于Grad-CAM请看论文：《Grad-CAM Visual Explanations from Deep Networks via Gradient-based Localization》 简单介绍Grad-CAM的操作，Grad-CAM通过对最后一层特征图进行加权求和得到heatmap，整个CAM系列的主要研究就在于这个加权求和中的权值从那里来。 Grad-CAM是对特征图进行求梯度，将每一张特征图上的梯度求平均得到权值（特征图的梯度是element-wise的）。求梯度时并不采用网络的输出，而是采用类向量，即one-hot向量。 下图是ResNet的Grad-CAM示意图，上图类向量采用的是猫的标签，下图采用的是狗的标签，可以看到在上图模型更关注猫（红色部分），下图判别为狗的主要依据是狗的头部。 ​ 下面采用一个LeNet-5演示backward_hook在Grad-CAM中的应用。 简述代码过程： 创建网络net； 注册forward_hook函数用于提取最后一层特征图； 注册backward_hook函数用于提取类向量（one-hot）关于特征图的梯度 对特征图的梯度进行求均值，并对特征图进行加权； 可视化heatmap。 PS：需要注意的是在backward_hook函数中，grad_out是一个tuple类型的，要取得特征图的梯度需要这样grad_block.append(grad_out[0].detach()) 思考 这里对3张飞机的图片进行观察heatmap，如下图所示，第一行是原图，第二行是叠加了heatmap的图片。 这里发现一个有意思的现象，模型将图片判为飞机的依据是蓝天，而不是飞机（图1-3）。 那么我们喂给模型一张纯天蓝色的图片，模型会判为什么呢？如图4所示，发现模型判为了飞机 从这里发现，虽然能将飞机正确分类，但是它学到的却不是飞机的特征！ 这导致模型的泛化性能大打折扣，从这里我们可以考虑采用trick让模型强制的学习到飞机而不是常与飞机一同出现的蓝天，或者是调整数据。 ​ 对于图4疑问：heatmap蓝色区域是否对图像完全不起作用呢？是否仅仅通过红色区域就可以对图像进行判别呢？ 接下来将一辆正确分类的汽车图片（图5）叠加到图4蓝色响应区域（即模型并不关注的区域），结果如图6所示，汽车部分的响应值很小，模型仍通过天蓝色区域将图片判为了飞机。 接着又将汽车叠加到图4红色响应区域（图的右下角），结果如图7所示，仍将图片判为了飞机。 有意思的是将汽车叠加到图7的红色响应区域，模型把图片判为了船，而且红色响应区域是蓝色区域的下部分，这个与船在大海中的位置很接近。 ​ 通过以上代码学习full_backward_hook的使用及其在Grad-CAM中的应用，并通过Grad-CAM能诊断模型是否学习到了关键特征。 关于CAM( class activation maping，类激活响应图)是一个很有趣的研究，有兴趣的朋友可以对CAM、Grad-CAM和Grad-CAM++进行研究。 小结 本小节介绍了编程语言中经典的思想——Hook函数，并讲解了pytorch中如何使用它们，最后还采用full_backward_hook实现有趣的Grad-CAM可视化，本节代码较多，建议对着配套代码单步调试进行学习，掌握hook函数的妙用，在今后使用pytorch进行模型分析、魔改的时候更游刃有余。 下一小结会把本章所学的Module相关容器、网络层的知识点串起来使用，通过剖析torchvision中经典模型的源代码，了解所学习的知识点是如何使用的。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年04月26日21:48:10 "},"chapter-4/4.6-classic-model.html":{"url":"chapter-4/4.6-classic-model.html","title":"4.6 经典模型代码分析","keywords":"","body":"4.6 经典Model代码分析 torchvision中提供了一些经典的卷积神经网络模型实现，本小节将挑选部分进行分析，学习torchvision是如何构建复杂的网络模型，学习它们的代码风格、代码规范。 AlexNet 出自：ImageNet Classification with Deep Convolutional Neural Networks 模型结构图如下图所示：整体可分为前半部分的特征提取与后半部分的分类。 ​ 代码分析： D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\Lib\\site-packages\\torchvision\\models\\alexnet.py 代码中定义了一个AlexNet类与一个alexnet函数，这样的封装形式贯穿整个torchvision的模型定义。 AlexNet类是nn.Module，其中定义了AlexNet模型的具体结构，而alexnet函数则是对Alexnet类的包装，并且实现加载预训练参数的功能，即以下代码： model = AlexNet(**kwargs) if pretrained: state_dict = load_state_dict_from_url(model_urls[\"alexnet\"], progress=progress) model.load_state_dict(state_dict) return model 从此也知道，torchvision中定义模型所采用的预训练模型均是通过指定的url下载，并存储于本地磁盘供下一次使用。 由于“网络问题”，通常建议大家通过代码中给出的url自行下载权重文件，然后在自己的代码中使用load_state_dict方法加载预训练参数。 分析了alexnet.py整体结构，下面回到AlexNet类本身，看看具体模型如何写的。 class AlexNet(nn.Module): def __init__(self, num_classes: int = 1000) -> None: def forward(self, x: torch.Tensor) -> torch.Tensor: AlexNet采用熟悉的方式定义了两个函数，熟悉4.1小结中的知识点的话，这里不比多说。 forward函数中第48行代码值得注意，二维特征图要输入到Linear层，通常通过flatten函数对特征图进行变换。 def forward(self, x: torch.Tensor) -> torch.Tensor: x = self.features(x) x = self.avgpool(x) x = torch.flatten(x, 1) # Line 48 x = self.classifier(x) return x 总结： 采用函数形式封装模型类，额外提供预训练权重加载功能； Linear层之前可通过torch.flatten将数据变为一维向量； VGG VGG出自：Very Deep Convolutional Networks For Large-Scale Image Recognition 其共有4种深度，分别是11， 13， 16， 19层，用得比较多的VGG16、19。VGG的代码就比AlexNet复杂了，因为它涉及8个具体的网络模型定义，因此不能再使用面向过程的方式进行编写，需要将共性的部分抽象出来，这一份代码值得新手仔细、认真学习。 首先是大体了解VGG整体结构，网络结构示意图如下图所示： ​ VGG最大特点是2个3x3、3个3x3卷积层的堆叠，并且堆叠总共分5次，最后接入三个FC层。从此可知，核心是如何将特征提取部分进行抽象，请大家带着这个问题观察代码：D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\Lib\\site-packages\\torchvision\\models\\vgg.py vgg.py中定义了VGG类、_vgg函数、make_layers函数、cfgs字典，以及一系列具体网络模型封装的函数，如vgg11，vgg13， vgg16等。 看过alexnet.py，这里能猜出VGG类是一个nn.module。 _vgg函数：vgg函数接收具体的网络参数，以此决定返回哪一个vgg模型； vggxxx：定义了具体VGG所需要的参数，并调用_vgg函数得到具体模型； make_layers函数：创建可抽象出来、共性的网络层函数，即网络结构图中的5次堆叠部分。 cfgs字典：配置各具体vgg模型所需要的参数，主要在make_layers中使用。 下面以vgg16为例，观察vgg.py是如何实现它的。 看到153行代码： def vgg16(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG: return _vgg(\"vgg16\", \"D\", False, pretrained, progress, **kwargs) 可知道，vgg16是对_vgg的封装，并且固定了两个参数\"vgg16\" 和 \"D\"。 跳到94行代码： def _vgg(arch: str, cfg: str, batch_norm: bool, pretrained: bool, progress: bool, **kwargs: Any) -> VGG: if pretrained: kwargs[\"init_weights\"] = False model = VGG(make_layers(cfgs[cfg], batch_norm=batch_norm), **kwargs) if pretrained: state_dict = load_state_dict_from_url(model_urls[arch], progress=progress) model.load_state_dict(state_dict) return model 可知道_vgg调用了VGG类得到最终的模型，并且给VGG传入了make_layers函数创建的网络层； 通过这行代码可知道，需要进入make_layers去观察如何创建网络层的。进入make_layers前，需要知道cfgs[cfg]当前传入的是： 'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'], 跳到69行代码： def make_layers(cfg: List[Union[str, int]], batch_norm: bool = False) -> nn.Sequential: layers: List[nn.Module] = [] in_channels = 3 for v in cfg: if v == \"M\": layers += [nn.MaxPool2d(kernel_size=2, stride=2)] else: v = cast(int, v) conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1) if batch_norm: layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)] else: layers += [conv2d, nn.ReLU(inplace=True)] in_channels = v return nn.Sequential(*layers) 从这里可知道是对cfg中进行for循环，不断的构建网络层，并且添加到list中，最后组装成一个Sequential的形式。这里的代码逻辑就是网络结构图中的抽象，把四种模型的共性地方抽象出来，然后通过不同的配置参数可生成vgg11, vgg13, vgg16, vgg19。这里的代码值得学习。 弄清楚make_layers是生成前面一系列卷积层的堆叠Sequential之后，继续进入VGG类观察。 跳到25行代码，看一个Module，可以先看forward函数，再看forward中的属性是怎么来的。 def forward(self, x: torch.Tensor) -> torch.Tensor: x = self.features(x) x = self.avgpool(x) x = torch.flatten(x, 1) x = self.classifier(x) return x 可以发现它的forward十分简洁，因为vgg模型就是以简洁出名的，像一个糖葫芦一样串起来即可。接着去看看self.features是什么，怎么来的，这个需要到init函数中寻找。 跳到34行代码：self.features = features 由此可知道，VGG特征提取部分的网络层均是通过make_layers函数定义的那个Sequential。 接着36行代码的classifier就没啥好说的。 接着的第45行代码出现了新内容，权重初始化。调用了_initialize_weights函数对VGG模型进行权重初始化。众所周知，良好的权重初始化对模型训练是至关重要的，早期对于权重初始化有许多的研究，比较著名的有Xavier方法、MSRA（Kaiming）方法。 预告：具体的权重初始化方法将在下一小节详细介绍。 下面观察如何编写函数对VGG进行权重初始化：跳转55行 def _initialize_weights(self) -> None: for m in self.modules(): if isinstance(m, nn.Conv2d): nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\") if m.bias is not None: nn.init.constant_(m.bias, 0) elif isinstance(m, nn.BatchNorm2d): nn.init.constant_(m.weight, 1) nn.init.constant_(m.bias, 0) elif isinstance(m, nn.Linear): nn.init.normal_(m.weight, 0, 0.01) nn.init.constant_(m.bias, 0) 此函数的逻辑就是遍历所有Module，并判断Module类型，根据不同的Module类型设置不同的初始化方法，如卷积层则用kaiming方法设置weight，bias全部设置为0；BN层的weight设置为1，bias设置为0；全连接层的weight用正态分布进行随机初始化，bias设置为0。 到这里一个具体的VGG模型定义就讲完了，下面总结一下它们的调用关系与逻辑。 vgg16() --> _vgg() --> make_layers --> VGG：最核心在于如何构建一个模块（函数也好、类也好）可以接收不同的参数（cfgs）就能生成对应VGG的特征提取部分的网络层（一个大的Sequential）。 GoogLeNet GoogLeNet-V1 出自 Going deeper with convolutions，后续也有V2，V3，V4，这里不进行介绍。 V1的提出最大的特点在于提出Inception模块，它是一个多分支的特征提取模块，如下图所示： ​ 网络结构如下图所示： ​ 代码并不复杂，但其中的Inception模块的编写，是之前没有遇到的，可以借鉴学习。 观察D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\Lib\\site-packages\\torchvision\\models\\googlenet.py 可以看到熟悉的定义了具体的Module——GoogLeNet类，模型的封装调用函数——googlenet，以及从GoogLeNet模型抽象出来的、反复需要使用的模块——Inception、InceptionAux、BasicConv2d。 这里面的代码并不复杂，这里不逐行分析，只把GoogLeNet类的逻辑关系理一理。 首先，将反复使用的模块抽象成一个类，这样在使用的时候只需要一行代码即可定义好，如BasicConv2d：包含了卷积层+BN层； Inception：包含四个分支的处理并合并最终特征图； InceptionAux：辅助分类层输出。 然后在init函数中像搭积木一样，把需要用到的模块逐一定义 最后在forward函数中调用定义好的网络层即可。 总结： 反复使用的模块抽象为一个Moudle类，并作为参数进行调用。好处在于当想修改这些基础元素模块的时候，仅需要重新写一个Module类替换即可，并不需要改动GoogLeNet类当中的任何代码（在resnet中会有体现）。要想理解好这一点，请仔细体会这几行代码 blocks = [BasicConv2d, Inception, InceptionAux] conv_block = blocks[0] inception_block = blocks[1] inception_aux_block = blocks[2] Resnet ResNet出自何恺明的《Deep Residual Learning for Image Recognition》，是目前工业界应用最广泛的卷积神经网络。 网络结构如下图所示，有ResNet-18， 34， 50， 101， 152，使用较多的为ResNet-50。其结构特点也是模块的堆叠，如表格中看到的x2， x3，x4, x6表示的是一个模块堆叠2次、3次、4次、6次。 ​ 在resnet模型中，最大的特点在于采用了残差结构的模块，如下图所示： ​ 这里有两种形式，一种是BasicBlock，另外一种是resnet50/101/152用的Bottleneck。 下面就来看看D:\\Anaconda_data\\envs\\pytorch_1.10_gpu\\Lib\\site-packages\\torchvision\\models\\resnet.py 是如何实现这一系列复杂的resnet模型。 提示：pycharm中按住Ctrl+Shift+ \"-\" ，可以把代码块收起来，可以快速浏览resnet.py下的主要内容，可以发现，还是熟悉的结构，分别有 ResNet类 _resnet函数 resnet18\\34\\50...一系列具体模型函数 抽象出来的基础模块：BasicBlock、Bottleneck、conv1x1和conv3x3。 这其中最为特色的是BasicBlock和Bottleneck，分别对应论文图5中的两个结构，它们将在不同的模型中使用。 下面就看看BasicBlock和Bottleneck到底是如何使用的。 跳到144行代码：class ResNet(nn.Module)，观察init函数里是如何使用block的。 跳到第178行代码：self.layer1 = self._make_layer(block, 64, layers[0])，在make_layer函数中使用了block进行网络层的构建。这点与VGG中的make_layers类似。 跳到205行代码： def _make_layer( self, block: Type[Union[BasicBlock, Bottleneck]], planes: int, blocks: int, stride: int = 1, dilate: bool = False, ) -> nn.Sequential: norm_layer = self._norm_layer downsample = None previous_dilation = self.dilation if dilate: self.dilation *= stride stride = 1 if stride != 1 or self.inplanes != planes * block.expansion: downsample = nn.Sequential( conv1x1(self.inplanes, planes * block.expansion, stride), norm_layer(planes * block.expansion), ) layers = [] layers.append( block( self.inplanes, planes, stride, downsample, self.groups, self.base_width, previous_dilation, norm_layer ) ) self.inplanes = planes * block.expansion for _ in range(1, blocks): layers.append( block( self.inplanes, planes, groups=self.groups, base_width=self.base_width, dilation=self.dilation, norm_layer=norm_layer, ) ) return nn.Sequential(*layers) 在此函数中使用block（是一个基础模块的类，是BasicBlock或Bottleneck）定义网络层，然后堆叠起来，最后使用Sequential进行包装，构成一个整体。 回到init函数可知道，178-184行代码所构建的模块对应了网络结构的四个部分，对应关系如下图所示： self.layer1 = self._make_layer(block, 64, layers[0]) self.layer2 = self._make_layer(block, 128, layers[1], stride=2, dilate=replace_stride_with_dilation[0]) self.layer3 = self._make_layer(block, 256, layers[2], stride=2, dilate=replace_stride_with_dilation[1]) self.layer4 = self._make_layer(block, 512, layers[3], stride=2, dilate=replace_stride_with_dilation[2]) ​ 在这里，可以发现resnet18和34用的是BasicBlock， resnet50/101/152用的是Bottleneck def resnet18(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> ResNet: return _resnet(\"resnet18\", BasicBlock, [2, 2, 2, 2], pretrained, progress, **kwargs) def resnet50(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> ResNet: return _resnet(\"resnet50\", Bottleneck, [3, 4, 6, 3], pretrained, progress, **kwargs) BasicBlock和Bottleneck的使用与googlenet中的blocks呼应上了，请大家仔细对比。 resnet总结 resnet的搭建是将block抽象出来提供接口，由用户自行传入，并且设定堆叠次数，如resnet18就是BasicBlock, [2, 2, 2, 2]， resnet50就是 Bottleneck, [3, 4, 6, 3]，处处体现了面向对象的编程思维，值得学习。 总结 本小节从简单的AlexNet到复杂的ResNet进行了代码分析，剖析了pytorch的代码结构，编写逻辑以及思想，其中面向对象的思维值得认真学习借鉴。 VGG中的make_layers()：通过参数配置形式搭建一个大的Sequential； GoogLeNet的BasicConv2d, Inception, InceptionAux、ResNet的BasicBlock、Bottleneck、conv1x1、conv3x3都是抽象的基础模块。 本小节在多出看到了权重初始化方法，好的权重初始化是模型训练的第一步，下一小节将介绍pytorch提供的系列权重初始化方法及其应用。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年04月26日21:48:10 "},"chapter-4/4.7-weight-init.html":{"url":"chapter-4/4.7-weight-init.html","title":"4.7 权重初始化方法","keywords":"","body":"4.7 权重初始化方法 https://pytorch.org/docs/stable/nn.init.html 良好的模型权重初始化，有利于模型的训练，在torch.nn.init中提供了数十个初始化方法，本小节对它们进行介绍。 回顾上一小节中VGG的初始化代码，先总结出权重初始化的流程与步骤。 for m in self.modules(): if isinstance(m, nn.Conv2d): nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\") if m.bias is not None: nn.init.constant_(m.bias, 0) elif isinstance(m, nn.BatchNorm2d): nn.init.constant_(m.weight, 1) nn.init.constant_(m.bias, 0) elif isinstance(m, nn.Linear): nn.init.normal_(m.weight, 0, 0.01) nn.init.constant_(m.bias, 0) 首先对每一个子module进行遍历，对不同的网络层进行设置对应的权重初始化方法，初始化方法采用的是nn.init.xxx函数。 接下来nn.init.xxx就是本节的主角，下面依次介绍nn.init.xxx函数。 主要分为三部分： Xavier 系列 kaiming 系列 常数方法 Xavier 系列 torch.nn.init.xavieruniform(tensor, gain=1.0) xavier 初始化方法中服从均匀分布 U(-a,a) ，分布的参数 a = gain * sqrt(6/fan_in+fan_out)， 这里有一个 gain，表示增益，它的大小是依据激活函数类型来设定。本方法也称为 Glorot initialization。 torch.nn.init.xaviernormal(tensor, gain=1.0) xavier初始化方法中服从正态分布， mean=0,std = gain * sqrt(2/fan_in + fan_out) Xavier初始化方法的理论分析可见《Understanding the difficulty of training deep feedforward neural networks - Glorot, X. & Bengio, Y. (2010),》 Kaiming系列 ​ 3.### torch.nn.init.kaiminguniform(tensor, a=0, mode='fan_in', nonlinearity='leaky_relu') 此为均匀分布，U～（-bound, bound）, bound = sqrt(6/(1+a^2)*fan_in) 其中，a为激活函数的负半轴的斜率，relu是0 mode- 可选为fan_in 或 fan_out, fan_in使正向传播时，方差一致; fan_out使反向传播时，方差一致 nonlinearity- 可选 relu 和 leaky_relu ，默认值为 :leaky_relu torch.nn.init.kaimingnormal(tensor, a=0, mode='fan_in', nonlinearity='leaky_relu') 此为0均值的正态分布，N～ (0,std)，其中std = sqrt(2/(1+a^2)*fan_in) 其中，a为激活函数的负半轴的斜率，relu是0 mode- 可选为fan_in 或 fan_out, fan_in使正向传播时，方差一致;fan_out使反向传播时，方差一致 nonlinearity- 可选 relu 和 leaky_relu ，默认值为： leaky_relu Kaiming系列的初始化方法理论分析可参阅《Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification - He, K. et al. (2015》 其它方法 均匀分布初始化 torch.nn.init.uniform_(tensor, a=0, b=1) 使值服从均匀分布U(a,b) 正态分布初始化 torch.nn.init.normal_(tensor, mean=0, std=1) 使值服从正态分布N(mean, std)，默认值为0，1 常数初始化 torch.nn.init.constant_(tensor, val) 使值为常数val nn.init.constant_(w, 0.3) 单位矩阵初始化 torch.nn.init.eye_(tensor) 将二维tensor初始化为单位矩阵（the identity matrix） 正交初始化 torch.nn.init.orthogonal_(tensor, gain=1) 使得tensor是正交的，论文:Exact solutions to the nonlinear dynamics of learning in deep linear neural networks” - Saxe, A. et al. (2013) 稀疏初始化 torch.nn.init.sparse_(tensor, sparsity, std=0.01) 从正态分布N～（0. std）中进行稀疏化，使每一个column有一部分为0 sparsity- 每一个column稀疏的比例，即为0的比例 nn.init.sparse_(w, sparsity=0.1) 全零初始化 torch.nn.init.zeros_(tensor) 所有参数置零。 全1初始化 torch.nn.init.ones_(tensor) 所有参数置一。 狄拉克初始化 torch.nn.init.dirac_(tensor, groups=1) 采用狄拉克函数进行权重初始化， 增益计算 torch.nn.init.calculate_gain(nonlinearity, param=None) 返回各激活函数对应的增益值，该值影响权重初始化的方差。 nonlinearity gain Linear / Identity 1 Conv{1,2,3}D 1 Sigmoid 1 Tanh 35 ReLU 2 Leaky Relu 1+negative_slope22 SELU 43 小结 本小节将torch.nn.init中包含的初始化方法进行了分类介绍，主要分为Xavier和Kaiming方法与其它常数方法，并且回顾了torchvision中如何对一个模型所有层进行权重初始化的流程，希望对大家有所帮助。 Copyright © TingsongYu 2021 all right reserved，powered by Gitbook文件修订时间： 2022年04月26日21:48:10 "}}